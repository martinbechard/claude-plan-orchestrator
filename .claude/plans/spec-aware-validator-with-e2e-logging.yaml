meta:
  name: Spec-Aware Validator with E2E Test Logging
  description: Enhance the validator agent to read functional spec verification blocks,
    run referenced E2E tests, capture timestamped JSON results, and include E2E pass/fail
    in the validation verdict. Create an e2e-analyzer agent for on-demand log review.
  plan_doc: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md
  created: '2026-02-18'
  max_attempts_default: 3
  validation:
    enabled: true
    run_after:
    - coder
    validators:
    - validator
    max_validation_attempts: 1
sections:
- id: phase-1
  name: Phase 1 - Documentation and Templates
  status: completed
  tasks:
  - id: '1.1'
    name: Create verification block template
    agent: coder
    status: completed
    description: "Create a reference template for verification blocks in functional\
      \ spec files.\n\nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Create the file docs/templates/verification-block.md with the following\
      \ content:\n\n   A markdown document that explains the verification block format\
      \ used in\n   functional specification files. Include:\n\n   - A header explaining\
      \ the purpose: these blocks tell the validator agent\n     which E2E tests verify\
      \ each requirement\n   - The full block format with all fields:\n     ### Verification\n\
      \     **Type:** Testable | Non-E2E | Blocked\n     **Test file(s):** <path to\
      \ test file(s), comma-separated for multiple>\n     **Status:** Pass | Fail\
      \ | Missing\n     **Scenario:** <description of what is being verified>\n  \
      \   - Route: <URL route being tested>\n     - Steps: <human-readable test steps>\n\
      \     - Assertions: <what the test checks>\n   - Explanation of each Type value:\n\
      \     Testable = has an automated E2E test\n     Non-E2E = verified by other\
      \ means (unit test, manual, code review)\n     Blocked = no UI/API exists yet,\
      \ test cannot be written\n   - Explanation of each Status value:\n     Pass\
      \ = test exists and passes\n     Fail = test exists but is failing\n     Missing\
      \ = test file referenced but does not exist yet\n   - Example of a complete\
      \ block for a diagnostics page load test\n   - Example of a Non-E2E block (e.g.,\
      \ a server-side validation check)\n   - Example of a Blocked block\n\n2. Git\
      \ commit:\n   git add docs/templates/verification-block.md\n   git commit -m\
      \ \"docs: add verification block template for functional specs\"\n\nFiles: docs/templates/verification-block.md\n"
    attempts: 1
    last_attempt: '2026-02-18T20:16:52.365573'
    model_used: sonnet
    completed_at: '2026-02-18T20:18:25.113320'
    result_message: 'Created docs/templates/verification-block.md with full format
      reference, field explanations, and three examples (Testable, Non-E2E, Blocked).
      Committed as ''docs: add verification block template for functional specs''.'
- id: phase-2
  name: Phase 2 - Implementation
  status: completed
  tasks:
  - id: '2.1'
    name: Add spec-aware config constants and parse_verification_blocks helper
    agent: coder
    status: completed
    description: "Add spec-aware validation configuration to plan-orchestrator.py\
      \ and a helper\nfunction to parse verification blocks from functional spec markdown\
      \ files.\n\nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read scripts/plan-orchestrator.py. Find the config constants section\n\
      \   (around lines 47-52 where DEFAULT_BUILD_COMMAND etc. are defined).\n\n2.\
      \ After DEFAULT_AGENTS_DIR, add two new defaults:\n\n   DEFAULT_SPEC_DIR = \"\
      \"\n   DEFAULT_E2E_COMMAND = \"npx playwright test\"\n\n3. Find where _config\
      \ values are read (around lines 275-280 where\n   BUILD_COMMAND, TEST_COMMAND\
      \ etc. are extracted). After AGENTS_DIR, add:\n\n   SPEC_DIR = _config.get(\"\
      spec_dir\", DEFAULT_SPEC_DIR)\n   E2E_COMMAND = _config.get(\"e2e_command\"\
      , DEFAULT_E2E_COMMAND)\n\n4. After the parse_agent_frontmatter() function (around\
      \ line 302), add a\n   new function parse_verification_blocks(content: str)\
      \ -> list[dict]:\n\n   This function takes the full text content of a functional\
      \ spec file and\n   returns a list of dicts, one per verification block found.\
      \ Each dict has:\n   - type: str (e.g., \"Testable\", \"Non-E2E\", \"Blocked\"\
      )\n   - test_files: list[str] (parsed from \"Test file(s):\" line, split on\
      \ comma)\n   - status: str (e.g., \"Pass\", \"Fail\", \"Missing\")\n   - scenario:\
      \ str (the scenario description text)\n\n   Parsing logic:\n   - Split content\
      \ by \"### Verification\" headings\n   - For each block after the split, use\
      \ regex to extract:\n     **Type:** <value>  -> type field\n     **Test file(s):**\
      \ <value>  -> test_files field (split by comma, strip each)\n     **Status:**\
      \ <value>  -> status field\n     **Scenario:** <value>  -> scenario field (everything\
      \ after Scenario: to next **)\n   - Skip blocks that fail to parse (missing\
      \ fields)\n   - Return empty list if no blocks found\n\n   Use these regex patterns:\n\
      \     re.compile(r'\\*\\*Type:\\*\\*\\s*(.+)')\n     re.compile(r'\\*\\*Test\
      \ file\\(s\\):\\*\\*\\s*(.+)')\n     re.compile(r'\\*\\*Status:\\*\\*\\s*(.+)')\n\
      \     re.compile(r'\\*\\*Scenario:\\*\\*\\s*(.+)')\n\n5. Verify syntax:\n  \
      \ python3 -c \"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\
      \ doraise=True); print('syntax OK')\"\n\n6. Git commit:\n   git add scripts/plan-orchestrator.py\n\
      \   git commit -m \"feat: add spec-aware config and parse_verification_blocks\
      \ helper\"\n\nFiles: scripts/plan-orchestrator.py\n"
    attempts: 1
    last_attempt: '2026-02-18T20:18:27.552538'
    model_used: sonnet
    completed_at: '2026-02-18T20:20:44.407296'
    result_message: Added DEFAULT_SPEC_DIR and DEFAULT_E2E_COMMAND constants, read
      SPEC_DIR and E2E_COMMAND from orchestrator config, and added parse_verification_blocks()
      helper with module-level compiled regex patterns. Syntax verified OK.
  - id: '2.2'
    name: Update build_validation_prompt to include spec-aware context
    agent: coder
    status: completed
    depends_on:
    - '2.1'
    description: "Update the build_validation_prompt() function in plan-orchestrator.py\
      \ to\ninclude spec-aware validation context when the project has SPEC_DIR configured.\n\
      \nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read scripts/plan-orchestrator.py. Find the build_validation_prompt()\n\
      \   function (around line 1005).\n\n2. After the existing return statement's\
      \ content (the f-string that ends\n   with the \"IMPORTANT: You MUST write...\"\
      \ line), add a spec-aware section\n   that is conditionally included. Modify\
      \ the function to:\n\n   a. Before constructing the return string, build a spec_context\
      \ variable:\n\n      spec_context = \"\"\n      if SPEC_DIR:\n          spec_context\
      \ = f\"\"\"\n\n## Spec-Aware Validation (E2E Tests)\n\nThis project has functional\
      \ specifications in: {SPEC_DIR}\nE2E test command: {E2E_COMMAND}\n\nAfter the\
      \ standard validation checks above, perform these additional steps:\n\n1. Run:\
      \ git diff --name-only HEAD~1 HEAD\n   Look for any files under {SPEC_DIR} in\
      \ the diff output.\n\n2. If spec files were modified, read each changed spec\
      \ file and find all\n   ### Verification blocks.\n\n3. For each block with **Type:\
      \ Testable** and a **Test file(s):** reference:\n   - Run the E2E test: {E2E_COMMAND}\
      \ <test_file> --reporter=json\n   - Capture the JSON output to logs/e2e/ with\
      \ a timestamped filename\n     (format: YYYY-MM-DDTHHMMSS.json)\n   - Parse\
      \ the JSON to determine pass/fail counts\n\n4. Include E2E test results in your\
      \ findings:\n   - [PASS] E2E: <test_file> - all N tests passed\n   - [FAIL]\
      \ E2E: <test_file> - M of N tests failed\n\n5. If no spec files were changed\
      \ in the diff, skip E2E testing and note:\n   - [PASS] E2E: No functional spec\
      \ changes detected, E2E tests skipped\n\n6. E2E failures should result in a\
      \ WARN verdict (not FAIL) unless the\n   failing tests are directly related\
      \ to the task's requirements.\n\"\"\"\n\n   b. Include spec_context in the returned\
      \ prompt string, before the\n      \"IMPORTANT: You MUST write...\" line.\n\n\
      3. Verify syntax:\n   python3 -c \"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\
      \ doraise=True); print('syntax OK')\"\n\n4. Git commit:\n   git add scripts/plan-orchestrator.py\n\
      \   git commit -m \"feat: include spec-aware E2E context in validation prompt\"\
      \n\nFiles: scripts/plan-orchestrator.py\n"
    attempts: 1
    last_attempt: '2026-02-18T20:20:46.739291'
    model_used: sonnet
    completed_at: '2026-02-18T20:22:34.985094'
    result_message: Updated build_validation_prompt() to conditionally include spec-aware
      E2E validation context when SPEC_DIR is configured. The spec_context block is
      injected between the standard validation checks and the output format section.
  - id: '2.3'
    name: Update validator agent with spec-aware instructions
    agent: coder
    status: completed
    depends_on:
    - '2.2'
    description: "Update the validator agent definition to include spec-aware validation\n\
      instructions.\n\nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read .claude/agents/validator.md.\n\n2. In the \"## Validation\
      \ Steps\" section, after step 2 (run test command)\n   and before step 3 (verify\
      \ requirements), insert a new step:\n\n   3. If the validation prompt includes\
      \ a \"Spec-Aware Validation\" section:\n      a. Run `git diff --name-only HEAD~1\
      \ HEAD` to find changed files\n      b. Filter for files under the spec directory\
      \ mentioned in the prompt\n      c. For each changed spec file, read it and\
      \ find `### Verification` blocks\n      d. For each block with `**Type: Testable**`\
      \ and `**Test file(s):**`:\n         - Run the E2E test command with `--reporter=json`\n\
      \         - Save JSON output to `logs/e2e/<timestamp>.json`\n         - Parse\
      \ pass/fail counts from the JSON\n      e. If no spec files changed, note that\
      \ E2E tests were skipped\n\n   Renumber the existing steps 3 and 4 to become\
      \ 4 and 5.\n\n3. In the \"## Verdict Rules\" section, add a clarification:\n\
      \n   Under WARN, add: \"E2E test failures for tests not directly related to\n\
      \   the task requirements.\"\n\n   Under FAIL, add: \"E2E test failures for\
      \ tests directly referenced by\n   the task's functional spec changes.\"\n\n\
      4. In the \"## Constraints\" section, add:\n\n   - When running E2E tests, always\
      \ use --reporter=json and save output to\n     logs/e2e/ with a timestamped\
      \ filename (YYYY-MM-DDTHHMMSS.json).\n   - Only run E2E tests when the validation\
      \ prompt includes spec-aware context.\n     Do not search for spec files on\
      \ your own.\n\n5. Git commit:\n   git add .claude/agents/validator.md\n   git\
      \ commit -m \"feat: add spec-aware E2E validation to validator agent\"\n\nFiles:\
      \ .claude/agents/validator.md\n"
    attempts: 1
    last_attempt: '2026-02-18T20:22:37.365403'
    model_used: sonnet
    completed_at: '2026-02-18T20:24:57.611674'
    result_message: 'Updated validator.md: inserted spec-aware E2E step 3 in Validation
      Steps (renumbered old 3/4 to 4/5), added WARN/FAIL E2E clarifications to Verdict
      Rules, and added two E2E constraints to Constraints section.'
  - id: '2.4'
    name: Create e2e-analyzer agent
    agent: coder
    status: completed
    description: "Create a new agent for on-demand analysis of accumulated E2E test\
      \ logs.\n\nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read .claude/agents/validator.md and .claude/agents/issue-verifier.md\n\
      \   for agent format reference (YAML frontmatter + markdown body).\n\n2. Create\
      \ .claude/agents/e2e-analyzer.md with:\n\n   Frontmatter:\n   - name: e2e-analyzer\n\
      \   - description: \"E2E test results analyzer. Reads accumulated JSON test\
      \ logs\n     in logs/e2e/ to identify flaky tests, detect regressions, summarize\n\
      \     pass/fail trends, and compare results between runs. Read-only.\"\n   -\
      \ tools: [Read, Grep, Glob, Bash]\n   - model: sonnet\n\n   Body sections:\n\
      \n   ## Role\n   You are an E2E test results analyzer. You review accumulated\
      \ Playwright\n   JSON test logs to provide insights about test health, flakiness,\
      \ and\n   regressions. You do NOT fix tests or modify code.\n\n   ## Before\
      \ Analyzing\n   1. List all JSON files in logs/e2e/ sorted by timestamp\n  \
      \ 2. Determine the date range of available logs\n   3. Read the user's analysis\
      \ request to understand what they want\n\n   ## Analysis Capabilities\n   For\
      \ each capability, describe the approach:\n\n   ### Summary Report\n   - Count\
      \ total pass/fail/skip across all runs or a date range\n   - Show per-test-file\
      \ breakdown\n   - Highlight any tests with 0% pass rate\n\n   ### Flaky Test\
      \ Detection\n   - Find tests that have both pass and fail results across runs\n\
      \   - Calculate flakiness rate (fail_count / total_runs)\n   - Rank by flakiness,\
      \ most flaky first\n\n   ### Regression Detection\n   - Find tests that were\
      \ passing before a given date but failing after\n   - Cross-reference with git\
      \ log to identify potential culprit commits\n   - Report: test name, last pass\
      \ date, first fail date, suspect commits\n\n   ### Run Comparison\n   - Compare\
      \ two specific JSON log files\n   - Show tests that changed status (pass->fail,\
      \ fail->pass)\n   - Show new tests and removed tests\n\n   ## Output Format\n\
      \   Use markdown tables for structured data. Include:\n   - Date range analyzed\n\
      \   - Number of log files reviewed\n   - Key findings with specific test names\
      \ and file paths\n\n   ## Constraints\n   - Read-only: do not modify any files\n\
      \   - Only use Read, Grep, Glob to inspect logs and code\n   - Use Bash only\
      \ for listing/sorting log files\n   - Parse JSON with python3 -c \"...\" one-liners\
      \ if needed\n\n   ## Output Protocol\n   Write a status file to .claude/plans/task-status.json\
      \ when done.\n\n3. Git commit:\n   git add .claude/agents/e2e-analyzer.md\n\
      \   git commit -m \"feat: add e2e-analyzer agent for test log analysis\"\n\n\
      Files: .claude/agents/e2e-analyzer.md\n"
    attempts: 1
    last_attempt: '2026-02-18T20:24:59.923360'
    model_used: sonnet
    completed_at: '2026-02-18T20:26:49.314133'
    result_message: 'Created .claude/agents/e2e-analyzer.md with YAML frontmatter
      and full analysis body covering summary reports, flaky test detection, regression
      detection, and run comparison. Committed as feat: add e2e-analyzer agent for
      test log analysis.'
- id: phase-3
  name: Phase 3 - Unit Tests
  status: pending
  tasks:
  - id: '3.1'
    name: Add unit tests for parse_verification_blocks
    agent: coder
    status: pending
    depends_on:
    - '2.1'
    description: "Add unit tests for the parse_verification_blocks() helper function.\n\
      \nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read tests/test_plan_orchestrator.py to understand existing test\
      \ patterns,\n   especially how the plan-orchestrator module is imported.\n\n\
      2. Add the following tests:\n\n   a. test_parse_verification_blocks_single_testable():\n\
      \      - Input: a spec markdown string containing one ### Verification block\n\
      \        with Type: Testable, Test file(s): tests/DG01-test.spec.ts,\n     \
      \   Status: Pass, Scenario: some description\n      - Call parse_verification_blocks(content)\n\
      \      - Assert returns a list with one dict\n      - Assert dict has type=\"\
      Testable\", test_files=[\"tests/DG01-test.spec.ts\"],\n        status=\"Pass\"\
      , scenario containing \"some description\"\n\n   b. test_parse_verification_blocks_multiple_blocks():\n\
      \      - Input: spec with two ### Verification blocks (one Testable, one Non-E2E)\n\
      \      - Assert returns two dicts with correct types\n\n   c. test_parse_verification_blocks_no_blocks():\n\
      \      - Input: a spec markdown string with no ### Verification heading\n  \
      \    - Assert returns empty list\n\n   d. test_parse_verification_blocks_multiple_test_files():\n\
      \      - Input: a block with Test file(s): tests/a.spec.ts, tests/b.spec.ts\n\
      \      - Assert test_files is [\"tests/a.spec.ts\", \"tests/b.spec.ts\"]\n\n\
      \   e. test_parse_verification_blocks_blocked_type():\n      - Input: a block\
      \ with Type: Blocked\n      - Assert returns a dict with type=\"Blocked\"\n\n\
      \   f. test_parse_verification_blocks_missing_fields():\n      - Input: a ###\
      \ Verification block with only Type field, missing others\n      - Assert the\
      \ block is skipped (returns empty list)\n\n3. Run the tests:\n   ~/.pyenv/versions/3.11.*/bin/python\
      \ -m pytest tests/test_plan_orchestrator.py -v -k parse_verification\n   Fix\
      \ any failures before marking this task complete.\n\nFiles: tests/test_plan_orchestrator.py\n"
  - id: '3.2'
    name: Add unit tests for spec-aware build_validation_prompt
    agent: coder
    status: pending
    depends_on:
    - '2.2'
    - '3.1'
    description: "Add unit tests verifying that build_validation_prompt() includes\
      \ spec-aware\ncontext when SPEC_DIR is configured, and omits it when not configured.\n\
      \nReference: docs/plans/2026-02-18-spec-aware-validator-with-e2e-logging-design.md\n\
      \nSteps:\n1. Read tests/test_plan_orchestrator.py to understand existing test\
      \ patterns\n   for build_validation_prompt(). Look for any existing tests of\
      \ this function.\n\n2. Read scripts/plan-orchestrator.py to check the current\
      \ signature of\n   build_validation_prompt() and what imports/fixtures the tests\
      \ need.\n\n3. Add the following tests:\n\n   a. test_build_validation_prompt_includes_spec_context():\n\
      \      - Monkeypatch the module's SPEC_DIR to \"docs/specs/\"\n      - Monkeypatch\
      \ E2E_COMMAND to \"npx playwright test\"\n      - Create minimal task, section,\
      \ and TaskResult objects\n      - Call build_validation_prompt(task, section,\
      \ task_result, \"validator\")\n      - Assert the result contains \"Spec-Aware\
      \ Validation\"\n      - Assert the result contains \"docs/specs/\"\n      -\
      \ Assert the result contains \"npx playwright test\"\n\n   b. test_build_validation_prompt_omits_spec_when_unconfigured():\n\
      \      - Monkeypatch SPEC_DIR to \"\" (empty string)\n      - Call build_validation_prompt()\n\
      \      - Assert the result does NOT contain \"Spec-Aware Validation\"\n\n  \
      \ c. test_build_validation_prompt_still_has_standard_checks():\n      - Monkeypatch\
      \ SPEC_DIR to \"docs/specs/\"\n      - Call build_validation_prompt()\n    \
      \  - Assert the result still contains the BUILD_COMMAND\n      - Assert the\
      \ result still contains the TEST_COMMAND\n      - Assert the result still contains\
      \ \"Verdict: PASS\"\n\n4. Run the tests:\n   ~/.pyenv/versions/3.11.*/bin/python\
      \ -m pytest tests/test_plan_orchestrator.py -v -k spec\n   Fix any failures\
      \ before marking this task complete.\n\nFiles: tests/test_plan_orchestrator.py\n"
- id: phase-4
  name: Phase 4 - Plugin Version Bump
  status: pending
  tasks:
  - id: '4.1'
    name: Bump plugin version and update release notes
    agent: coder
    status: pending
    depends_on:
    - '2.4'
    description: "Bump the plugin version in plugin.json and update RELEASE-NOTES.md\n\
      for the spec-aware validator feature.\n\nSteps:\n1. Read plugin.json. Find the\
      \ current version number.\n2. Bump the minor version (this is a new feature).\n\
      3. Read RELEASE-NOTES.md. Add a new entry at the top for the new\n   version\
      \ with a summary:\n   - **Spec-aware validator**: Validator agent reads functional\
      \ spec\n     verification blocks and runs referenced E2E tests when spec files\
      \ are\n     changed. Results captured as timestamped JSON in logs/e2e/.\n  \
      \ - **E2E analyzer agent**: New on-demand agent for reviewing accumulated\n\
      \     E2E test logs to identify flaky tests, regressions, and trends.\n   -\
      \ **Verification block template**: Reference format for annotating\n     functional\
      \ specs with testable verification blocks.\n4. Git commit both files:\n   git\
      \ add plugin.json RELEASE-NOTES.md\n   git commit -m \"chore: bump version for\
      \ spec-aware-validator feature\"\n\nFiles: plugin.json, RELEASE-NOTES.md\n"
- id: phase-5
  name: Phase 5 - Final Verification
  status: pending
  tasks:
  - id: '5.1'
    name: Final verification - syntax, tests, and dry-run
    agent: code-reviewer
    status: pending
    depends_on:
    - '3.1'
    - '3.2'
    - '4.1'
    description: "Run all verification checks to confirm the feature is correctly\n\
      implemented and all tests pass.\n\nSteps:\n1. Check Python syntax for both scripts:\n\
      \   python3 -c \"import py_compile; py_compile.compile('scripts/auto-pipeline.py',\
      \ doraise=True); py_compile.compile('scripts/plan-orchestrator.py', doraise=True)\"\
      \n\n2. Run the full test suite:\n   ~/.pyenv/versions/3.11.*/bin/python -m pytest\
      \ tests/ -v\n\n3. Verify the new config constants exist in plan-orchestrator.py:\n\
      \   python3 -c \"\n   import importlib.util\n   spec = importlib.util.spec_from_file_location('po',\
      \ 'scripts/plan-orchestrator.py')\n   mod = importlib.util.module_from_spec(spec)\n\
      \   spec.loader.exec_module(mod)\n   assert hasattr(mod, 'SPEC_DIR'), 'SPEC_DIR\
      \ not found'\n   assert hasattr(mod, 'E2E_COMMAND'), 'E2E_COMMAND not found'\n\
      \   assert callable(mod.parse_verification_blocks), 'parse_verification_blocks\
      \ not callable'\n   print('All new constants and functions verified OK')\n \
      \  \"\n\n4. Verify the validator agent has spec-aware instructions:\n   grep\
      \ -c \"Spec-Aware\" .claude/agents/validator.md\n\n5. Verify the e2e-analyzer\
      \ agent exists:\n   test -f .claude/agents/e2e-analyzer.md && echo \"e2e-analyzer.md\
      \ exists\"\n\n6. Verify the verification block template exists:\n   test -f\
      \ docs/templates/verification-block.md && echo \"template exists\"\n\n7. Run\
      \ orchestrator dry-run to confirm no startup errors:\n   python3 scripts/plan-orchestrator.py\
      \ --plan .claude/plans/sample-plan.yaml --dry-run\n\n8. Run the fallback test\
      \ command:\n   python3 -m pytest tests/ 2>/dev/null || echo 'No test suite configured'\n\
      \nIf any check fails, report the specific failure with details.\n\nFiles: scripts/plan-orchestrator.py,\
      \ .claude/agents/validator.md,\n  .claude/agents/e2e-analyzer.md, docs/templates/verification-block.md,\n\
      \  tests/test_plan_orchestrator.py, plugin.json, RELEASE-NOTES.md\n"
