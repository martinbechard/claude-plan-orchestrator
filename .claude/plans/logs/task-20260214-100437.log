=== Claude Task Output ===
Timestamp: 2026-02-14T10:04:37.620335
Duration: 170.8s
Return code: 0
Stdout lines: 84
Stderr lines: 0
Cost: $1.6130
Tokens: 30 input / 8384 output / 2010211 cache_read / 61666 cache_create
Turns: 31
API time: 169839ms

=== STDOUT ===
{"type":"system","subtype":"hook_started","hook_id":"e4af3e44-1213-4f08-a654-b40f3321ba50","hook_name":"SessionStart:startup","hook_event":"SessionStart","uuid":"71c383ab-ecbf-42d0-b62c-d8c87d9cc551","session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3"}
{"type":"system","subtype":"hook_started","hook_id":"b0b39292-359c-49d9-815a-5410d80adcc3","hook_name":"SessionStart:startup","hook_event":"SessionStart","uuid":"a5de4d38-36e4-46c5-9fb7-21316ae3be8d","session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3"}
{"type":"system","subtype":"hook_response","hook_id":"e4af3e44-1213-4f08-a654-b40f3321ba50","hook_name":"SessionStart:startup","hook_event":"SessionStart","output":"{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"You are in 'explanatory' output style mode, where you should provide educational insights about the codebase as you help with the user's task.\\n\\nYou should be clear and educational, providing helpful explanations while remaining focused on the task. Balance educational content with task completion. When providing insights, you may exceed typical length constraints, but remain focused and relevant.\\n\\n## Insights\\nIn order to encourage learning, before and after writing code, always provide brief educational explanations about implementation choices using (with backticks):\\n\\\"`★ Insight ─────────────────────────────────────`\\n[2-3 key educational points]\\n`─────────────────────────────────────────────────`\\\"\\n\\nThese insights should be included in the conversation, not in the codebase. You should generally focus on interesting insights that are specific to the codebase or the code you just wrote, rather than general programming concepts. Do not wait until the end to provide insights. Provide them as you write code.\"\n  }\n}\n","stdout":"{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"You are in 'explanatory' output style mode, where you should provide educational insights about the codebase as you help with the user's task.\\n\\nYou should be clear and educational, providing helpful explanations while remaining focused on the task. Balance educational content with task completion. When providing insights, you may exceed typical length constraints, but remain focused and relevant.\\n\\n## Insights\\nIn order to encourage learning, before and after writing code, always provide brief educational explanations about implementation choices using (with backticks):\\n\\\"`★ Insight ─────────────────────────────────────`\\n[2-3 key educational points]\\n`─────────────────────────────────────────────────`\\\"\\n\\nThese insights should be included in the conversation, not in the codebase. You should generally focus on interesting insights that are specific to the codebase or the code you just wrote, rather than general programming concepts. Do not wait until the end to provide insights. Provide them as you write code.\"\n  }\n}\n","stderr":"","exit_code":0,"outcome":"success","uuid":"e078f8c3-537d-4e2c-9703-36fcadfadfbf","session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3"}
{"type":"system","subtype":"hook_response","hook_id":"b0b39292-359c-49d9-815a-5410d80adcc3","hook_name":"SessionStart:startup","hook_event":"SessionStart","output":"{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"<EXTREMELY_IMPORTANT>\\nYou have superpowers.\\n\\n**Below is the full content of your 'superpowers:using-superpowers' skill - your introduction to using skills. For all other skills, use the 'Skill' tool:**\\n\\n---\\nname: using-superpowers\\ndescription: Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions\\n---\\n\\n<EXTREMELY-IMPORTANT>\\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\\n\\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\\n\\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\\n</EXTREMELY-IMPORTANT>\\n\\n## How to Access Skills\\n\\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you—follow it directly. Never use the Read tool on skill files.\\n\\n**In other environments:** Check your platform's documentation for how skills are loaded.\\n\\n# Using Skills\\n\\n## The Rule\\n\\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\\n\\n```dot\\ndigraph skill_flow {\\n    \\\"User message received\\\" [shape=doublecircle];\\n    \\\"About to EnterPlanMode?\\\" [shape=doublecircle];\\n    \\\"Already brainstormed?\\\" [shape=diamond];\\n    \\\"Invoke brainstorming skill\\\" [shape=box];\\n    \\\"Might any skill apply?\\\" [shape=diamond];\\n    \\\"Invoke Skill tool\\\" [shape=box];\\n    \\\"Announce: 'Using [skill] to [purpose]'\\\" [shape=box];\\n    \\\"Has checklist?\\\" [shape=diamond];\\n    \\\"Create TodoWrite todo per item\\\" [shape=box];\\n    \\\"Follow skill exactly\\\" [shape=box];\\n    \\\"Respond (including clarifications)\\\" [shape=doublecircle];\\n\\n    \\\"About to EnterPlanMode?\\\" -> \\\"Already brainstormed?\\\";\\n    \\\"Already brainstormed?\\\" -> \\\"Invoke brainstorming skill\\\" [label=\\\"no\\\"];\\n    \\\"Already brainstormed?\\\" -> \\\"Might any skill apply?\\\" [label=\\\"yes\\\"];\\n    \\\"Invoke brainstorming skill\\\" -> \\\"Might any skill apply?\\\";\\n\\n    \\\"User message received\\\" -> \\\"Might any skill apply?\\\";\\n    \\\"Might any skill apply?\\\" -> \\\"Invoke Skill tool\\\" [label=\\\"yes, even 1%\\\"];\\n    \\\"Might any skill apply?\\\" -> \\\"Respond (including clarifications)\\\" [label=\\\"definitely not\\\"];\\n    \\\"Invoke Skill tool\\\" -> \\\"Announce: 'Using [skill] to [purpose]'\\\";\\n    \\\"Announce: 'Using [skill] to [purpose]'\\\" -> \\\"Has checklist?\\\";\\n    \\\"Has checklist?\\\" -> \\\"Create TodoWrite todo per item\\\" [label=\\\"yes\\\"];\\n    \\\"Has checklist?\\\" -> \\\"Follow skill exactly\\\" [label=\\\"no\\\"];\\n    \\\"Create TodoWrite todo per item\\\" -> \\\"Follow skill exactly\\\";\\n}\\n```\\n\\n## Red Flags\\n\\nThese thoughts mean STOP—you're rationalizing:\\n\\n| Thought | Reality |\\n|---------|---------|\\n| \\\"This is just a simple question\\\" | Questions are tasks. Check for skills. |\\n| \\\"I need more context first\\\" | Skill check comes BEFORE clarifying questions. |\\n| \\\"Let me explore the codebase first\\\" | Skills tell you HOW to explore. Check first. |\\n| \\\"I can check git/files quickly\\\" | Files lack conversation context. Check for skills. |\\n| \\\"Let me gather information first\\\" | Skills tell you HOW to gather information. |\\n| \\\"This doesn't need a formal skill\\\" | If a skill exists, use it. |\\n| \\\"I remember this skill\\\" | Skills evolve. Read current version. |\\n| \\\"This doesn't count as a task\\\" | Action = task. Check for skills. |\\n| \\\"The skill is overkill\\\" | Simple things become complex. Use it. |\\n| \\\"I'll just do this one thing first\\\" | Check BEFORE doing anything. |\\n| \\\"This feels productive\\\" | Undisciplined action wastes time. Skills prevent this. |\\n| \\\"I know what that means\\\" | Knowing the concept ≠ using the skill. Invoke it. |\\n\\n## Skill Priority\\n\\nWhen multiple skills could apply, use this order:\\n\\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\\n\\n\\\"Let's build X\\\" → brainstorming first, then implementation skills.\\n\\\"Fix this bug\\\" → debugging first, then domain-specific skills.\\n\\n## Skill Types\\n\\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\\n\\n**Flexible** (patterns): Adapt principles to context.\\n\\nThe skill itself tells you which.\\n\\n## User Instructions\\n\\nInstructions say WHAT, not HOW. \\\"Add X\\\" or \\\"Fix Y\\\" doesn't mean skip workflows.\\n\\n\\n</EXTREMELY_IMPORTANT>\"\n  }\n}\n","stdout":"{\n  \"hookSpecificOutput\": {\n    \"hookEventName\": \"SessionStart\",\n    \"additionalContext\": \"<EXTREMELY_IMPORTANT>\\nYou have superpowers.\\n\\n**Below is the full content of your 'superpowers:using-superpowers' skill - your introduction to using skills. For all other skills, use the 'Skill' tool:**\\n\\n---\\nname: using-superpowers\\ndescription: Use when starting any conversation - establishes how to find and use skills, requiring Skill tool invocation before ANY response including clarifying questions\\n---\\n\\n<EXTREMELY-IMPORTANT>\\nIf you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.\\n\\nIF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.\\n\\nThis is not negotiable. This is not optional. You cannot rationalize your way out of this.\\n</EXTREMELY-IMPORTANT>\\n\\n## How to Access Skills\\n\\n**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you—follow it directly. Never use the Read tool on skill files.\\n\\n**In other environments:** Check your platform's documentation for how skills are loaded.\\n\\n# Using Skills\\n\\n## The Rule\\n\\n**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.\\n\\n```dot\\ndigraph skill_flow {\\n    \\\"User message received\\\" [shape=doublecircle];\\n    \\\"About to EnterPlanMode?\\\" [shape=doublecircle];\\n    \\\"Already brainstormed?\\\" [shape=diamond];\\n    \\\"Invoke brainstorming skill\\\" [shape=box];\\n    \\\"Might any skill apply?\\\" [shape=diamond];\\n    \\\"Invoke Skill tool\\\" [shape=box];\\n    \\\"Announce: 'Using [skill] to [purpose]'\\\" [shape=box];\\n    \\\"Has checklist?\\\" [shape=diamond];\\n    \\\"Create TodoWrite todo per item\\\" [shape=box];\\n    \\\"Follow skill exactly\\\" [shape=box];\\n    \\\"Respond (including clarifications)\\\" [shape=doublecircle];\\n\\n    \\\"About to EnterPlanMode?\\\" -> \\\"Already brainstormed?\\\";\\n    \\\"Already brainstormed?\\\" -> \\\"Invoke brainstorming skill\\\" [label=\\\"no\\\"];\\n    \\\"Already brainstormed?\\\" -> \\\"Might any skill apply?\\\" [label=\\\"yes\\\"];\\n    \\\"Invoke brainstorming skill\\\" -> \\\"Might any skill apply?\\\";\\n\\n    \\\"User message received\\\" -> \\\"Might any skill apply?\\\";\\n    \\\"Might any skill apply?\\\" -> \\\"Invoke Skill tool\\\" [label=\\\"yes, even 1%\\\"];\\n    \\\"Might any skill apply?\\\" -> \\\"Respond (including clarifications)\\\" [label=\\\"definitely not\\\"];\\n    \\\"Invoke Skill tool\\\" -> \\\"Announce: 'Using [skill] to [purpose]'\\\";\\n    \\\"Announce: 'Using [skill] to [purpose]'\\\" -> \\\"Has checklist?\\\";\\n    \\\"Has checklist?\\\" -> \\\"Create TodoWrite todo per item\\\" [label=\\\"yes\\\"];\\n    \\\"Has checklist?\\\" -> \\\"Follow skill exactly\\\" [label=\\\"no\\\"];\\n    \\\"Create TodoWrite todo per item\\\" -> \\\"Follow skill exactly\\\";\\n}\\n```\\n\\n## Red Flags\\n\\nThese thoughts mean STOP—you're rationalizing:\\n\\n| Thought | Reality |\\n|---------|---------|\\n| \\\"This is just a simple question\\\" | Questions are tasks. Check for skills. |\\n| \\\"I need more context first\\\" | Skill check comes BEFORE clarifying questions. |\\n| \\\"Let me explore the codebase first\\\" | Skills tell you HOW to explore. Check first. |\\n| \\\"I can check git/files quickly\\\" | Files lack conversation context. Check for skills. |\\n| \\\"Let me gather information first\\\" | Skills tell you HOW to gather information. |\\n| \\\"This doesn't need a formal skill\\\" | If a skill exists, use it. |\\n| \\\"I remember this skill\\\" | Skills evolve. Read current version. |\\n| \\\"This doesn't count as a task\\\" | Action = task. Check for skills. |\\n| \\\"The skill is overkill\\\" | Simple things become complex. Use it. |\\n| \\\"I'll just do this one thing first\\\" | Check BEFORE doing anything. |\\n| \\\"This feels productive\\\" | Undisciplined action wastes time. Skills prevent this. |\\n| \\\"I know what that means\\\" | Knowing the concept ≠ using the skill. Invoke it. |\\n\\n## Skill Priority\\n\\nWhen multiple skills could apply, use this order:\\n\\n1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task\\n2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution\\n\\n\\\"Let's build X\\\" → brainstorming first, then implementation skills.\\n\\\"Fix this bug\\\" → debugging first, then domain-specific skills.\\n\\n## Skill Types\\n\\n**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.\\n\\n**Flexible** (patterns): Adapt principles to context.\\n\\nThe skill itself tells you which.\\n\\n## User Instructions\\n\\nInstructions say WHAT, not HOW. \\\"Add X\\\" or \\\"Fix Y\\\" doesn't mean skip workflows.\\n\\n\\n</EXTREMELY_IMPORTANT>\"\n  }\n}\n","stderr":"","exit_code":0,"outcome":"success","uuid":"f4ae1d33-79c7-4545-9de1-c2cfa6ba89d0","session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3"}
{"type":"system","subtype":"init","cwd":"/Users/martinbechard/dev/claude-plan-orchestrator","session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","tools":["Task","TaskOutput","Bash","Glob","Grep","ExitPlanMode","Read","Edit","Write","NotebookEdit","WebFetch","TodoWrite","WebSearch","TaskStop","AskUserQuestion","Skill","EnterPlanMode","ToolSearch","mcp__plugin_greptile_greptile__list_custom_context","mcp__plugin_greptile_greptile__get_custom_context","mcp__plugin_greptile_greptile__search_custom_context","mcp__plugin_greptile_greptile__list_merge_requests","mcp__plugin_greptile_greptile__list_pull_requests","mcp__plugin_greptile_greptile__get_merge_request","mcp__plugin_greptile_greptile__list_merge_request_comments","mcp__plugin_greptile_greptile__list_code_reviews","mcp__plugin_greptile_greptile__get_code_review","mcp__plugin_greptile_greptile__trigger_code_review","mcp__plugin_greptile_greptile__search_greptile_comments","mcp__plugin_greptile_greptile__create_custom_context"],"mcp_servers":[{"name":"plugin:github:github","status":"failed"},{"name":"claude.ai Canva","status":"needs-auth"},{"name":"claude.ai Notion","status":"needs-auth"},{"name":"plugin:greptile:greptile","status":"connected"}],"model":"claude-opus-4-6","permissionMode":"bypassPermissions","slash_commands":["keybindings-help","debug","implement","coding-rules","implement","feature-dev:feature-dev","code-review:code-review","commit-commands:commit-push-pr","commit-commands:clean_gone","commit-commands:commit","agent-sdk-dev:new-sdk-app","plugin-dev:create-plugin","hookify:help","hookify:list","hookify:configure","hookify:hookify","ralph-loop:help","ralph-loop:cancel-ralph","ralph-loop:ralph-loop","superpowers:execute-plan","superpowers:write-plan","superpowers:brainstorm","frontend-design:frontend-design","plugin-dev:command-development","plugin-dev:skill-development","plugin-dev:plugin-settings","plugin-dev:plugin-structure","plugin-dev:hook-development","plugin-dev:mcp-integration","plugin-dev:agent-development","hookify:writing-rules","superpowers:using-git-worktrees","superpowers:test-driven-development","superpowers:systematic-debugging","superpowers:using-superpowers","superpowers:dispatching-parallel-agents","superpowers:executing-plans","superpowers:finishing-a-development-branch","superpowers:brainstorming","superpowers:writing-plans","superpowers:requesting-code-review","superpowers:receiving-code-review","superpowers:writing-skills","superpowers:verification-before-completion","superpowers:subagent-driven-development","compact","context","cost","init","pr-comments","release-notes","review","security-review","insights"],"apiKeySource":"none","claude_code_version":"2.1.42","output_style":"default","agents":["Bash","general-purpose","statusline-setup","Explore","Plan","feature-dev:code-reviewer","feature-dev:code-explorer","feature-dev:code-architect","agent-sdk-dev:agent-sdk-verifier-ts","agent-sdk-dev:agent-sdk-verifier-py","plugin-dev:agent-creator","plugin-dev:skill-reviewer","plugin-dev:plugin-validator","hookify:conversation-analyzer","superpowers:code-reviewer","code-reviewer","issue-verifier","systems-designer","ux-designer","validator","planner","coder"],"skills":["keybindings-help","debug","implement","coding-rules","superpowers:execute-plan","superpowers:write-plan","superpowers:brainstorm","frontend-design:frontend-design","plugin-dev:command-development","plugin-dev:skill-development","plugin-dev:plugin-settings","plugin-dev:plugin-structure","plugin-dev:hook-development","plugin-dev:mcp-integration","plugin-dev:agent-development","hookify:writing-rules","superpowers:using-git-worktrees","superpowers:test-driven-development","superpowers:systematic-debugging","superpowers:using-superpowers","superpowers:dispatching-parallel-agents","superpowers:executing-plans","superpowers:finishing-a-development-branch","superpowers:brainstorming","superpowers:writing-plans","superpowers:requesting-code-review","superpowers:receiving-code-review","superpowers:writing-skills","superpowers:verification-before-completion","superpowers:subagent-driven-development"],"plugins":[{"name":"frontend-design","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/frontend-design/2cd88e7947b7"},{"name":"github","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/github/2cd88e7947b7"},{"name":"feature-dev","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/feature-dev/2cd88e7947b7"},{"name":"code-review","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/code-review/2cd88e7947b7"},{"name":"commit-commands","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/commit-commands/2cd88e7947b7"},{"name":"typescript-lsp","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/typescript-lsp/1.0.0"},{"name":"agent-sdk-dev","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/agent-sdk-dev/2cd88e7947b7"},{"name":"pyright-lsp","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/pyright-lsp/1.0.0"},{"name":"explanatory-output-style","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/explanatory-output-style/2cd88e7947b7"},{"name":"plugin-dev","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/plugin-dev/2cd88e7947b7"},{"name":"hookify","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/hookify/2cd88e7947b7"},{"name":"greptile","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/greptile/2cd88e7947b7"},{"name":"ralph-loop","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/ralph-loop/2cd88e7947b7"},{"name":"superpowers","path":"/Users/martinbechard/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.0"}],"uuid":"a5df4910-edb8-4d0f-a6ce-db267c5a7b64","fast_mode_state":"off"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Pd3mhHBsDiEicYhPQgfQeN","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nI'll start by reading the necessary files to understand the codebase before making changes."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":12268,"cache_read_input_tokens":20419,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12268},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b8387687-71f9-4519-a05b-a428ca0d567e"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Pd3mhHBsDiEicYhPQgfQeN","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01433u7ndeuJiobcssbUVsqq","name":"Skill","input":{"skill":"coding-rules"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":12268,"cache_read_input_tokens":20419,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":12268},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"d7150092-65be-43b9-8731-a8c24fe3bf20"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","tool_use_id":"toolu_01433u7ndeuJiobcssbUVsqq","content":"Launching skill: coding-rules"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"6c5295d8-9e6a-41ee-a94f-1e2d8040ca87","tool_use_result":{"success":true,"commandName":"coding-rules"}}
{"type":"user","message":{"role":"user","content":[{"type":"text","text":"Base directory for this skill: /Users/martinbechard/dev/claude-plan-orchestrator/.claude/skills/coding-rules\n\n# Coding Rules (Summary)\n\nThis skill provides a condensed overview of the project's coding standards. Each section\nbelow summarizes a rule category. For the full rules with rationale (the BECAUSE chains)\nand examples, read **CODING-RULES.md** at the project root.\n\n## Rule 0: File Headers and Design Traceability\n\nEvery source file must include a header comment with the file path, a one-line purpose\nsummary, and a reference to the relevant design document. Before modifying code, verify\nchanges against the design document referenced in the header. Design documents are the\nsingle source of truth for module behavior; keep them synchronized with the code.\n\n## Rule 1: Naming Conventions\n\nUse PascalCase for classes, interfaces, types, and React components. Use camelCase for\nvariables, functions, methods, and utility files. Use ALL_CAPS_SNAKE_CASE for manifest\nconstants. Use kebab-case for configuration files. File names must match their primary\nclass or component. Names must be clear, descriptive, and follow Command-Query Separation\n(nouns for queries, verbs for mutations).\n\n## Rule 2: File Organization and Imports\n\nOrganize files into standard directories (src/, scripts/, docs/, tests/). Separate shared\ncontracts (interfaces, types, constants) from implementation. Files exceeding 200 lines\nshould be refactored into a module folder with an entry point that exports only the public\nAPI. Entry points must contain only import/export statements. Organize imports as: external\nlibraries, project aliases, relative imports. Remove unused imports. Avoid circular\ndependencies.\n\n## Rule 3: Code Structure and Readability\n\nMethods should not exceed 30-40 lines; extract complex logic into helpers. Classes should\nnot exceed 300 lines. Functions with more than two parameters must use a parameter object.\nPrioritize code clarity over premature abstraction. Focus on minimal, necessary changes;\navoid over-engineering.\n\n## Rule 4: Type Safety\n\nNever use the any type; create proper typed interfaces. Use interface for contracts, type\nfor data shapes and unions, class when behavior or state is required. Avoid primitive\nobsession; use domain-specific types. Never use literal magic numbers or strings; define\nmanifest constants at the top of the file or in a constants module.\n\n## Rule 5: Coupling and Cohesion\n\nClasses must have a single responsibility (SRP). Methods must perform a single logical\noperation. Depend on interfaces rather than concrete implementations. Do not access private\nmembers of other classes. Avoid Feature Envy (move methods to where the data lives).\nUtility functions used by only one class should be private to that class.\n\n## Rule 6: Error Handling\n\nNever use empty catch blocks; always log or re-throw. Do not use exceptions for control\nflow. Provide clear error messages with context (what was attempted, which values were\ninvolved). Include variable names alongside values in log statements.\n\n## Rule 7: Comments and Documentation\n\nEvery exported symbol must have a doc comment explaining its purpose. Write comments to\nexplain why, not what. Remove commented-out code (use version control). Keep comments\naccurate and up-to-date. Avoid excessive comments; refactor for clarity instead. Remove\nTODO/FIXME comments before task completion; use the YAML plan to track remaining work.\n\n## Rule 11: Test Discipline\n\nRun related tests after any code change. Failing tests are your responsibility; fix them\nimmediately. TypeScript errors in test files count as broken tests. When splitting large\ntest suites, migrate incrementally (one group at a time, verify, continue).\n\n## Rule 12: AI-Specific Discipline\n\nNever remove existing functionality when asked to simplify. Do not add features or\nimprovements beyond what was asked. Show actual state honestly (null, empty, not configured);\nnever invent fallback data. Never defer work because a file is too large; split and\nintegrate immediately. Commit frequently; uncommitted work is lost when the session ends.\n\n---\n\nFor the full rules with rationale, examples, and additional categories (conditional logic,\nUI feedback, build management), read **CODING-RULES.md** at the project root.\n"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"92434d16-7e08-4140-9906-f1b5f72e19de","isSynthetic":true}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CHqQSP4HxQjdz6YGFp7NUB","type":"message","role":"assistant","content":[{"type":"text","text":"\n\nNow let me read the required files in parallel."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1061,"cache_read_input_tokens":32687,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1061},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"bd147310-d13e-4e5d-a648-c7f697f7caf8"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CHqQSP4HxQjdz6YGFp7NUB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EXHtApD8WP88hYtqQPKTzm","name":"Read","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1061,"cache_read_input_tokens":32687,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1061},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"6f495a59-91e6-4ed3-ac0b-2427296c8c44"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EXHtApD8WP88hYtqQPKTzm","type":"tool_result","content":"     1→#!/usr/bin/env -S python3 -u\n     2→\"\"\"\n     3→Auto-Pipeline: Automated backlog processing for Claude Code.\n     4→\n     5→Monitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\n     6→creates implementation plans via Claude, executes them via the plan\n     7→orchestrator, and archives completed items.\n     8→\n     9→Usage:\n    10→    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n    11→\n    12→Copyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n    13→\"\"\"\n    14→\n    15→import argparse\n    16→import json\n    17→import os\n    18→import re\n    19→import shutil\n    20→import signal\n    21→import subprocess\n    22→import sys\n    23→import termios\n    24→import threading\n    25→import time\n    26→from dataclasses import dataclass, field\n    27→from datetime import datetime, timedelta\n    28→from pathlib import Path\n    29→from typing import Optional\n    30→from zoneinfo import ZoneInfo\n    31→\n    32→import yaml\n    33→\n    34→try:\n    35→    from watchdog.observers import Observer\n    36→    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\n    37→except ImportError:\n    38→    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    39→    sys.exit(1)\n    40→\n    41→# ─── Configuration ────────────────────────────────────────────────────\n    42→\n    43→ORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\n    44→DEFAULT_DEV_SERVER_PORT = 3000\n    45→DEFAULT_BUILD_COMMAND = \"pnpm run build\"\n    46→DEFAULT_TEST_COMMAND = \"pnpm test\"\n    47→DEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\n    48→DEFAULT_AGENTS_DIR = \".claude/agents/\"\n    49→\n    50→DEFECT_DIR = \"docs/defect-backlog\"\n    51→FEATURE_DIR = \"docs/feature-backlog\"\n    52→COMPLETED_SUBDIR = \"completed\"\n    53→PLANS_DIR = \".claude/plans\"\n    54→DESIGN_DIR = \"docs/plans\"\n    55→STOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\n    56→SAFETY_SCAN_INTERVAL_SECONDS = 60\n    57→PLAN_CREATION_TIMEOUT_SECONDS = 600\n    58→CHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\n    59→RATE_LIMIT_BUFFER_SECONDS = 30\n    60→RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\n    61→\n    62→\n    63→def load_orchestrator_config() -> dict:\n    64→    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n    65→\n    66→    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    67→    \"\"\"\n    68→    try:\n    69→        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n    70→            config = yaml.safe_load(f)\n    71→        return config if isinstance(config, dict) else {}\n    72→    except (IOError, yaml.YAMLError):\n    73→        return {}\n    74→\n    75→\n    76→_config = load_orchestrator_config()\n    77→DEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\n    78→BUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\n    79→TEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\n    80→DEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\n    81→AGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n    82→\n    83→# Pattern matching backlog item slugs (NN-slug-name format)\n    84→BACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n    85→\n    86→# Status patterns in backlog files that indicate already-processed items\n    87→COMPLETED_STATUS_PATTERN = re.compile(\n    88→    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n    89→)\n    90→\n    91→# Rate limit detection (same pattern as plan-orchestrator.py)\n    92→RATE_LIMIT_PATTERN = re.compile(\n    93→    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    94→    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    95→    r\"(?:\\s*\\(([^)]+)\\))?\",\n    96→    re.IGNORECASE | re.DOTALL,\n    97→)\n    98→MONTH_NAMES = {\n    99→    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n   100→    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n   101→    \"may\": 5, \"jun\": 6, \"june\": 6,\n   102→    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n   103→    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n   104→    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n   105→}\n   106→\n   107→# Known locations for the claude binary\n   108→CLAUDE_BINARY_SEARCH_PATHS = [\n   109→    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n   110→    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n   111→]\n   112→\n   113→# Global state\n   114→VERBOSE = False\n   115→CLAUDE_CMD: list[str] = [\"claude\"]\n   116→_saved_terminal_settings = None  # Saved termios settings for restoration\n   117→\n   118→# ─── Terminal Management ─────────────────────────────────────────────\n   119→\n   120→\n   121→def save_terminal_settings() -> None:\n   122→    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n   123→    global _saved_terminal_settings\n   124→    try:\n   125→        if sys.stdin.isatty():\n   126→            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n   127→    except (termios.error, OSError):\n   128→        pass\n   129→\n   130→\n   131→def restore_terminal_settings() -> None:\n   132→    \"\"\"Restore terminal settings after child process exits or is killed.\n   133→\n   134→    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n   135→    settings aren't restored, leaving the terminal without echo and in a\n   136→    broken state. This fixes that.\n   137→    \"\"\"\n   138→    global _saved_terminal_settings\n   139→    if _saved_terminal_settings is None:\n   140→        return\n   141→    try:\n   142→        if sys.stdin.isatty():\n   143→            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n   144→    except (termios.error, OSError):\n   145→        pass\n   146→\n   147→\n   148→# ─── Logging ──────────────────────────────────────────────────────────\n   149→\n   150→\n   151→_PIPELINE_PID = os.getpid()\n   152→\n   153→\n   154→def log(message: str) -> None:\n   155→    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n   156→    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n   157→    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n   158→\n   159→\n   160→def verbose_log(message: str) -> None:\n   161→    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n   162→    if VERBOSE:\n   163→        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n   164→        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n   165→\n   166→\n   167→# ─── Claude Binary Resolution ────────────────────────────────────────\n   168→\n   169→\n   170→def resolve_claude_binary() -> list[str]:\n   171→    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n   172→    claude_path = shutil.which(\"claude\")\n   173→    if claude_path:\n   174→        return [claude_path]\n   175→\n   176→    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n   177→        if os.path.isfile(search_path):\n   178→            node_path = shutil.which(\"node\")\n   179→            if node_path:\n   180→                return [node_path, search_path]\n   181→\n   182→    npx_path = shutil.which(\"npx\")\n   183→    if npx_path:\n   184→        return [npx_path, \"@anthropic-ai/claude-code\"]\n   185→\n   186→    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n   187→    return [\"claude\"]\n   188→\n   189→\n   190→# ─── Output Streaming ────────────────────────────────────────────────\n   191→\n   192→\n   193→class OutputCollector:\n   194→    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n   195→\n   196→    def __init__(self):\n   197→        self.lines: list[str] = []\n   198→        self.bytes_received: int = 0\n   199→        self.line_count: int = 0\n   200→\n   201→    def add_line(self, line: str) -> None:\n   202→        self.lines.append(line)\n   203→        self.bytes_received += len(line.encode(\"utf-8\"))\n   204→        self.line_count += 1\n   205→\n   206→    def get_output(self) -> str:\n   207→        return \"\".join(self.lines)\n   208→\n   209→\n   210→def stream_output(\n   211→    pipe, prefix: str, collector: OutputCollector, show_full: bool\n   212→) -> None:\n   213→    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n   214→    try:\n   215→        for line in iter(pipe.readline, \"\"):\n   216→            if line:\n   217→                collector.add_line(line)\n   218→                if show_full:\n   219→                    ts = datetime.now().strftime(\"%H:%M:%S\")\n   220→                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n   221→    except Exception as e:\n   222→        if VERBOSE:\n   223→            verbose_log(f\"Error streaming {prefix}: {e}\")\n   224→\n   225→\n   226→# ─── Rate Limit Handling ─────────────────────────────────────────────\n   227→\n   228→\n   229→def parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n   230→    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n   231→    match = RATE_LIMIT_PATTERN.search(output)\n   232→    if not match:\n   233→        return None\n   234→\n   235→    date_str = match.group(1).strip()\n   236→    time_str = match.group(2).strip()\n   237→    tz_str = match.group(3)\n   238→\n   239→    try:\n   240→        parts = date_str.split()\n   241→        if len(parts) != 2:\n   242→            return None\n   243→        month_name, day_str = parts\n   244→        month = MONTH_NAMES.get(month_name.lower())\n   245→        if not month:\n   246→            return None\n   247→        day = int(day_str)\n   248→\n   249→        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n   250→        if not time_match:\n   251→            return None\n   252→        hour = int(time_match.group(1))\n   253→        minute = int(time_match.group(2) or \"0\")\n   254→        ampm = time_match.group(3).lower()\n   255→        if ampm == \"pm\" and hour != 12:\n   256→            hour += 12\n   257→        elif ampm == \"am\" and hour == 12:\n   258→            hour = 0\n   259→\n   260→        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n   261→        now = datetime.now(tz)\n   262→        year = now.year\n   263→        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n   264→\n   265→        if reset_time < now:\n   266→            reset_time = reset_time.replace(year=year + 1)\n   267→\n   268→        return reset_time\n   269→    except (ValueError, KeyError):\n   270→        return None\n   271→\n   272→\n   273→def check_rate_limit(output: str) -> Optional[float]:\n   274→    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n   275→    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n   276→        return None\n   277→\n   278→    reset_time = parse_rate_limit_reset_time(output)\n   279→    if reset_time:\n   280→        now = datetime.now(reset_time.tzinfo)\n   281→        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n   282→        return max(wait_seconds, 0)\n   283→\n   284→    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n   285→\n   286→\n   287→# ─── Stop Semaphore ──────────────────────────────────────────────────\n   288→\n   289→\n   290→def check_stop_requested() -> bool:\n   291→    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n   292→    return os.path.exists(STOP_SEMAPHORE_PATH)\n   293→\n   294→\n   295→def clear_stop_semaphore() -> None:\n   296→    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n   297→    if os.path.exists(STOP_SEMAPHORE_PATH):\n   298→        os.remove(STOP_SEMAPHORE_PATH)\n   299→        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n   300→\n   301→\n   302→# ─── Backlog Scanning ────────────────────────────────────────────────\n   303→\n   304→\n   305→@dataclass\n   306→class BacklogItem:\n   307→    \"\"\"A defect or feature backlog item.\"\"\"\n   308→    path: str\n   309→    name: str\n   310→    slug: str\n   311→    item_type: str  # \"defect\" or \"feature\"\n   312→\n   313→    @property\n   314→    def display_name(self) -> str:\n   315→        return f\"{self.item_type}: {self.name}\"\n   316→\n   317→\n   318→def is_item_completed(filepath: str) -> bool:\n   319→    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n   320→    try:\n   321→        with open(filepath, \"r\") as f:\n   322→            content = f.read(2000)  # Only need the header\n   323→        return bool(COMPLETED_STATUS_PATTERN.search(content))\n   324→    except (IOError, OSError):\n   325→        return False\n   326→\n   327→\n   328→def scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n   329→    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n   330→    items: list[BacklogItem] = []\n   331→    dir_path = Path(directory)\n   332→\n   333→    if not dir_path.exists():\n   334→        return items\n   335→\n   336→    for md_file in sorted(dir_path.glob(\"*.md\")):\n   337→        if md_file.name.startswith(\".\"):\n   338→            continue\n   339→        if is_item_completed(str(md_file)):\n   340→            verbose_log(f\"Skipping completed item: {md_file.name}\")\n   341→            continue\n   342→\n   343→        slug = md_file.stem  # filename without .md\n   344→        items.append(BacklogItem(\n   345→            path=str(md_file),\n   346→            name=md_file.stem.replace(\"-\", \" \").title(),\n   347→            slug=slug,\n   348→            item_type=item_type,\n   349→        ))\n   350→\n   351→    return items\n   352→\n   353→\n   354→def parse_dependencies(filepath: str) -> list[str]:\n   355→    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n   356→\n   357→    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n   358→    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n   359→    scaffold') that don't match the NN-slug pattern are silently skipped.\n   360→\n   361→    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n   362→    \"\"\"\n   363→    try:\n   364→        with open(filepath, \"r\") as f:\n   365→            content = f.read()\n   366→    except (IOError, OSError):\n   367→        return []\n   368→\n   369→    deps: list[str] = []\n   370→    in_deps_section = False\n   371→\n   372→    for line in content.splitlines():\n   373→        stripped = line.strip()\n   374→\n   375→        # Detect the Dependencies heading\n   376→        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n   377→            in_deps_section = True\n   378→            continue\n   379→\n   380→        # Stop at the next heading\n   381→        if in_deps_section and stripped.startswith(\"##\"):\n   382→            break\n   383→\n   384→        if not in_deps_section:\n   385→            continue\n   386→\n   387→        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n   388→        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n   389→        if not list_match:\n   390→            continue\n   391→\n   392→        raw = list_match.group(1).strip()\n   393→        # Extract the filename portion (before any parenthetical comment or space)\n   394→        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n   395→        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n   396→        # Strip .md extension if present\n   397→        slug = filename_part.removesuffix(\".md\").strip()\n   398→\n   399→        # Only include items matching the NN-slug backlog pattern\n   400→        if BACKLOG_SLUG_PATTERN.match(slug):\n   401→            deps.append(slug)\n   402→        else:\n   403→            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n   404→\n   405→    return deps\n   406→\n   407→\n   408→def completed_slugs() -> set[str]:\n   409→    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n   410→    slugs: set[str] = set()\n   411→\n   412→    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n   413→        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n   414→        if not completed_dir.exists():\n   415→            continue\n   416→        for md_file in completed_dir.glob(\"*.md\"):\n   417→            slugs.add(md_file.stem)\n   418→\n   419→    return slugs\n   420→\n   421→\n   422→def scan_all_backlogs() -> list[BacklogItem]:\n   423→    \"\"\"Scan both backlog directories with dependency filtering.\n   424→\n   425→    Returns defects first, then features. Items whose dependencies are not\n   426→    all present in the completed/ directories are filtered out.\n   427→    \"\"\"\n   428→    defects = scan_directory(DEFECT_DIR, \"defect\")\n   429→    features = scan_directory(FEATURE_DIR, \"feature\")\n   430→    all_items = defects + features\n   431→\n   432→    # Build the set of completed slugs for dependency resolution\n   433→    done = completed_slugs()\n   434→    verbose_log(f\"Completed slugs: {done}\")\n   435→\n   436→    # Filter items with unsatisfied dependencies\n   437→    ready: list[BacklogItem] = []\n   438→    for item in all_items:\n   439→        deps = parse_dependencies(item.path)\n   440→        if not deps:\n   441→            ready.append(item)\n   442→            continue\n   443→\n   444→        unsatisfied = [d for d in deps if d not in done]\n   445→        if unsatisfied:\n   446→            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n   447→        else:\n   448→            ready.append(item)\n   449→\n   450→    return ready\n   451→\n   452→\n   453→# ─── Filesystem Watcher ──────────────────────────────────────────────\n   454→\n   455→\n   456→class BacklogWatcher(FileSystemEventHandler):\n   457→    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n   458→\n   459→    def __init__(self, event_callback):\n   460→        super().__init__()\n   461→        self.event_callback = event_callback\n   462→\n   463→    def on_created(self, event):\n   464→        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n   465→            # Ignore files in completed/ subdirectory\n   466→            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n   467→                verbose_log(f\"File created: {event.src_path}\")\n   468→                self.event_callback()\n   469→\n   470→    def on_modified(self, event):\n   471→        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n   472→            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n   473→                verbose_log(f\"File modified: {event.src_path}\")\n   474→                self.event_callback()\n   475→\n   476→\n   477→# ─── Child Process Runner ────────────────────────────────────────────\n   478→\n   479→\n   480→@dataclass\n   481→class ProcessResult:\n   482→    \"\"\"Result of a child process execution.\"\"\"\n   483→    success: bool\n   484→    exit_code: int\n   485→    stdout: str\n   486→    stderr: str\n   487→    duration_seconds: float\n   488→    rate_limited: bool = False\n   489→    rate_limit_wait: Optional[float] = None\n   490→\n   491→\n   492→# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\n   493→MAX_PLAN_NAME_LENGTH = 50\n   494→\n   495→\n   496→class SessionUsageTracker:\n   497→    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n   498→\n   499→    def __init__(self) -> None:\n   500→        self.work_item_costs: list[dict] = []\n   501→        self.total_cost_usd: float = 0.0\n   502→        self.total_input_tokens: int = 0\n   503→        self.total_output_tokens: int = 0\n   504→\n   505→    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n   506→        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n   507→        try:\n   508→            with open(report_path) as f:\n   509→                report = json.load(f)\n   510→            total = report.get(\"total\", {})\n   511→            cost = total.get(\"cost_usd\", 0.0)\n   512→            self.total_cost_usd += cost\n   513→            self.total_input_tokens += total.get(\"input_tokens\", 0)\n   514→            self.total_output_tokens += total.get(\"output_tokens\", 0)\n   515→            self.work_item_costs.append({\n   516→                \"name\": work_item_name,\n   517→                \"cost_usd\": cost,\n   518→            })\n   519→            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n   520→        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n   521→            pass  # Report not available, skip silently\n   522→\n   523→    def format_session_summary(self) -> str:\n   524→        \"\"\"Format session-level usage summary.\"\"\"\n   525→        lines = [\"\\n=== Pipeline Session Usage ===\"]\n   526→        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n   527→        lines.append(\n   528→            f\"Total tokens: {self.total_input_tokens:,} input / \"\n   529→            f\"{self.total_output_tokens:,} output\"\n   530→        )\n   531→        if self.work_item_costs:\n   532→            lines.append(\"Per work item:\")\n   533→            for item in self.work_item_costs:\n   534→                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n   535→        return \"\\n\".join(lines)\n   536→\n   537→    def write_session_report(self) -> Optional[str]:\n   538→        \"\"\"Write a session summary JSON file.\"\"\"\n   539→        if not self.work_item_costs:\n   540→            return None\n   541→        log_dir = Path(\".claude/plans/logs\")\n   542→        log_dir.mkdir(parents=True, exist_ok=True)\n   543→        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n   544→        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n   545→        report = {\n   546→            \"session_timestamp\": datetime.now().isoformat(),\n   547→            \"total_cost_usd\": self.total_cost_usd,\n   548→            \"total_input_tokens\": self.total_input_tokens,\n   549→            \"total_output_tokens\": self.total_output_tokens,\n   550→            \"work_items\": self.work_item_costs,\n   551→        }\n   552→        with open(report_path, \"w\") as f:\n   553→            json.dump(report, f, indent=2)\n   554→        return str(report_path)\n   555→\n   556→\n   557→def run_child_process(\n   558→    cmd: list[str],\n   559→    description: str,\n   560→    timeout: Optional[int] = None,\n   561→    show_output: bool = False,\n   562→) -> ProcessResult:\n   563→    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n   564→    start_time = time.time()\n   565→    log(f\"Starting: {description}\")\n   566→    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n   567→\n   568→    # Save terminal settings before child process can corrupt them\n   569→    save_terminal_settings()\n   570→\n   571→    stdout_collector = OutputCollector()\n   572→    stderr_collector = OutputCollector()\n   573→\n   574→    try:\n   575→        # Force unbuffered output from Python child processes (orchestrator)\n   576→        # so their output streams in real-time instead of in chunks\n   577→        child_env = os.environ.copy()\n   578→        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n   579→        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n   580→\n   581→        process = subprocess.Popen(\n   582→            cmd,\n   583→            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n   584→            stdout=subprocess.PIPE,\n   585→            stderr=subprocess.PIPE,\n   586→            text=True,\n   587→            cwd=os.getcwd(),\n   588→            env=child_env,\n   589→        )\n   590→\n   591→        # Track active child for signal handling\n   592→        global _active_child_process\n   593→        _active_child_process = process\n   594→        log(f\"Spawned child process PID {process.pid}: {description}\")\n   595→\n   596→        # Start output streaming threads\n   597→        stdout_thread = threading.Thread(\n   598→            target=stream_output,\n   599→            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n   600→        )\n   601→        stderr_thread = threading.Thread(\n   602→            target=stream_output,\n   603→            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n   604→        )\n   605→        stdout_thread.start()\n   606→        stderr_thread.start()\n   607→\n   608→        # Monitor process with optional timeout\n   609→        if not (show_output or VERBOSE):\n   610→            print(f\"  [{description}] Working\", end=\"\", flush=True)\n   611→\n   612→        while process.poll() is None:\n   613→            time.sleep(1)\n   614→            elapsed = time.time() - start_time\n   615→\n   616→            if not (show_output or VERBOSE):\n   617→                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n   618→                if current_bytes > 0 and int(elapsed) % 10 == 0:\n   619→                    print(\".\", end=\"\", flush=True)\n   620→\n   621→            if timeout and elapsed > timeout:\n   622→                if not (show_output or VERBOSE):\n   623→                    print(\" [TIMEOUT]\", flush=True)\n   624→                log(f\"TIMEOUT after {timeout}s: {description}\")\n   625→                process.terminate()\n   626→                try:\n   627→                    process.wait(timeout=5)\n   628→                except subprocess.TimeoutExpired:\n   629→                    process.kill()\n   630→                    process.wait()\n   631→                stdout_thread.join(timeout=2)\n   632→                stderr_thread.join(timeout=2)\n   633→                _active_child_process = None\n   634→                restore_terminal_settings()\n   635→                duration = time.time() - start_time\n   636→                return ProcessResult(\n   637→                    success=False, exit_code=-1,\n   638→                    stdout=stdout_collector.get_output(),\n   639→                    stderr=stderr_collector.get_output(),\n   640→                    duration_seconds=duration,\n   641→                )\n   642→\n   643→        # Process finished\n   644→        stdout_thread.join(timeout=5)\n   645→        stderr_thread.join(timeout=5)\n   646→        _active_child_process = None\n   647→        restore_terminal_settings()\n   648→\n   649→        duration = time.time() - start_time\n   650→        exit_code = process.returncode\n   651→        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n   652→\n   653→        if not (show_output or VERBOSE):\n   654→            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n   655→            print(\n   656→                f\" {status} ({stdout_collector.line_count} lines, \"\n   657→                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n   658→                flush=True,\n   659→            )\n   660→\n   661→        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n   662→\n   663→        # Check for rate limiting\n   664→        rate_limit_wait = check_rate_limit(full_output)\n   665→        if rate_limit_wait is not None:\n   666→            return ProcessResult(\n   667→                success=False, exit_code=exit_code,\n   668→                stdout=stdout_collector.get_output(),\n   669→                stderr=stderr_collector.get_output(),\n   670→                duration_seconds=duration,\n   671→                rate_limited=True,\n   672→                rate_limit_wait=rate_limit_wait,\n   673→            )\n   674→\n   675→        return ProcessResult(\n   676→            success=(exit_code == 0),\n   677→            exit_code=exit_code,\n   678→            stdout=stdout_collector.get_output(),\n   679→            stderr=stderr_collector.get_output(),\n   680→            duration_seconds=duration,\n   681→        )\n   682→\n   683→    except FileNotFoundError as e:\n   684→        _active_child_process = None\n   685→        restore_terminal_settings()\n   686→        duration = time.time() - start_time\n   687→        log(f\"ERROR: Command not found: {e}\")\n   688→        return ProcessResult(\n   689→            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n   690→            duration_seconds=duration,\n   691→        )\n   692→    except Exception as e:\n   693→        _active_child_process = None\n   694→        restore_terminal_settings()\n   695→        duration = time.time() - start_time\n   696→        log(f\"ERROR: Unexpected error running {description}: {e}\")\n   697→        return ProcessResult(\n   698→            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n   699→            duration_seconds=duration,\n   700→        )\n   701→\n   702→\n   703→# Active child process for signal handling\n   704→_active_child_process: Optional[subprocess.Popen] = None\n   705→\n   706→\n   707→# ─── Plan Creation ────────────────────────────────────────────────────\n   708→\n   709→PLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n   710→\n   711→## Instructions\n   712→\n   713→1. Read the backlog item file: {item_path}\n   714→2. Read procedure-coding-rules.md for coding standards\n   715→3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n   716→4. Read the CLAUDE.md file for project conventions\n   717→5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   718→   Previous fix attempts and their verification results are recorded there.\n   719→   Your plan MUST address any unresolved findings from prior verifications.\n   720→\n   721→## What to produce\n   722→\n   723→1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   724→   - Brief architecture overview\n   725→   - Key files to create/modify\n   726→   - Design decisions\n   727→\n   728→2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   729→   - Use the exact format: meta + sections with nested tasks\n   730→   - Each section has: id, name, status: pending, tasks: [...]\n   731→   - Each task has: id, name, description, status: pending\n   732→   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   733→   - Include: documentation tasks, implementation tasks, unit tests, verification\n   734→   - The verification task should run {build_command} and {test_command}\n   735→\n   736→3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   737→   - If validation fails, fix the YAML format and retry\n   738→\n   739→4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n   740→\n   741→## Backlog item type: {item_type}\n   742→\n   743→## Agent Selection\n   744→\n   745→Tasks can specify which agent should execute them via the optional \"agent\" field.\n   746→Available agents are in {agents_dir}:\n   747→\n   748→- **coder**: Implementation specialist. Use for coding, implementation, and\n   749→  modification tasks. This is the default if no agent is specified.\n   750→- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n   751→  compliance-checking tasks.\n   752→\n   753→Example:\n   754→  - id: '2.1'\n   755→    name: Implement the feature\n   756→    agent: coder\n   757→    status: pending\n   758→    description: ...\n   759→\n   760→  - id: '3.1'\n   761→    name: Review code quality\n   762→    agent: code-reviewer\n   763→    status: pending\n   764→    description: ...\n   765→\n   766→If you do not set the agent field, the orchestrator will infer it from the\n   767→task description (verification tasks get code-reviewer, everything else gets coder).\n   768→\n   769→## Validation (Optional)\n   770→\n   771→Plans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n   772→\n   773→Example meta configuration:\n   774→\n   775→  meta:\n   776→    validation:\n   777→      enabled: true\n   778→      run_after:\n   779→        - coder\n   780→      validators:\n   781→        - validator\n   782→      max_validation_attempts: 1\n   783→\n   784→The validator produces PASS/WARN/FAIL verdicts:\n   785→- PASS: task proceeds normally\n   786→- WARN: task completes but warnings are logged\n   787→- FAIL: task is retried with validation findings prepended to the prompt\n   788→\n   789→For defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n   790→\n   791→## Important\n   792→- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n   793→- For defects: include a task to verify the fix with a regression test\n   794→- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n   795→- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n   796→- If the backlog item has a ## Verification Log with unresolved findings, your plan\n   797→  must specifically address those findings. The previous code fix may be correct but\n   798→  incomplete (e.g., operational steps not executed, data not deployed).\n   799→\"\"\"\n   800→\n   801→\n   802→def reset_interrupted_tasks(plan_path: str) -> int:\n   803→    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n   804→\n   805→    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n   806→    'in_progress'. On recovery, these should be treated as fresh retries,\n   807→    not as failed attempts. Returns the number of tasks reset.\n   808→    \"\"\"\n   809→    try:\n   810→        with open(plan_path, \"r\") as f:\n   811→            plan = yaml.safe_load(f)\n   812→    except (IOError, yaml.YAMLError) as e:\n   813→        log(f\"WARNING: Could not read plan for reset: {e}\")\n   814→        return 0\n   815→\n   816→    if not plan or \"sections\" not in plan:\n   817→        return 0\n   818→\n   819→    reset_count = 0\n   820→    for section in plan.get(\"sections\", []):\n   821→        for task in section.get(\"tasks\", []):\n   822→            if task.get(\"status\") == \"in_progress\":\n   823→                task_id = task.get(\"id\", \"?\")\n   824→                task[\"status\"] = \"pending\"\n   825→                # Clear attempt counter so interrupted tasks don't burn retries\n   826→                task.pop(\"attempts\", None)\n   827→                task.pop(\"last_attempt\", None)\n   828→                reset_count += 1\n   829→                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n   830→\n   831→        # Also reset section status if it was in_progress\n   832→        if section.get(\"status\") == \"in_progress\":\n   833→            section[\"status\"] = \"pending\"\n   834→\n   835→    if reset_count > 0:\n   836→        try:\n   837→            with open(plan_path, \"w\") as f:\n   838→                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n   839→            log(f\"Reset {reset_count} interrupted task(s)\")\n   840→        except IOError as e:\n   841→            log(f\"WARNING: Could not write plan after reset: {e}\")\n   842→            return 0\n   843→\n   844→    return reset_count\n   845→\n   846→\n   847→def check_existing_plan(item: BacklogItem) -> Optional[str]:\n   848→    \"\"\"Check if a valid YAML plan already exists for this item.\n   849→\n   850→    Returns the plan path if it exists and is valid, None otherwise.\n   851→    This enables recovery: if the pipeline was interrupted after plan creation\n   852→    but before completion, we skip straight to execution on restart.\n   853→    \"\"\"\n   854→    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n   855→    if not os.path.exists(plan_path):\n   856→        return None\n   857→\n   858→    # Reset any tasks stuck as in_progress from a previous interrupted run\n   859→    reset_interrupted_tasks(plan_path)\n   860→\n   861→    # Count task statuses from YAML directly (faster than dry-run validation)\n   862→    try:\n   863→        with open(plan_path, \"r\") as f:\n   864→            plan = yaml.safe_load(f)\n   865→        if not plan or \"sections\" not in plan:\n   866→            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n   867→            return None\n   868→        done = 0\n   869→        pending = 0\n   870→        for section in plan.get(\"sections\", []):\n   871→            for task in section.get(\"tasks\", []):\n   872→                status = task.get(\"status\", \"pending\")\n   873→                if status == \"completed\":\n   874→                    done += 1\n   875→                elif status == \"pending\":\n   876→                    pending += 1\n   877→    except (IOError, yaml.YAMLError):\n   878→        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n   879→        return None\n   880→\n   881→    if pending == 0 and done > 0:\n   882→        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n   883→    else:\n   884→        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n   885→    return plan_path\n   886→\n   887→\n   888→def create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n   889→    \"\"\"Create a design doc and YAML plan for a backlog item.\n   890→\n   891→    Returns the plan YAML path on success, or None on failure.\n   892→    If a valid plan already exists (from a previous interrupted run), returns it directly.\n   893→    \"\"\"\n   894→    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n   895→    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n   896→\n   897→    if dry_run:\n   898→        existing = os.path.exists(plan_path)\n   899→        if existing:\n   900→            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n   901→        else:\n   902→            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n   903→            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n   904→            log(f\"  Plan:   {plan_path}\")\n   905→        return plan_path\n   906→\n   907→    # Check for existing plan (recovery from interrupted run)\n   908→    existing_plan = check_existing_plan(item)\n   909→    if existing_plan:\n   910→        log(f\"Resuming from existing plan (skipping Phase 1)\")\n   911→        return existing_plan\n   912→\n   913→    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n   914→        item_path=item.path,\n   915→        date=date_str,\n   916→        slug=item.slug,\n   917→        item_type=item.item_type,\n   918→        agents_dir=AGENTS_DIR,\n   919→        build_command=BUILD_COMMAND,\n   920→        test_command=TEST_COMMAND,\n   921→    )\n   922→\n   923→    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n   924→\n   925→    result = run_child_process(\n   926→        cmd,\n   927→        description=f\"Plan creation for {item.slug}\",\n   928→        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n   929→        show_output=VERBOSE,\n   930→    )\n   931→\n   932→    if result.rate_limited:\n   933→        return None  # Caller handles rate limit sleep\n   934→\n   935→    if not result.success:\n   936→        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n   937→        if result.stderr:\n   938→            log(f\"  stderr: {result.stderr[:500]}\")\n   939→        return None\n   940→\n   941→    # Verify the plan was created and is valid\n   942→    if not os.path.exists(plan_path):\n   943→        log(f\"Plan file not created at expected path: {plan_path}\")\n   944→        return None\n   945→\n   946→    # Dry-run validation\n   947→    validate_result = run_child_process(\n   948→        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n   949→        description=f\"Plan validation for {item.slug}\",\n   950→        timeout=30,\n   951→    )\n   952→\n   953→    if not validate_result.success:\n   954→        log(f\"Plan validation failed for {item.slug}\")\n   955→        if validate_result.stdout:\n   956→            log(f\"  output: {validate_result.stdout[:500]}\")\n   957→        return None\n   958→\n   959→    # Count tasks from dry-run output\n   960→    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n   961→    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n   962→    return plan_path\n   963→\n   964→\n   965→# ─── Dev Server Management ───────────────────────────────────────────\n   966→\n   967→# Track whether we stopped the dev server so we know to restart it\n   968→_dev_server_was_running = False\n   969→\n   970→\n   971→def find_dev_server_pid() -> Optional[int]:\n   972→    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n   973→    try:\n   974→        result = subprocess.run(\n   975→            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n   976→            capture_output=True, text=True, timeout=5,\n   977→        )\n   978→        if result.returncode == 0 and result.stdout.strip():\n   979→            # lsof may return multiple PIDs (parent + child); take the first\n   980→            pids = result.stdout.strip().split(\"\\n\")\n   981→            return int(pids[0])\n   982→    except (subprocess.TimeoutExpired, ValueError, OSError):\n   983→        pass\n   984→    return None\n   985→\n   986→\n   987→def stop_dev_server() -> bool:\n   988→    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n   989→    global _dev_server_was_running\n   990→    pid = find_dev_server_pid()\n   991→    if pid is None:\n   992→        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n   993→        _dev_server_was_running = False\n   994→        return False\n   995→\n   996→    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n   997→    try:\n   998→        os.kill(pid, signal.SIGTERM)\n   999→        # Wait for it to stop\n  1000→        for _ in range(10):\n  1001→            time.sleep(1)\n  1002→            if find_dev_server_pid() is None:\n  1003→                break\n  1004→        # Force kill if still running\n  1005→        if find_dev_server_pid() is not None:\n  1006→            remaining_pid = find_dev_server_pid()\n  1007→            if remaining_pid:\n  1008→                os.kill(remaining_pid, signal.SIGKILL)\n  1009→                time.sleep(1)\n  1010→    except OSError as e:\n  1011→        verbose_log(f\"Error stopping dev server: {e}\")\n  1012→\n  1013→    _dev_server_was_running = True\n  1014→    log(\"Dev server stopped\")\n  1015→    return True\n  1016→\n  1017→\n  1018→def start_dev_server() -> None:\n  1019→    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n  1020→    global _dev_server_was_running\n  1021→    if not _dev_server_was_running:\n  1022→        verbose_log(\"Dev server was not running before - skipping restart\")\n  1023→        return\n  1024→\n  1025→    # Check it's not already running (e.g. orchestrator started one)\n  1026→    if find_dev_server_pid() is not None:\n  1027→        verbose_log(\"Dev server already running - skipping restart\")\n  1028→        _dev_server_was_running = False\n  1029→        return\n  1030→\n  1031→    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n  1032→    try:\n  1033→        subprocess.Popen(\n  1034→            DEV_SERVER_COMMAND.split(),\n  1035→            stdout=subprocess.DEVNULL,\n  1036→            stderr=subprocess.DEVNULL,\n  1037→            cwd=os.getcwd(),\n  1038→            start_new_session=True,  # Detach from our process group\n  1039→        )\n  1040→        # Wait briefly for startup\n  1041→        time.sleep(3)\n  1042→        if find_dev_server_pid() is not None:\n  1043→            log(\"Dev server restarted\")\n  1044→        else:\n  1045→            log(\"WARNING: Dev server may not have started - check manually\")\n  1046→    except OSError as e:\n  1047→        log(f\"WARNING: Failed to restart dev server: {e}\")\n  1048→\n  1049→    _dev_server_was_running = False\n  1050→\n  1051→\n  1052→# ─── Plan Execution ───────────────────────────────────────────────────\n  1053→\n  1054→\n  1055→def execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n  1056→    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n  1057→    if dry_run:\n  1058→        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n  1059→        return True\n  1060→\n  1061→    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n  1062→    stop_dev_server()\n  1063→\n  1064→    try:\n  1065→        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n  1066→        if VERBOSE:\n  1067→            orch_cmd.append(\"--verbose\")\n  1068→\n  1069→        result = run_child_process(\n  1070→            orch_cmd,\n  1071→            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n  1072→            timeout=None,  # Orchestrator has its own timeouts\n  1073→            show_output=True,  # Always stream orchestrator output\n  1074→        )\n  1075→\n  1076→        if result.rate_limited and result.rate_limit_wait:\n  1077→            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n  1078→            try:\n  1079→                time.sleep(result.rate_limit_wait)\n  1080→            except KeyboardInterrupt:\n  1081→                log(\"Interrupted during rate limit wait\")\n  1082→                return False\n  1083→            # After rate limit, the orchestrator needs to be re-run\n  1084→            # It will resume from where it left off (tasks already completed in YAML)\n  1085→            log(\"Resuming orchestrator after rate limit...\")\n  1086→            return execute_plan(plan_path, dry_run)\n  1087→\n  1088→        if not result.success:\n  1089→            log(f\"Orchestrator failed (exit {result.exit_code})\")\n  1090→            # Check for partial completion\n  1091→            completed = result.stdout.count(\"Result: SUCCESS\")\n  1092→            failed = result.stdout.count(\"Result: FAILED\")\n  1093→            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n  1094→            return False\n  1095→\n  1096→        # Parse summary from orchestrator output\n  1097→        completed = result.stdout.count(\"Result: SUCCESS\")\n  1098→        log(f\"Orchestrator completed: {completed} tasks\")\n  1099→        return True\n  1100→    finally:\n  1101→        # Always restart dev server after orchestrator, even on failure\n  1102→        start_dev_server()\n  1103→\n  1104→\n  1105→# ─── Archive ──────────────────────────────────────────────────────────\n  1106→\n  1107→\n  1108→def find_in_progress_plans() -> list[str]:\n  1109→    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n  1110→\n  1111→    When the pipeline restarts, any plan with remaining pending tasks must\n  1112→    be completed before new backlog items are processed. This prevents the\n  1113→    pipeline from starting new work while previous plans are incomplete.\n  1114→    Excludes the sample-plan.yaml template.\n  1115→    \"\"\"\n  1116→    in_progress: list[str] = []\n  1117→    plans_dir = Path(PLANS_DIR)\n  1118→\n  1119→    if not plans_dir.exists():\n  1120→        return in_progress\n  1121→\n  1122→    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n  1123→        if yaml_file.name == \"sample-plan.yaml\":\n  1124→            continue\n  1125→\n  1126→        try:\n  1127→            with open(yaml_file, \"r\") as f:\n  1128→                plan = yaml.safe_load(f)\n  1129→        except (IOError, yaml.YAMLError):\n  1130→            continue\n  1131→\n  1132→        if not plan or \"sections\" not in plan:\n  1133→            continue\n  1134→\n  1135→        has_completed = False\n  1136→        has_pending = False\n  1137→        for section in plan.get(\"sections\", []):\n  1138→            for task in section.get(\"tasks\", []):\n  1139→                status = task.get(\"status\", \"pending\")\n  1140→                if status == \"completed\":\n  1141→                    has_completed = True\n  1142→                elif status in (\"pending\", \"in_progress\"):\n  1143→                    has_pending = True\n  1144→\n  1145→        # A plan is \"in progress\" if it has both completed and pending tasks\n  1146→        # (i.e. it was started but not finished)\n  1147→        if has_completed and has_pending:\n  1148→            in_progress.append(str(yaml_file))\n  1149→\n  1150→    return in_progress\n  1151→\n  1152→\n  1153→def archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n  1154→    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n  1155→    source = item.path\n  1156→    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n  1157→    dest = os.path.join(dest_dir, os.path.basename(item.path))\n  1158→\n  1159→    if dry_run:\n  1160→        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n  1161→        return True\n  1162→\n  1163→    try:\n  1164→        os.makedirs(dest_dir, exist_ok=True)\n  1165→        shutil.move(source, dest)\n  1166→\n  1167→        # Git commit the move\n  1168→        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n  1169→        subprocess.run(\n  1170→            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n  1171→            capture_output=True, check=True,\n  1172→        )\n  1173→        log(f\"Archived: {source} -> {dest}\")\n  1174→        return True\n  1175→    except (OSError, subprocess.CalledProcessError) as e:\n  1176→        log(f\"WARNING: Failed to archive {source}: {e}\")\n  1177→        return False\n  1178→\n  1179→\n  1180→# ─── Symptom Verification ─────────────────────────────────────────────\n  1181→\n  1182→VERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\n  1183→reported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n  1184→\n  1185→## Instructions\n  1186→\n  1187→1. Read the defect file: {item_path}\n  1188→2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n  1189→3. Read the \"Fix Required\" section for any commands or checks that should be performed\n  1190→4. If there is a \"## Verification Log\" section, read previous verification attempts\n  1191→\n  1192→## What to check\n  1193→\n  1194→For each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n  1195→- Run the command or check the condition\n  1196→- Record whether it passed or failed\n  1197→- Record the actual output or observation\n  1198→\n  1199→Also check:\n  1200→- Does `{build_command}` pass? (code correctness)\n  1201→- Do unit tests pass? (`{test_command}`)\n  1202→- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n  1203→\n  1204→## What to produce\n  1205→\n  1206→Append your findings to the defect file at {item_path}.\n  1207→If no \"## Verification Log\" section exists, create one at the end of the file.\n  1208→\n  1209→Use this exact format (the count MUST increment from the last entry, or start at 1):\n  1210→\n  1211→```\n  1212→### Verification #{count} - YYYY-MM-DD HH:MM\n  1213→\n  1214→**Verdict: PASS** or **Verdict: FAIL**\n  1215→\n  1216→**Checks performed:**\n  1217→- [ ] or [x] Build passes\n  1218→- [ ] or [x] Unit tests pass\n  1219→- [ ] or [x] (each specific symptom check from the defect)\n  1220→\n  1221→**Findings:**\n  1222→(describe what you observed for each check - be specific about command outputs)\n  1223→```\n  1224→\n  1225→## CRITICAL RULES\n  1226→\n  1227→- Do NOT modify any code files\n  1228→- Do NOT fix anything\n  1229→- Do NOT change the defect's ## Status line\n  1230→- ONLY read, run verification commands, and append findings to the defect file\n  1231→- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  1232→  run your check, then stop it\n  1233→- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n  1234→\"\"\"\n  1235→\n  1236→# Maximum number of verify-then-fix cycles before giving up\n  1237→MAX_VERIFICATION_CYCLES = 3\n  1238→\n  1239→\n  1240→def count_verification_attempts(item_path: str) -> int:\n  1241→    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n  1242→    try:\n  1243→        with open(item_path, \"r\") as f:\n  1244→            content = f.read()\n  1245→    except IOError:\n  1246→        return 0\n  1247→\n  1248→    return len(re.findall(r\"### Verification #\\d+\", content))\n  1249→\n  1250→\n  1251→def last_verification_passed(item_path: str) -> bool:\n  1252→    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n  1253→    try:\n  1254→        with open(item_path, \"r\") as f:\n  1255→            content = f.read()\n  1256→    except IOError:\n  1257→        return False\n  1258→\n  1259→    # Find all verdict lines and check the last one\n  1260→    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n  1261→    if not verdicts:\n  1262→        return False\n  1263→    return verdicts[-1].upper() == \"PASS\"\n  1264→\n  1265→\n  1266→def verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n  1267→    \"\"\"Run symptom verification on a completed defect fix.\n  1268→\n  1269→    Returns True if verification passed, False if it failed.\n  1270→    The verifier appends findings to the defect file regardless of outcome.\n  1271→    \"\"\"\n  1272→    if item.item_type != \"defect\":\n  1273→        # Features don't have symptom verification (yet)\n  1274→        return True\n  1275→\n  1276→    attempt_count = count_verification_attempts(item.path) + 1\n  1277→\n  1278→    if dry_run:\n  1279→        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n  1280→        return True\n  1281→\n  1282→    log(f\"Running symptom verification #{attempt_count}...\")\n  1283→\n  1284→    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n  1285→        item_path=item.path,\n  1286→        slug=item.slug,\n  1287→        count=attempt_count,\n  1288→        build_command=BUILD_COMMAND,\n  1289→        test_command=TEST_COMMAND,\n  1290→        dev_server_command=DEV_SERVER_COMMAND,\n  1291→    )\n  1292→\n  1293→    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n  1294→\n  1295→    result = run_child_process(\n  1296→        cmd,\n  1297→        description=f\"Verify {item.slug} #{attempt_count}\",\n  1298→        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n  1299→        show_output=VERBOSE,\n  1300→    )\n  1301→\n  1302→    if result.rate_limited:\n  1303→        log(\"Rate limited during verification\")\n  1304→        return False\n  1305→\n  1306→    if not result.success:\n  1307→        log(f\"Verification process failed (exit {result.exit_code})\")\n  1308→        return False\n  1309→\n  1310→    # Check if the verifier recorded a PASS\n  1311→    passed = last_verification_passed(item.path)\n  1312→    if passed:\n  1313→        log(f\"Verification #{attempt_count}: PASSED\")\n  1314→    else:\n  1315→        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n  1316→\n  1317→    return passed\n  1318→\n  1319→\n  1320→# ─── Main Pipeline ────────────────────────────────────────────────────\n  1321→\n  1322→\n  1323→def _read_plan_name(plan_path: str) -> str:\n  1324→    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n  1325→    try:\n  1326→        with open(plan_path, \"r\") as f:\n  1327→            plan = yaml.safe_load(f)\n  1328→        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n  1329→    except (IOError, yaml.YAMLError):\n  1330→        return \"unknown\"\n  1331→\n  1332→\n  1333→def _try_record_usage(\n  1334→    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n  1335→) -> None:\n  1336→    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n  1337→    plan_name = _read_plan_name(plan_path)\n  1338→    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n  1339→    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n  1340→    if report_path.exists():\n  1341→        session_tracker.record_from_report(str(report_path), work_item_name)\n  1342→\n  1343→\n  1344→def process_item(\n  1345→    item: BacklogItem,\n  1346→    dry_run: bool = False,\n  1347→    session_tracker: Optional[SessionUsageTracker] = None,\n  1348→) -> bool:\n  1349→    \"\"\"Process a single backlog item through the full pipeline.\n  1350→\n  1351→    For defects, runs a verify-then-fix cycle:\n  1352→      Phase 1: Create plan\n  1353→      Phase 2: Execute plan (orchestrator)\n  1354→      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n  1355→        - If PASS: Phase 4 (archive)\n  1356→        - If FAIL: Delete stale plan, loop back to Phase 1\n  1357→          (next plan creation sees verification findings in the defect file)\n  1358→      Phase 4: Archive\n  1359→\n  1360→    Returns True on success, False on failure or max cycles exceeded.\n  1361→    \"\"\"\n  1362→    item_start = time.time()\n  1363→    log(f\"{'=' * 60}\")\n  1364→    log(f\"Processing {item.display_name}\")\n  1365→    log(f\"  Type: {item.item_type}\")\n  1366→    log(f\"  File: {item.path}\")\n  1367→    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n  1368→    log(f\"{'=' * 60}\")\n  1369→\n  1370→    prior_verifications = count_verification_attempts(item.path)\n  1371→\n  1372→    for cycle in range(MAX_VERIFICATION_CYCLES):\n  1373→        cycle_num = prior_verifications + cycle + 1\n  1374→\n  1375→        if check_stop_requested():\n  1376→            log(\"Stop requested during processing.\")\n  1377→            return False\n  1378→\n  1379→        # Phase 1: Create plan\n  1380→        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n  1381→        plan_path = create_plan(item, dry_run)\n  1382→        if not plan_path:\n  1383→            log(f\"FAILED: Could not create plan for {item.display_name}\")\n  1384→            return False\n  1385→\n  1386→        # Phase 2: Execute plan\n  1387→        log(\"Phase 2: Running orchestrator...\")\n  1388→        success = execute_plan(plan_path, dry_run)\n  1389→\n  1390→        # Record usage from the orchestrator's report (regardless of success)\n  1391→        if session_tracker and plan_path:\n  1392→            _try_record_usage(session_tracker, plan_path, item.display_name)\n  1393→\n  1394→        if not success:\n  1395→            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n  1396→            return False\n  1397→\n  1398→        # Phase 3: Verify symptoms\n  1399→        log(\"Phase 3: Verifying symptoms...\")\n  1400→        verified = verify_item(item, dry_run)\n  1401→\n  1402→        if verified:\n  1403→            # Phase 4: Archive\n  1404→            log(\"Phase 4: Archiving...\")\n  1405→            archive_item(item, dry_run)\n  1406→\n  1407→            elapsed = time.time() - item_start\n  1408→            minutes = int(elapsed // 60)\n  1409→            seconds = int(elapsed % 60)\n  1410→            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n  1411→            return True\n  1412→\n  1413→        # Verification failed - prepare for next cycle\n  1414→        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n  1415→\n  1416→        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n  1417→            # Delete the stale plan so next cycle creates a fresh one\n  1418→            # that incorporates the verification findings\n  1419→            if plan_path and os.path.exists(plan_path):\n  1420→                os.remove(plan_path)\n  1421→                log(f\"Removed stale plan: {plan_path}\")\n  1422→            log(\"Cycling back to Phase 1 with verification findings...\")\n  1423→        else:\n  1424→            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n  1425→            log(\"Defect stays in queue with accumulated verification findings.\")\n  1426→\n  1427→    return False\n  1428→\n  1429→\n  1430→def main_loop(dry_run: bool = False, once: bool = False) -> None:\n  1431→    \"\"\"Main processing loop with filesystem watching.\"\"\"\n  1432→    global VERBOSE, CLAUDE_CMD\n  1433→\n  1434→    # Save terminal settings at startup (before any child can corrupt them)\n  1435→    save_terminal_settings()\n  1436→\n  1437→    # Resolve Claude binary\n  1438→    CLAUDE_CMD = resolve_claude_binary()\n  1439→    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n  1440→\n  1441→    # Clear stale stop semaphore\n  1442→    clear_stop_semaphore()\n  1443→\n  1444→    # Track items that failed in this session (don't retry)\n  1445→    failed_items: set[str] = set()\n  1446→\n  1447→    # Track usage across all work items in this session\n  1448→    session_tracker = SessionUsageTracker()\n  1449→\n  1450→    # Event to signal new items detected\n  1451→    new_item_event = threading.Event()\n  1452→\n  1453→    def on_new_item():\n  1454→        new_item_event.set()\n  1455→\n  1456→    # Set up filesystem watcher\n  1457→    observer = Observer()\n  1458→    watcher = BacklogWatcher(on_new_item)\n  1459→\n  1460→    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n  1461→        if os.path.isdir(watch_dir):\n  1462→            observer.schedule(watcher, watch_dir, recursive=False)\n  1463→            verbose_log(f\"Watching directory: {watch_dir}\")\n  1464→\n  1465→    if not once:\n  1466→        observer.start()\n  1467→        log(\"Filesystem watcher started\")\n  1468→\n  1469→    try:\n  1470→        while True:\n  1471→            # Check stop semaphore\n  1472→            if check_stop_requested():\n  1473→                log(\"Stop requested via semaphore. Exiting.\")\n  1474→                break\n  1475→\n  1476→            # Resume in-progress plans before scanning for new work.\n  1477→            # This ensures partially-completed plans finish before new items start.\n  1478→            if not dry_run:\n  1479→                in_progress_plans = find_in_progress_plans()\n  1480→                if in_progress_plans:\n  1481→                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n  1482→                    for plan_path in in_progress_plans:\n  1483→                        if check_stop_requested():\n  1484→                            break\n  1485→                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n  1486→                        success = execute_plan(plan_path, dry_run)\n  1487→                        # Record usage from the orchestrator's report\n  1488→                        plan_basename = os.path.basename(plan_path)\n  1489→                        _try_record_usage(\n  1490→                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n  1491→                        )\n  1492→                        if not success:\n  1493→                            failed_items.add(plan_path)\n  1494→                            log(f\"In-progress plan failed: {plan_path}\")\n  1495→                    # After resuming, re-scan (completed plans may unblock new items)\n  1496→                    continue\n  1497→\n  1498→            # Scan for items (with dependency filtering)\n  1499→            items = scan_all_backlogs()\n  1500→\n  1501→            # Filter out previously failed items\n  1502→            items = [i for i in items if i.path not in failed_items]\n  1503→\n  1504→            if items:\n  1505→                log(f\"Found {len(items)} item(s) to process\")\n  1506→                for i, item in enumerate(items, 1):\n  1507→                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n  1508→            else:\n  1509→                if once:\n  1510→                    log(\"No items to process. Exiting (--once mode).\")\n  1511→                    break\n  1512→                log(f\"No items to process. Watching for new items...\")\n  1513→                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n  1514→\n  1515→                # Wait for either a filesystem event or the safety scan interval\n  1516→                new_item_event.clear()\n  1517→                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n  1518→                continue\n  1519→\n  1520→            # In --once mode, process only the first item then exit\n  1521→            if once:\n  1522→                item = items[0]\n  1523→                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n  1524→                success = process_item(item, dry_run, session_tracker)\n  1525→                if not success:\n  1526→                    log(f\"Item failed: {item.slug}\")\n  1527→                log(\"Exiting (--once mode).\")\n  1528→                break\n  1529→\n  1530→            # Process items one at a time\n  1531→            for item in items:\n  1532→                if check_stop_requested():\n  1533→                    log(\"Stop requested. Finishing current session.\")\n  1534→                    break\n  1535→\n  1536→                success = process_item(item, dry_run, session_tracker)\n  1537→                if not success:\n  1538→                    failed_items.add(item.path)\n  1539→                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n  1540→\n  1541→            # Brief pause before next scan\n  1542→            time.sleep(2)\n  1543→\n  1544→    except KeyboardInterrupt:\n  1545→        log(\"Interrupted by user. Shutting down...\")\n  1546→    finally:\n  1547→        # Print and write session usage summary\n  1548→        print(session_tracker.format_session_summary())\n  1549→        session_report = session_tracker.write_session_report()\n  1550→        if session_report:\n  1551→            log(f\"[Session usage report: {session_report}]\")\n  1552→\n  1553→        if not once:\n  1554→            observer.stop()\n  1555→            observer.join(timeout=5)\n  1556→        restore_terminal_settings()\n  1557→        log(\"Auto-pipeline stopped.\")\n  1558→\n  1559→\n  1560→# ─── Signal Handling ──────────────────────────────────────────────────\n  1561→\n  1562→\n  1563→def handle_signal(signum, frame):\n  1564→    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n  1565→    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n  1566→    log(f\"Received {sig_name}. Shutting down gracefully...\")\n  1567→\n  1568→    # Terminate active child process if any\n  1569→    if _active_child_process and _active_child_process.poll() is None:\n  1570→        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n  1571→        _active_child_process.terminate()\n  1572→        try:\n  1573→            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n  1574→        except subprocess.TimeoutExpired:\n  1575→            log(\"Child process did not exit gracefully. Killing...\")\n  1576→            _active_child_process.kill()\n  1577→            _active_child_process.wait()\n  1578→\n  1579→    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n  1580→    restore_terminal_settings()\n  1581→\n  1582→    sys.exit(0)\n  1583→\n  1584→\n  1585→# ─── Entry Point ──────────────────────────────────────────────────────\n  1586→\n  1587→\n  1588→def main():\n  1589→    global VERBOSE\n  1590→\n  1591→    parser = argparse.ArgumentParser(\n  1592→        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n  1593→    )\n  1594→    parser.add_argument(\n  1595→        \"--dry-run\", action=\"store_true\",\n  1596→        help=\"Show what would be processed without spawning Claude or orchestrator\",\n  1597→    )\n  1598→    parser.add_argument(\n  1599→        \"--once\", action=\"store_true\",\n  1600→        help=\"Process the first item found then exit (single-item mode)\",\n  1601→    )\n  1602→    parser.add_argument(\n  1603→        \"--verbose\", action=\"store_true\",\n  1604→        help=\"Stream all child output in detail\",\n  1605→    )\n  1606→    args = parser.parse_args()\n  1607→    VERBOSE = args.verbose\n  1608→\n  1609→    # Register signal handlers\n  1610→    signal.signal(signal.SIGINT, handle_signal)\n  1611→    signal.signal(signal.SIGTERM, handle_signal)\n  1612→\n  1613→    log(\"Starting auto-pipeline\")\n  1614→    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n  1615→    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n  1616→    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n  1617→\n  1618→    main_loop(dry_run=args.dry_run, once=args.once)\n  1619→\n  1620→\n  1621→if __name__ == \"__main__\":\n  1622→    main()\n  1623→"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"1b858dd4-c844-44d4-8718-f7dd6897dd56","tool_use_result":{"type":"text","file":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","content":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","numLines":1623,"startLine":1,"totalLines":1623}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CHqQSP4HxQjdz6YGFp7NUB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018Wd7Gke6Q7jBfaEZ5WgSy6","name":"Read","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/docs/plans/2026-02-14-07-quota-aware-execution-design.md"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1061,"cache_read_input_tokens":32687,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1061},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"1129706f-e14e-48d8-9786-526c112dd095"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018Wd7Gke6Q7jBfaEZ5WgSy6","type":"tool_result","content":"     1→# Quota-Aware Execution with Weekly Budget Limits - Design Document\n     2→\n     3→**Goal:** Add budget awareness to the orchestrator and auto-pipeline so they can stop gracefully before exhausting the user's weekly Claude usage quota, reserving a configurable portion for interactive use.\n     4→\n     5→**Architecture:** Add a BudgetConfig dataclass to hold budget limits parsed from plan YAML meta or CLI flags. Add a BudgetGuard class that checks cumulative cost (from PlanUsageTracker, Feature 06) against the configured ceiling before each task. When spending exceeds the threshold, the orchestrator pauses the plan with a \"paused_quota\" status. The auto-pipeline performs a per-work-item budget check and stops processing new items when the budget is exhausted. No external quota API is required; the system uses locally-tracked cost data combined with a user-configured ceiling.\n     6→\n     7→**Tech Stack:** Python 3 (plan-orchestrator.py, auto-pipeline.py), YAML (plan meta.budget configuration)\n     8→\n     9→---\n    10→\n    11→## Architecture Overview\n    12→\n    13→### Dependency: Feature 06 (Token Usage Tracking)\n    14→\n    15→This feature builds directly on the TaskUsage dataclass, PlanUsageTracker, and per-task cost data introduced by Feature 06. Specifically:\n    16→\n    17→- TaskResult.usage provides per-task cost via total_cost_usd\n    18→- PlanUsageTracker.get_total_usage() provides cumulative plan cost\n    19→- Usage report JSON files provide cross-plan session cost data\n    20→\n    21→Feature 06 is already implemented.\n    22→\n    23→### BudgetConfig Dataclass\n    24→\n    25→New dataclass to hold budget configuration, placed after PlanUsageTracker in plan-orchestrator.py:\n    26→\n    27→    @dataclass\n    28→    class BudgetConfig:\n    29→        \"\"\"Budget limits for plan execution.\"\"\"\n    30→        max_quota_percent: float = DEFAULT_MAX_QUOTA_PERCENT   # 100.0\n    31→        quota_ceiling_usd: float = DEFAULT_QUOTA_CEILING_USD   # 0.0 = unlimited\n    32→        reserved_budget_usd: float = DEFAULT_RESERVED_BUDGET_USD  # 0.0\n    33→\n    34→        @property\n    35→        def effective_limit_usd(self) -> float:\n    36→            \"\"\"Calculate effective spending limit in USD.\"\"\"\n    37→            if self.quota_ceiling_usd <= 0:\n    38→                return float('inf')\n    39→            percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n    40→            if self.reserved_budget_usd > 0:\n    41→                reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n    42→                return min(percent_limit, reserve_limit)\n    43→            return percent_limit\n    44→\n    45→        @property\n    46→        def is_enabled(self) -> bool:\n    47→            \"\"\"Whether budget enforcement is active.\"\"\"\n    48→            return self.quota_ceiling_usd > 0\n    49→\n    50→Configuration sources (in priority order):\n    51→1. CLI flags: --max-budget-pct, --quota-ceiling, --reserved-budget\n    52→2. Plan YAML meta.budget block\n    53→3. Defaults (100% / unlimited = no budget enforcement)\n    54→\n    55→### BudgetGuard Class\n    56→\n    57→Stateful guard that wraps PlanUsageTracker and enforces limits. It does not maintain its own cost counter; it queries the tracker directly.\n    58→\n    59→    class BudgetGuard:\n    60→        \"\"\"Checks cumulative cost against budget limits before each task.\"\"\"\n    61→\n    62→        def __init__(self, config: BudgetConfig, usage_tracker: PlanUsageTracker):\n    63→            self.config = config\n    64→            self.usage_tracker = usage_tracker\n    65→\n    66→        def can_proceed(self) -> tuple[bool, str]:\n    67→            \"\"\"Check if budget allows another task.\n    68→            Returns (can_proceed, reason_if_not).\n    69→            \"\"\"\n    70→            if not self.config.is_enabled:\n    71→                return (True, \"\")\n    72→            total = self.usage_tracker.get_total_usage()\n    73→            spent = total.total_cost_usd\n    74→            limit = self.config.effective_limit_usd\n    75→            if spent >= limit:\n    76→                pct = (spent / self.config.quota_ceiling_usd * 100) if self.config.quota_ceiling_usd > 0 else 0\n    77→                reason = (\n    78→                    f\"Budget limit reached: ${spent:.4f} / ${limit:.4f} \"\n    79→                    f\"({pct:.1f}% of ${self.config.quota_ceiling_usd:.2f} ceiling)\"\n    80→                )\n    81→                return (False, reason)\n    82→            return (True, \"\")\n    83→\n    84→        def get_usage_percent(self) -> float:\n    85→            \"\"\"Current spending as percentage of ceiling.\"\"\"\n    86→            if not self.config.is_enabled:\n    87→                return 0.0\n    88→            total = self.usage_tracker.get_total_usage()\n    89→            return (total.total_cost_usd / self.config.quota_ceiling_usd * 100)\n    90→\n    91→        def format_status(self) -> str:\n    92→            \"\"\"Format current budget status for display.\"\"\"\n    93→            if not self.config.is_enabled:\n    94→                return \"[Budget: unlimited]\"\n    95→            total = self.usage_tracker.get_total_usage()\n    96→            spent = total.total_cost_usd\n    97→            limit = self.config.effective_limit_usd\n    98→            pct = self.get_usage_percent()\n    99→            return f\"[Budget: ${spent:.4f} / ${limit:.4f} ({pct:.1f}% of ceiling)]\"\n   100→\n   101→The guard returns a tuple so the caller gets both the decision and a human-readable explanation.\n   102→\n   103→### Plan YAML Configuration\n   104→\n   105→Budget settings in the plan meta block:\n   106→\n   107→    meta:\n   108→      name: My Feature\n   109→      budget:\n   110→        max_quota_percent: 90\n   111→        quota_ceiling_usd: 100.00\n   112→\n   113→When no budget block is present, no budget enforcement occurs (backwards compatible).\n   114→\n   115→### CLI Flags\n   116→\n   117→New orchestrator flags:\n   118→\n   119→    --max-budget-pct N       Maximum % of quota ceiling to use (default: 100)\n   120→    --quota-ceiling N.NN     Weekly quota ceiling in USD (default: 0 = unlimited)\n   121→    --reserved-budget N.NN   USD amount to reserve for interactive use (default: 0)\n   122→\n   123→CLI flags override plan YAML values when both are specified.\n   124→\n   125→### parse_budget_config Helper\n   126→\n   127→A helper function parses BudgetConfig from both the plan meta and CLI args:\n   128→\n   129→    def parse_budget_config(plan: dict, args: argparse.Namespace) -> BudgetConfig:\n   130→        \"\"\"Parse budget configuration from plan YAML and CLI overrides.\"\"\"\n   131→        budget_meta = plan.get(\"meta\", {}).get(\"budget\", {})\n   132→        config = BudgetConfig(\n   133→            max_quota_percent=budget_meta.get(\"max_quota_percent\", DEFAULT_MAX_QUOTA_PERCENT),\n   134→            quota_ceiling_usd=budget_meta.get(\"quota_ceiling_usd\", DEFAULT_QUOTA_CEILING_USD),\n   135→            reserved_budget_usd=budget_meta.get(\"reserved_budget_usd\", DEFAULT_RESERVED_BUDGET_USD),\n   136→        )\n   137→        # CLI overrides\n   138→        if hasattr(args, 'max_budget_pct') and args.max_budget_pct is not None:\n   139→            config.max_quota_percent = args.max_budget_pct\n   140→        if hasattr(args, 'quota_ceiling') and args.quota_ceiling is not None:\n   141→            config.quota_ceiling_usd = args.quota_ceiling\n   142→        if hasattr(args, 'reserved_budget') and args.reserved_budget is not None:\n   143→            config.reserved_budget_usd = args.reserved_budget\n   144→        return config\n   145→\n   146→### Pre-Task Check in Orchestrator\n   147→\n   148→In run_orchestrator(), after the existing circuit breaker check and before task execution:\n   149→\n   150→1. Call budget_guard.can_proceed()\n   151→2. If False, print the reason, set meta.status to \"paused_quota\", save the plan, and break\n   152→3. After each task completes, the usage is already recorded in usage_tracker (no extra step needed since BudgetGuard reads from it)\n   153→\n   154→The check happens in the main task loop:\n   155→- Sequential path (around line 2374, after circuit breaker check)\n   156→- Parallel path (around line 2396, before parallel group execution)\n   157→\n   158→### Plan Pause Behavior\n   159→\n   160→When budget is exhausted:\n   161→\n   162→1. The current task completes (no mid-task interruption)\n   163→2. Plan YAML is updated: meta.status becomes \"paused_quota\"\n   164→3. A meta.pause_reason is written with the budget explanation\n   165→4. The usage report is generated (from PlanUsageTracker)\n   166→5. run_orchestrator() exits with code 0 (not a failure)\n   167→\n   168→A paused plan can be resumed later with --resume-from, and the budget guard re-evaluates from current spending.\n   169→\n   170→### Auto-Pipeline Integration\n   171→\n   172→The auto-pipeline checks session-level spending across work items using SessionUsageTracker.total_cost_usd:\n   173→\n   174→1. Parse budget config from CLI flags (--max-budget-pct, --quota-ceiling)\n   175→2. Create a PipelineBudgetGuard that checks SessionUsageTracker.total_cost_usd against the ceiling\n   176→3. Before starting each new work item, check can_proceed()\n   177→4. If budget exhausted, log the reason and break the main loop\n   178→\n   179→The auto-pipeline budget check is per-work-item (coarser granularity than per-task).\n   180→\n   181→### Exit Codes\n   182→\n   183→The orchestrator uses specific exit behavior for budget pauses:\n   184→\n   185→- Exit code 0: Plan paused due to budget (not a failure)\n   186→- The auto-pipeline detects \"paused_quota\" in the plan YAML after execution\n   187→- This is distinct from exit code 1 (real failure) and rate-limit retries\n   188→\n   189→---\n   190→\n   191→## Key Files\n   192→\n   193→### Modified Files\n   194→\n   195→| File | Change |\n   196→|------|--------|\n   197→| scripts/plan-orchestrator.py | BudgetConfig, BudgetGuard, parse_budget_config, pre-task check, CLI flags, plan pause logic |\n   198→| scripts/auto-pipeline.py | PipelineBudgetGuard, per-work-item check, CLI flags |\n   199→\n   200→### New Files\n   201→\n   202→| File | Purpose |\n   203→|------|---------|\n   204→| tests/test_budget_guard.py | Unit tests for BudgetConfig, BudgetGuard, parse_budget_config |\n   205→\n   206→---\n   207→\n   208→## Design Decisions\n   209→\n   210→1. **User-configured ceiling, not API-queried quota.** There is no known programmatic API to query remaining Claude weekly quota. The pragmatic approach is a user-configured ceiling combined with locally-tracked cost. This is simple, requires no API access, and works across all plan types.\n   211→\n   212→2. **BudgetGuard wraps PlanUsageTracker, not a separate cost counter.** Instead of maintaining its own running cost total, BudgetGuard queries PlanUsageTracker.get_total_usage().total_cost_usd directly. This avoids duplicate state and keeps cost data in one authoritative place.\n   213→\n   214→3. **BudgetGuard is separate from CircuitBreaker.** The circuit breaker handles task failures and rate limits. The budget guard handles cost thresholds. These are orthogonal concerns and should not be merged.\n   215→\n   216→4. **CLI flags override plan YAML.** This lets users run the same plan with different budgets (e.g., more conservative overnight). The plan YAML provides defaults, the CLI provides overrides.\n   217→\n   218→5. **Pause, don't fail.** Budget exhaustion is a normal operational condition, not an error. The plan is paused, not failed, and can be resumed when more budget is available. Exit code 0 signals this.\n   219→\n   220→6. **Session-scoped spending, not weekly aggregation.** Tracking weekly spending across sessions would require reading all historical usage reports and summing them for the current billing week. This adds complexity (billing cycle detection, timezone handling). The MVP tracks spending within a single orchestrator run or pipeline session. Users can set their ceiling to account for prior spending manually.\n   221→\n   222→7. **BudgetConfig and BudgetGuard live in plan-orchestrator.py.** Following the single-file convention established by TaskResult, CircuitBreaker, and PlanUsageTracker.\n   223→\n   224→8. **No cost estimation or prediction.** The \"nice to have\" cost estimation from the backlog item is deferred. Predicting task cost requires historical data that does not yet exist. The MVP checks \"have we spent too much?\" before each task.\n   225→"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"0b6c61f0-e0f2-46a6-8260-bf0374815ece","tool_use_result":{"type":"text","file":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/docs/plans/2026-02-14-07-quota-aware-execution-design.md","content":"# Quota-Aware Execution with Weekly Budget Limits - Design Document\n\n**Goal:** Add budget awareness to the orchestrator and auto-pipeline so they can stop gracefully before exhausting the user's weekly Claude usage quota, reserving a configurable portion for interactive use.\n\n**Architecture:** Add a BudgetConfig dataclass to hold budget limits parsed from plan YAML meta or CLI flags. Add a BudgetGuard class that checks cumulative cost (from PlanUsageTracker, Feature 06) against the configured ceiling before each task. When spending exceeds the threshold, the orchestrator pauses the plan with a \"paused_quota\" status. The auto-pipeline performs a per-work-item budget check and stops processing new items when the budget is exhausted. No external quota API is required; the system uses locally-tracked cost data combined with a user-configured ceiling.\n\n**Tech Stack:** Python 3 (plan-orchestrator.py, auto-pipeline.py), YAML (plan meta.budget configuration)\n\n---\n\n## Architecture Overview\n\n### Dependency: Feature 06 (Token Usage Tracking)\n\nThis feature builds directly on the TaskUsage dataclass, PlanUsageTracker, and per-task cost data introduced by Feature 06. Specifically:\n\n- TaskResult.usage provides per-task cost via total_cost_usd\n- PlanUsageTracker.get_total_usage() provides cumulative plan cost\n- Usage report JSON files provide cross-plan session cost data\n\nFeature 06 is already implemented.\n\n### BudgetConfig Dataclass\n\nNew dataclass to hold budget configuration, placed after PlanUsageTracker in plan-orchestrator.py:\n\n    @dataclass\n    class BudgetConfig:\n        \"\"\"Budget limits for plan execution.\"\"\"\n        max_quota_percent: float = DEFAULT_MAX_QUOTA_PERCENT   # 100.0\n        quota_ceiling_usd: float = DEFAULT_QUOTA_CEILING_USD   # 0.0 = unlimited\n        reserved_budget_usd: float = DEFAULT_RESERVED_BUDGET_USD  # 0.0\n\n        @property\n        def effective_limit_usd(self) -> float:\n            \"\"\"Calculate effective spending limit in USD.\"\"\"\n            if self.quota_ceiling_usd <= 0:\n                return float('inf')\n            percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n            if self.reserved_budget_usd > 0:\n                reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n                return min(percent_limit, reserve_limit)\n            return percent_limit\n\n        @property\n        def is_enabled(self) -> bool:\n            \"\"\"Whether budget enforcement is active.\"\"\"\n            return self.quota_ceiling_usd > 0\n\nConfiguration sources (in priority order):\n1. CLI flags: --max-budget-pct, --quota-ceiling, --reserved-budget\n2. Plan YAML meta.budget block\n3. Defaults (100% / unlimited = no budget enforcement)\n\n### BudgetGuard Class\n\nStateful guard that wraps PlanUsageTracker and enforces limits. It does not maintain its own cost counter; it queries the tracker directly.\n\n    class BudgetGuard:\n        \"\"\"Checks cumulative cost against budget limits before each task.\"\"\"\n\n        def __init__(self, config: BudgetConfig, usage_tracker: PlanUsageTracker):\n            self.config = config\n            self.usage_tracker = usage_tracker\n\n        def can_proceed(self) -> tuple[bool, str]:\n            \"\"\"Check if budget allows another task.\n            Returns (can_proceed, reason_if_not).\n            \"\"\"\n            if not self.config.is_enabled:\n                return (True, \"\")\n            total = self.usage_tracker.get_total_usage()\n            spent = total.total_cost_usd\n            limit = self.config.effective_limit_usd\n            if spent >= limit:\n                pct = (spent / self.config.quota_ceiling_usd * 100) if self.config.quota_ceiling_usd > 0 else 0\n                reason = (\n                    f\"Budget limit reached: ${spent:.4f} / ${limit:.4f} \"\n                    f\"({pct:.1f}% of ${self.config.quota_ceiling_usd:.2f} ceiling)\"\n                )\n                return (False, reason)\n            return (True, \"\")\n\n        def get_usage_percent(self) -> float:\n            \"\"\"Current spending as percentage of ceiling.\"\"\"\n            if not self.config.is_enabled:\n                return 0.0\n            total = self.usage_tracker.get_total_usage()\n            return (total.total_cost_usd / self.config.quota_ceiling_usd * 100)\n\n        def format_status(self) -> str:\n            \"\"\"Format current budget status for display.\"\"\"\n            if not self.config.is_enabled:\n                return \"[Budget: unlimited]\"\n            total = self.usage_tracker.get_total_usage()\n            spent = total.total_cost_usd\n            limit = self.config.effective_limit_usd\n            pct = self.get_usage_percent()\n            return f\"[Budget: ${spent:.4f} / ${limit:.4f} ({pct:.1f}% of ceiling)]\"\n\nThe guard returns a tuple so the caller gets both the decision and a human-readable explanation.\n\n### Plan YAML Configuration\n\nBudget settings in the plan meta block:\n\n    meta:\n      name: My Feature\n      budget:\n        max_quota_percent: 90\n        quota_ceiling_usd: 100.00\n\nWhen no budget block is present, no budget enforcement occurs (backwards compatible).\n\n### CLI Flags\n\nNew orchestrator flags:\n\n    --max-budget-pct N       Maximum % of quota ceiling to use (default: 100)\n    --quota-ceiling N.NN     Weekly quota ceiling in USD (default: 0 = unlimited)\n    --reserved-budget N.NN   USD amount to reserve for interactive use (default: 0)\n\nCLI flags override plan YAML values when both are specified.\n\n### parse_budget_config Helper\n\nA helper function parses BudgetConfig from both the plan meta and CLI args:\n\n    def parse_budget_config(plan: dict, args: argparse.Namespace) -> BudgetConfig:\n        \"\"\"Parse budget configuration from plan YAML and CLI overrides.\"\"\"\n        budget_meta = plan.get(\"meta\", {}).get(\"budget\", {})\n        config = BudgetConfig(\n            max_quota_percent=budget_meta.get(\"max_quota_percent\", DEFAULT_MAX_QUOTA_PERCENT),\n            quota_ceiling_usd=budget_meta.get(\"quota_ceiling_usd\", DEFAULT_QUOTA_CEILING_USD),\n            reserved_budget_usd=budget_meta.get(\"reserved_budget_usd\", DEFAULT_RESERVED_BUDGET_USD),\n        )\n        # CLI overrides\n        if hasattr(args, 'max_budget_pct') and args.max_budget_pct is not None:\n            config.max_quota_percent = args.max_budget_pct\n        if hasattr(args, 'quota_ceiling') and args.quota_ceiling is not None:\n            config.quota_ceiling_usd = args.quota_ceiling\n        if hasattr(args, 'reserved_budget') and args.reserved_budget is not None:\n            config.reserved_budget_usd = args.reserved_budget\n        return config\n\n### Pre-Task Check in Orchestrator\n\nIn run_orchestrator(), after the existing circuit breaker check and before task execution:\n\n1. Call budget_guard.can_proceed()\n2. If False, print the reason, set meta.status to \"paused_quota\", save the plan, and break\n3. After each task completes, the usage is already recorded in usage_tracker (no extra step needed since BudgetGuard reads from it)\n\nThe check happens in the main task loop:\n- Sequential path (around line 2374, after circuit breaker check)\n- Parallel path (around line 2396, before parallel group execution)\n\n### Plan Pause Behavior\n\nWhen budget is exhausted:\n\n1. The current task completes (no mid-task interruption)\n2. Plan YAML is updated: meta.status becomes \"paused_quota\"\n3. A meta.pause_reason is written with the budget explanation\n4. The usage report is generated (from PlanUsageTracker)\n5. run_orchestrator() exits with code 0 (not a failure)\n\nA paused plan can be resumed later with --resume-from, and the budget guard re-evaluates from current spending.\n\n### Auto-Pipeline Integration\n\nThe auto-pipeline checks session-level spending across work items using SessionUsageTracker.total_cost_usd:\n\n1. Parse budget config from CLI flags (--max-budget-pct, --quota-ceiling)\n2. Create a PipelineBudgetGuard that checks SessionUsageTracker.total_cost_usd against the ceiling\n3. Before starting each new work item, check can_proceed()\n4. If budget exhausted, log the reason and break the main loop\n\nThe auto-pipeline budget check is per-work-item (coarser granularity than per-task).\n\n### Exit Codes\n\nThe orchestrator uses specific exit behavior for budget pauses:\n\n- Exit code 0: Plan paused due to budget (not a failure)\n- The auto-pipeline detects \"paused_quota\" in the plan YAML after execution\n- This is distinct from exit code 1 (real failure) and rate-limit retries\n\n---\n\n## Key Files\n\n### Modified Files\n\n| File | Change |\n|------|--------|\n| scripts/plan-orchestrator.py | BudgetConfig, BudgetGuard, parse_budget_config, pre-task check, CLI flags, plan pause logic |\n| scripts/auto-pipeline.py | PipelineBudgetGuard, per-work-item check, CLI flags |\n\n### New Files\n\n| File | Purpose |\n|------|---------|\n| tests/test_budget_guard.py | Unit tests for BudgetConfig, BudgetGuard, parse_budget_config |\n\n---\n\n## Design Decisions\n\n1. **User-configured ceiling, not API-queried quota.** There is no known programmatic API to query remaining Claude weekly quota. The pragmatic approach is a user-configured ceiling combined with locally-tracked cost. This is simple, requires no API access, and works across all plan types.\n\n2. **BudgetGuard wraps PlanUsageTracker, not a separate cost counter.** Instead of maintaining its own running cost total, BudgetGuard queries PlanUsageTracker.get_total_usage().total_cost_usd directly. This avoids duplicate state and keeps cost data in one authoritative place.\n\n3. **BudgetGuard is separate from CircuitBreaker.** The circuit breaker handles task failures and rate limits. The budget guard handles cost thresholds. These are orthogonal concerns and should not be merged.\n\n4. **CLI flags override plan YAML.** This lets users run the same plan with different budgets (e.g., more conservative overnight). The plan YAML provides defaults, the CLI provides overrides.\n\n5. **Pause, don't fail.** Budget exhaustion is a normal operational condition, not an error. The plan is paused, not failed, and can be resumed when more budget is available. Exit code 0 signals this.\n\n6. **Session-scoped spending, not weekly aggregation.** Tracking weekly spending across sessions would require reading all historical usage reports and summing them for the current billing week. This adds complexity (billing cycle detection, timezone handling). The MVP tracks spending within a single orchestrator run or pipeline session. Users can set their ceiling to account for prior spending manually.\n\n7. **BudgetConfig and BudgetGuard live in plan-orchestrator.py.** Following the single-file convention established by TaskResult, CircuitBreaker, and PlanUsageTracker.\n\n8. **No cost estimation or prediction.** The \"nice to have\" cost estimation from the backlog item is deferred. Predicting task cost requires historical data that does not yet exist. The MVP checks \"have we spent too much?\" before each task.\n","numLines":225,"startLine":1,"totalLines":225}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CHqQSP4HxQjdz6YGFp7NUB","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Fym5g5R6KYh7kcbKXoH84X","name":"Read","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/.claude/plans/07-quota-aware-execution.yaml"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2,"cache_creation_input_tokens":1061,"cache_read_input_tokens":32687,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1061},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"7620a186-0548-48aa-b434-d5ee5521bcd9"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Fym5g5R6KYh7kcbKXoH84X","type":"tool_result","content":"     1→meta:\n     2→  name: Quota-Aware Execution with Weekly Budget Limits\n     3→  description: 'Add budget awareness to the orchestrator and auto-pipeline so they\n     4→    can stop gracefully before exhausting the user''s weekly Claude usage quota. Adds\n     5→    BudgetConfig dataclass, BudgetGuard class, CLI flags, pre-task budget checks,\n     6→    plan pause logic, and auto-pipeline session budget tracking. Builds on Feature\n     7→    06 (Token Usage Tracking) which is already implemented.\n     8→\n     9→    '\n    10→  plan_doc: docs/plans/2026-02-14-07-quota-aware-execution-design.md\n    11→  created: '2026-02-14'\n    12→  max_attempts_default: 3\n    13→  validation:\n    14→    enabled: true\n    15→    run_after:\n    16→    - coder\n    17→    validators:\n    18→    - validator\n    19→    max_validation_attempts: 1\n    20→sections:\n    21→- id: phase-1\n    22→  name: Phase 1 - BudgetConfig and BudgetGuard Classes\n    23→  status: completed\n    24→  tasks:\n    25→  - id: '1.1'\n    26→    name: Add BudgetConfig dataclass and budget constants\n    27→    agent: coder\n    28→    status: completed\n    29→    description: \"In scripts/plan-orchestrator.py, add the BudgetConfig dataclass\\\n    30→      \\ and related constants.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n    31→      \\ \\nSteps:\\n1. Add three manifest constants after the existing MAX_PLAN_NAME_LENGTH\\\n    32→      \\ constant (currently at line 48):\\n\\n   DEFAULT_MAX_QUOTA_PERCENT = 100.0 \\n\\\n    33→      \\   DEFAULT_QUOTA_CEILING_USD = 0.0\\n   DEFAULT_RESERVED_BUDGET_USD = 0.0\\n\\\n    34→      \\ \\n2. Add the BudgetConfig dataclass after the PlanUsageTracker class (after\\\n    35→      \\ the write_report method). Find the end of PlanUsageTracker by searching for\\\n    36→      \\ the write_report method's return statement.\\n\\n   @dataclass\\n   class BudgetConfig:\\n\\\n    37→      \\       \\\"\\\"\\\"Budget limits for plan execution.\\n\\n       Configuration for\\\n    38→      \\ the budget guard that enforces spending limits.\\n       A ceiling of 0.0 (the\\\n    39→      \\ default) disables budget enforcement entirely.\\n       \\\"\\\"\\\"\\n       max_quota_percent:\\\n    40→      \\ float = DEFAULT_MAX_QUOTA_PERCENT\\n       quota_ceiling_usd: float = DEFAULT_QUOTA_CEILING_USD\\n\\\n    41→      \\       reserved_budget_usd: float = DEFAULT_RESERVED_BUDGET_USD\\n \\n      \\\n    42→      \\ @property\\n       def effective_limit_usd(self) -> float:\\n           \\\"\\\"\\\n    43→      \\\"Calculate effective spending limit in USD.\\\"\\\"\\\"\\n           if self.quota_ceiling_usd\\\n    44→      \\ <= 0:\\n               return float('inf')\\n           percent_limit = self.quota_ceiling_usd\\\n    45→      \\ * (self.max_quota_percent / 100.0)\\n           if self.reserved_budget_usd\\\n    46→      \\ > 0:\\n               reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\\n\\\n    47→      \\               return min(percent_limit, reserve_limit)\\n           return\\\n    48→      \\ percent_limit\\n\\n       @property\\n       def is_enabled(self) -> bool:\\n\\\n    49→      \\           \\\"\\\"\\\"Whether budget enforcement is active.\\\"\\\"\\\"\\n           return\\\n    50→      \\ self.quota_ceiling_usd > 0\\n\\n3. Verify with: python3 -c \\\"import py_compile;\\\n    51→      \\ py_compile.compile('scripts/plan-orchestrator.py', doraise=True); print('syntax\\\n    52→      \\ OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    53→    attempts: 1\n    54→    last_attempt: '2026-02-14T09:47:27.098220'\n    55→    completed_at: '2026-02-14T09:49:46.625849'\n    56→    result_message: Added 3 budget constants (DEFAULT_MAX_QUOTA_PERCENT, DEFAULT_QUOTA_CEILING_USD,\n    57→      DEFAULT_RESERVED_BUDGET_USD) after MAX_PLAN_NAME_LENGTH and BudgetConfig dataclass\n    58→      with effective_limit_usd and is_enabled properties after PlanUsageTracker.write_report.\n    59→      Syntax verified, all assertions pass.\n    60→  - id: '1.2'\n    61→    name: Add BudgetGuard class\n    62→    agent: coder\n    63→    status: completed\n    64→    depends_on:\n    65→    - '1.1'\n    66→    description: \"In scripts/plan-orchestrator.py, add the BudgetGuard class immediately\\\n    67→      \\ after the BudgetConfig dataclass.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n    68→      \\ \\nSteps:\\n1. Add BudgetGuard class right after BudgetConfig:\\n\\n   class BudgetGuard:\\n\\\n    69→      \\       \\\"\\\"\\\"Checks cumulative cost against budget limits before each task.\\n\\\n    70→      \\n       Wraps a PlanUsageTracker to read current spending. Does not maintain\\n\\\n    71→      \\       its own cost counter; queries the tracker directly to avoid duplicate\\\n    72→      \\ state.\\n       \\\"\\\"\\\"\\n\\n       def __init__(self, config: BudgetConfig, usage_tracker:\\\n    73→      \\ PlanUsageTracker) -> None:\\n           self.config = config\\n           self.usage_tracker\\\n    74→      \\ = usage_tracker\\n\\n       def can_proceed(self) -> tuple[bool, str]:\\n   \\\n    75→      \\        \\\"\\\"\\\"Check if budget allows another task.\\n           Returns (can_proceed,\\\n    76→      \\ reason_if_not).\\n           \\\"\\\"\\\"\\n           if not self.config.is_enabled:\\n\\\n    77→      \\               return (True, \\\"\\\")\\n           total = self.usage_tracker.get_total_usage()\\n\\\n    78→      \\           spent = total.total_cost_usd\\n           limit = self.config.effective_limit_usd\\n\\\n    79→      \\           if spent >= limit:\\n               pct = (spent / self.config.quota_ceiling_usd\\\n    80→      \\ * 100) if self.config.quota_ceiling_usd > 0 else 0\\n               reason\\\n    81→      \\ = (\\n                   f\\\"Budget limit reached: ${spent:.4f} / ${limit:.4f}\\\n    82→      \\ \\\"\\n                   f\\\"({pct:.1f}% of ${self.config.quota_ceiling_usd:.2f}\\\n    83→      \\ ceiling)\\\"\\n               )\\n               return (False, reason)\\n    \\\n    84→      \\       return (True, \\\"\\\")\\n\\n       def get_usage_percent(self) -> float:\\n\\\n    85→      \\           \\\"\\\"\\\"Current spending as percentage of ceiling.\\\"\\\"\\\"\\n       \\\n    86→      \\    if not self.config.is_enabled:\\n               return 0.0\\n           total\\\n    87→      \\ = self.usage_tracker.get_total_usage()\\n           return (total.total_cost_usd\\\n    88→      \\ / self.config.quota_ceiling_usd * 100)\\n\\n       def format_status(self) ->\\\n    89→      \\ str:\\n           \\\"\\\"\\\"Format current budget status for display.\\\"\\\"\\\"\\n \\\n    90→      \\          if not self.config.is_enabled:\\n               return \\\"[Budget:\\\n    91→      \\ unlimited]\\\"\\n           total = self.usage_tracker.get_total_usage()\\n  \\\n    92→      \\         spent = total.total_cost_usd\\n           limit = self.config.effective_limit_usd\\n\\\n    93→      \\           pct = self.get_usage_percent()\\n           return f\\\"[Budget: ${spent:.4f}\\\n    94→      \\ / ${limit:.4f} ({pct:.1f}% of ceiling)]\\\"\\n\\n2. Verify with: python3 -c \\\"\\\n    95→      import py_compile; py_compile.compile('scripts/plan-orchestrator.py', doraise=True);\\\n    96→      \\ print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    97→    attempts: 1\n    98→    last_attempt: '2026-02-14T09:49:48.710476'\n    99→    completed_at: '2026-02-14T09:52:51.642396'\n   100→    result_message: Added BudgetGuard class with can_proceed(), get_usage_percent(),\n   101→      and format_status() methods after BudgetConfig in plan-orchestrator.py. Wraps\n   102→      PlanUsageTracker to check cumulative cost against budget limits. Syntax verified,\n   103→      class tested OK.\n   104→  - id: '1.3'\n   105→    name: Add parse_budget_config helper function\n   106→    agent: coder\n   107→    status: completed\n   108→    depends_on:\n   109→    - '1.2'\n   110→    description: \"In scripts/plan-orchestrator.py, add the parse_budget_config helper\\\n   111→      \\ function after the BudgetGuard class.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n   112→      \\ \\nSteps:\\n1. Add the function after BudgetGuard:\\n\\n   def parse_budget_config(plan:\\\n   113→      \\ dict, args: argparse.Namespace) -> BudgetConfig:\\n       \\\"\\\"\\\"Parse budget\\\n   114→      \\ configuration from plan YAML and CLI overrides.\\n\\n       Priority: CLI flags\\\n   115→      \\ > plan YAML meta.budget > defaults.\\n       A ceiling of 0.0 means no budget\\\n   116→      \\ enforcement.\\n       \\\"\\\"\\\"\\n       budget_meta = plan.get(\\\"meta\\\", {}).get(\\\"\\\n   117→      budget\\\", {})\\n       config = BudgetConfig(\\n           max_quota_percent=budget_meta.get(\\\"\\\n   118→      max_quota_percent\\\", DEFAULT_MAX_QUOTA_PERCENT),\\n           quota_ceiling_usd=budget_meta.get(\\\"\\\n   119→      quota_ceiling_usd\\\", DEFAULT_QUOTA_CEILING_USD),\\n           reserved_budget_usd=budget_meta.get(\\\"\\\n   120→      reserved_budget_usd\\\", DEFAULT_RESERVED_BUDGET_USD),\\n       )\\n       if hasattr(args,\\\n   121→      \\ 'max_budget_pct') and args.max_budget_pct is not None:\\n           config.max_quota_percent\\\n   122→      \\ = args.max_budget_pct\\n       if hasattr(args, 'quota_ceiling') and args.quota_ceiling\\\n   123→      \\ is not None:\\n           config.quota_ceiling_usd = args.quota_ceiling\\n \\\n   124→      \\      if hasattr(args, 'reserved_budget') and args.reserved_budget is not None:\\n\\\n   125→      \\           config.reserved_budget_usd = args.reserved_budget\\n       return\\\n   126→      \\ config\\n\\n2. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n   127→      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n   128→    attempts: 1\n   129→    last_attempt: '2026-02-14T09:52:53.707169'\n   130→    completed_at: '2026-02-14T09:54:59.753512'\n   131→    result_message: 'Added parse_budget_config helper function after BudgetGuard class.\n   132→      Parses BudgetConfig from plan YAML meta.budget block with CLI flag overrides\n   133→      (priority: CLI > YAML > defaults). Syntax verified, all assertions pass.'\n   134→- id: phase-2\n   135→  name: Phase 2 - Orchestrator Integration\n   136→  status: completed\n   137→  tasks:\n   138→  - id: '2.1'\n   139→    name: Add budget CLI flags to argparse\n   140→    agent: coder\n   141→    status: completed\n   142→    depends_on:\n   143→    - '1.3'\n   144→    description: \"In scripts/plan-orchestrator.py, add three new CLI flags to the\\\n   145→      \\ argument parser in main().\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n   146→      \\ \\nSteps:\\n1. In main(), find the argparse block (currently starting around\\\n   147→      \\ line 2835). Add the following three arguments after the --skip-smoke argument:\\n\\\n   148→      \\ \\n   parser.add_argument(\\n       \\\"--max-budget-pct\\\",\\n       type=float,\\n\\\n   149→      \\       default=None,\\n       metavar=\\\"N\\\",\\n       help=\\\"Maximum percentage\\\n   150→      \\ of quota ceiling to use (default: 100, unlimited)\\\"\\n   )\\n   parser.add_argument(\\n\\\n   151→      \\       \\\"--quota-ceiling\\\",\\n       type=float,\\n       default=None,\\n   \\\n   152→      \\    metavar=\\\"N.NN\\\",\\n       help=\\\"Weekly quota ceiling in USD (default:\\\n   153→      \\ 0 = no budget enforcement)\\\"\\n   )\\n   parser.add_argument(\\n       \\\"--reserved-budget\\\"\\\n   154→      ,\\n       type=float,\\n       default=None,\\n       metavar=\\\"N.NN\\\",\\n    \\\n   155→      \\   help=\\\"USD amount to reserve for interactive use (default: 0)\\\"\\n   )\\n\\n\\\n   156→      2. Update the run_orchestrator() call at the bottom of main() to pass the new\\\n   157→      \\ args.\\n   Change the existing call to pass the full args namespace so budget\\\n   158→      \\ config\\n   can be parsed inside run_orchestrator:\\n\\n   run_orchestrator(\\n\\\n   159→      \\       plan_path=args.plan,\\n       dry_run=args.dry_run,\\n       resume_from=args.resume_from,\\n\\\n   160→      \\       single_task=args.single_task,\\n       verbose=args.verbose,\\n      \\\n   161→      \\ parallel=args.parallel,\\n       skip_smoke=args.skip_smoke,\\n       cli_args=args\\n\\\n   162→      \\   )\\n\\n3. Update the run_orchestrator function signature to accept cli_args:\\n\\\n   163→      \\   Add cli_args: Optional[argparse.Namespace] = None as the last parameter.\\n\\\n   164→      \\n4. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n   165→      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n   166→    attempts: 1\n   167→    last_attempt: '2026-02-14T09:55:01.809556'\n   168→    completed_at: '2026-02-14T09:57:17.932707'\n   169→    result_message: 'Added --max-budget-pct, --quota-ceiling, --reserved-budget CLI\n   170→      flags to argparse in main(). Updated run_orchestrator() call to pass cli_args=args\n   171→      and updated its signature with cli_args: Optional[argparse.Namespace] = None\n   172→      parameter. Syntax verified, all 3 flags visible in --help output.'\n   173→  - id: '2.2'\n   174→    name: Integrate BudgetGuard into run_orchestrator\n   175→    agent: coder\n   176→    status: completed\n   177→    depends_on:\n   178→    - '2.1'\n   179→    description: \"In scripts/plan-orchestrator.py, wire BudgetGuard into the main\\\n   180→      \\ orchestration loop.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n   181→      \\ \\nSteps:\\n1. In run_orchestrator(), after the usage_tracker = PlanUsageTracker()\\\n   182→      \\ line\\n   (currently around line 2371), parse budget config and create the\\\n   183→      \\ guard:\\n\\n   # Parse budget configuration from plan YAML + CLI overrides\\n\\\n   184→      \\   budget_config = parse_budget_config(plan, cli_args) if cli_args else BudgetConfig()\\n\\\n   185→      \\   budget_guard = BudgetGuard(budget_config, usage_tracker)\\n \\n2. In the header\\\n   186→      \\ print block (after the existing \\\"Dry run:\\\" line), add budget info:\\n\\n \\\n   187→      \\  if budget_config.is_enabled:\\n       print(f\\\"Budget: {budget_guard.format_status()}\\\"\\\n   188→      )\\n       print(f\\\"  Ceiling: ${budget_config.quota_ceiling_usd:.2f}, Limit:\\\n   189→      \\ ${budget_config.effective_limit_usd:.2f}\\\")\\n   else:\\n       print(\\\"Budget:\\\n   190→      \\ unlimited (no --quota-ceiling configured)\\\")\\n\\n3. In the main while loop,\\\n   191→      \\ AFTER the circuit breaker check (around line 2387)\\n   and BEFORE the parallel/sequential\\\n   192→      \\ execution blocks, add a budget check:\\n\\n   # Check budget before starting\\\n   193→      \\ next task\\n   can_proceed, budget_reason = budget_guard.can_proceed()\\n  \\\n   194→      \\ if not can_proceed:\\n       print(f\\\"\\\\n=== Budget limit reached ===\\\")\\n\\\n   195→      \\       print(f\\\"{budget_reason}\\\")\\n       print(f\\\"Plan paused. Resume with\\\n   196→      \\ --resume-from when more budget is available.\\\")\\n       # Mark plan as paused\\n\\\n   197→      \\       plan.setdefault(\\\"meta\\\", {})[\\\"status\\\"] = \\\"paused_quota\\\"\\n     \\\n   198→      \\  plan[\\\"meta\\\"][\\\"pause_reason\\\"] = budget_reason\\n       if not dry_run:\\n\\\n   199→      \\           save_plan(plan_path, plan, commit=True,\\n                    commit_message=\\\"\\\n   200→      plan: Paused due to budget limit\\\")\\n       break\\n\\n4. After each task prints\\\n   201→      \\ its usage summary line (the existing\\n   usage_tracker.record + print format_summary_line\\\n   202→      \\ blocks in both\\n   sequential and parallel paths), also print the budget status:\\n\\\n   203→      \\n   In the sequential path (after the existing usage_tracker.record block):\\n\\\n   204→      \\   if budget_config.is_enabled:\\n       print(budget_guard.format_status())\\n\\\n   205→      \\ \\n   In the parallel path (after the existing usage_tracker.record loop):\\n\\\n   206→      \\   if budget_config.is_enabled:\\n       print(budget_guard.format_status())\\n\\\n   207→      \\ \\n5. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n   208→      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n   209→    attempts: 1\n   210→    last_attempt: '2026-02-14T09:57:19.997572'\n   211→    completed_at: '2026-02-14T10:01:44.737519'\n   212→    result_message: 'Integrated BudgetGuard into run_orchestrator: moved usage_tracker\n   213→      init earlier, created budget_config and budget_guard from plan YAML + CLI overrides,\n   214→      added budget info to header print block, added pre-task budget check in main\n   215→      loop (pauses plan with paused_quota status on limit), and added budget status\n   216→      prints after task usage summaries in both sequential and parallel paths. Syntax\n   217→      verified, runtime assertions pass.'\n   218→- id: phase-3\n   219→  name: Phase 3 - Auto-Pipeline Integration\n   220→  status: pending\n   221→  tasks:\n   222→  - id: '3.1'\n   223→    name: Add PipelineBudgetGuard and CLI flags to auto-pipeline\n   224→    agent: coder\n   225→    status: in_progress\n   226→    depends_on:\n   227→    - '1.1'\n   228→    description: \"In scripts/auto-pipeline.py, add budget awareness to the pipeline.\\n\\\n   229→      \\ \\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\n\\\n   230→      Steps:\\n 1. Add budget constants after the existing RATE_LIMIT_DEFAULT_WAIT_SECONDS\\n\\\n   231→      \\   constant (around line 60):\\n\\n   DEFAULT_MAX_QUOTA_PERCENT = 100.0\\n   DEFAULT_QUOTA_CEILING_USD\\\n   232→      \\ = 0.0\\n   DEFAULT_RESERVED_BUDGET_USD = 0.0\\n \\n2. Add a PipelineBudgetGuard\\\n   233→      \\ class after SessionUsageTracker (after the\\n   write_session_report method).\\\n   234→      \\ This is simpler than the orchestrator's\\n   BudgetGuard because it reads from\\\n   235→      \\ SessionUsageTracker.total_cost_usd:\\n \\n   class PipelineBudgetGuard:\\n  \\\n   236→      \\     \\\"\\\"\\\"Checks session-level cost against budget limits before each work\\\n   237→      \\ item.\\\"\\\"\\\"\\n\\n       def __init__(self, max_quota_percent: float, quota_ceiling_usd:\\\n   238→      \\ float,\\n                    reserved_budget_usd: float = 0.0) -> None:\\n \\\n   239→      \\          self.max_quota_percent = max_quota_percent\\n           self.quota_ceiling_usd\\\n   240→      \\ = quota_ceiling_usd\\n           self.reserved_budget_usd = reserved_budget_usd\\n\\\n   241→      \\n       @property\\n       def is_enabled(self) -> bool:\\n           return\\\n   242→      \\ self.quota_ceiling_usd > 0\\n\\n       @property\\n       def effective_limit_usd(self)\\\n   243→      \\ -> float:\\n           if self.quota_ceiling_usd <= 0:\\n               return\\\n   244→      \\ float('inf')\\n           percent_limit = self.quota_ceiling_usd * (self.max_quota_percent\\\n   245→      \\ / 100.0)\\n           if self.reserved_budget_usd > 0:\\n               reserve_limit\\\n   246→      \\ = self.quota_ceiling_usd - self.reserved_budget_usd\\n               return\\\n   247→      \\ min(percent_limit, reserve_limit)\\n           return percent_limit\\n\\n   \\\n   248→      \\    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\\n \\\n   249→      \\          \\\"\\\"\\\"Check if session budget allows another work item.\\\"\\\"\\\"\\n \\\n   250→      \\          if not self.is_enabled:\\n               return (True, \\\"\\\")\\n   \\\n   251→      \\        limit = self.effective_limit_usd\\n           if session_cost_usd >=\\\n   252→      \\ limit:\\n               pct = (session_cost_usd / self.quota_ceiling_usd *\\\n   253→      \\ 100)\\n               reason = (\\n                   f\\\"Session budget limit\\\n   254→      \\ reached: ${session_cost_usd:.4f} / ${limit:.4f} \\\"\\n                   f\\\"\\\n   255→      ({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\\\"\\n               )\\n\\\n   256→      \\               return (False, reason)\\n           return (True, \\\"\\\")\\n\\n3.\\\n   257→      \\ Add CLI flags to the argparse block in main() (after the --verbose argument):\\n\\\n   258→      \\n   parser.add_argument(\\n       \\\"--max-budget-pct\\\", type=float, default=None,\\n\\\n   259→      \\       metavar=\\\"N\\\",\\n       help=\\\"Maximum percentage of quota ceiling to\\\n   260→      \\ use (default: 100)\\\"\\n   )\\n   parser.add_argument(\\n       \\\"--quota-ceiling\\\"\\\n   261→      , type=float, default=None,\\n       metavar=\\\"N.NN\\\",\\n       help=\\\"Weekly\\\n   262→      \\ quota ceiling in USD (default: 0 = no limit)\\\"\\n   )\\n   parser.add_argument(\\n\\\n   263→      \\       \\\"--reserved-budget\\\", type=float, default=None,\\n       metavar=\\\"\\\n   264→      N.NN\\\",\\n       help=\\\"USD to reserve for interactive use (default: 0)\\\"\\n \\\n   265→      \\  )\\n\\n4. Pass the budget args to main_loop. Update main_loop signature:\\n\\\n   266→      \\   def main_loop(dry_run: bool = False, once: bool = False,\\n             \\\n   267→      \\   budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\\n\\n5. In main(),\\\n   268→      \\ create the guard and pass it:\\n   budget_guard = PipelineBudgetGuard(\\n  \\\n   269→      \\     max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\\n\\\n   270→      \\       quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\\n\\\n   271→      \\       reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\\n\\\n   272→      \\   )\\n   main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)\\n\\\n   273→      \\n6. In main_loop(), before each call to process_item(), add a budget check:\\n\\\n   274→      \\   if budget_guard and budget_guard.is_enabled:\\n       can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\\n\\\n   275→      \\       if not can_go:\\n           log(f\\\"Budget limit reached: {reason}\\\")\\n\\\n   276→      \\           log(\\\"Stopping pipeline due to budget constraint.\\\")\\n         \\\n   277→      \\  break\\n \\n   This check should go in two places:\\n   a) In the --once path,\\\n   278→      \\ before processing the single item\\n   b) In the continuous loop, before each\\\n   279→      \\ item in the for loop\\n\\n7. In the startup log, add budget info:\\n   if budget_guard\\\n   280→      \\ and budget_guard.is_enabled:\\n       log(f\\\"  Budget: ${budget_guard.effective_limit_usd:.2f}\\\n   281→      \\ limit\\\")\\n\\n8. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/auto-pipeline.py',\\\n   282→      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/auto-pipeline.py\\n\"\n   283→    attempts: 1\n   284→    last_attempt: '2026-02-14T10:01:46.802005'\n   285→- id: phase-4\n   286→  name: Phase 4 - Unit Tests\n   287→  status: pending\n   288→  tasks:\n   289→  - id: '4.1'\n   290→    name: Write unit tests for BudgetConfig\n   291→    agent: coder\n   292→    status: pending\n   293→    depends_on:\n   294→    - '1.3'\n   295→    description: \"Create tests/test_budget_guard.py with unit tests for the BudgetConfig\\\n   296→      \\ dataclass.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n   297→      \\ \\nSteps:\\n1. Create tests/test_budget_guard.py with these test cases:\\n\\n\\\n   298→      \\   a. test_budget_config_defaults: Create BudgetConfig() with no args.\\n  \\\n   299→      \\    Verify max_quota_percent=100.0, quota_ceiling_usd=0.0,\\n      reserved_budget_usd=0.0,\\\n   300→      \\ is_enabled=False, effective_limit_usd=inf.\\n\\n   b. test_budget_config_with_ceiling:\\\n   301→      \\ Create BudgetConfig(\\n      quota_ceiling_usd=100.0, max_quota_percent=90.0).\\n\\\n   302→      \\      Verify is_enabled=True, effective_limit_usd=90.0.\\n\\n   c. test_budget_config_with_reserved:\\\n   303→      \\ Create BudgetConfig(\\n      quota_ceiling_usd=100.0, reserved_budget_usd=15.0).\\n\\\n   304→      \\      Verify effective_limit_usd=85.0 (100 - 15).\\n\\n   d. test_budget_config_percent_and_reserved_takes_minimum:\\\n   305→      \\ Create\\n      BudgetConfig(quota_ceiling_usd=100.0, max_quota_percent=90.0,\\n\\\n   306→      \\      reserved_budget_usd=5.0). Verify effective_limit_usd=90.0\\n      (min\\\n   307→      \\ of 90.0 percent limit and 95.0 reserve limit = 90.0).\\n\\n   e. test_budget_config_reserved_more_restrictive:\\\n   308→      \\ Create\\n      BudgetConfig(quota_ceiling_usd=100.0, max_quota_percent=95.0,\\n\\\n   309→      \\      reserved_budget_usd=20.0). Verify effective_limit_usd=80.0\\n      (min\\\n   310→      \\ of 95.0 percent limit and 80.0 reserve limit = 80.0).\\n\\n   f. test_budget_config_zero_ceiling_not_enabled:\\\n   311→      \\ BudgetConfig(\\n      quota_ceiling_usd=0.0). Verify is_enabled=False.\\n \\n\\\n   312→      2. Import using importlib (same pattern as test_token_usage.py):\\n   import\\\n   313→      \\ importlib.util\\n   spec = importlib.util.spec_from_file_location(\\n      \\\n   314→      \\ \\\"plan_orchestrator\\\", \\\"scripts/plan-orchestrator.py\\\")\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n   315→      \\   spec.loader.exec_module(mod)\\n   BudgetConfig = mod.BudgetConfig\\n\\n 3.\\\n   316→      \\ Run: python3 -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n\\\n   317→      \\ \\nFiles: tests/test_budget_guard.py\\n\"\n   318→  - id: '4.2'\n   319→    name: Write unit tests for BudgetGuard\n   320→    agent: coder\n   321→    status: pending\n   322→    depends_on:\n   323→    - '1.2'\n   324→    - '4.1'\n   325→    description: \"Add BudgetGuard tests to tests/test_budget_guard.py.\\n\\nReference:\\\n   326→      \\ docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n1. Add\\\n   327→      \\ BudgetGuard to the import block:\\n   BudgetGuard = mod.BudgetGuard\\n   PlanUsageTracker\\\n   328→      \\ = mod.PlanUsageTracker\\n   TaskUsage = mod.TaskUsage\\n\\n2. Add these test\\\n   329→      \\ cases:\\n\\n   a. test_guard_unlimited_always_proceeds: Create BudgetGuard with\\n\\\n   330→      \\      BudgetConfig() (default, no ceiling). Record some cost in the\\n     \\\n   331→      \\ tracker. Verify can_proceed() returns (True, \\\"\\\").\\n\\n   b. test_guard_under_budget_proceeds:\\\n   332→      \\ Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=10.0, max_quota_percent=90.0).\\n\\\n   333→      \\      Record a task with cost $5. Verify can_proceed() returns (True, \\\"\\\"\\\n   334→      ).\\n \\n   c. test_guard_at_limit_stops: Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=10.0,\\\n   335→      \\ max_quota_percent=90.0) (limit=$9).\\n      Record tasks totaling $9.00. Verify\\\n   336→      \\ can_proceed() returns (False, reason)\\n      where reason contains \\\"Budget\\\n   337→      \\ limit reached\\\".\\n\\n   d. test_guard_over_limit_stops: Create BudgetGuard\\\n   338→      \\ with\\n      BudgetConfig(quota_ceiling_usd=10.0, max_quota_percent=90.0).\\n\\\n   339→      \\      Record tasks totaling $9.50. Verify can_proceed() returns (False, reason).\\n\\\n   340→      \\n   e. test_guard_usage_percent: Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=100.0).\\\n   341→      \\ Record a task costing $25.\\n      Verify get_usage_percent() returns 25.0.\\n\\\n   342→      \\ \\n   f. test_guard_format_status_unlimited: Create BudgetGuard with\\n    \\\n   343→      \\  BudgetConfig(). Verify format_status() returns \\\"[Budget: unlimited]\\\".\\n\\\n   344→      \\n   g. test_guard_format_status_with_ceiling: Create BudgetGuard with\\n   \\\n   345→      \\   BudgetConfig(quota_ceiling_usd=100.0). Record a task costing $30.\\n    \\\n   346→      \\  Verify format_status() contains \\\"$30\\\" and \\\"$100\\\".\\n \\n3. Run: python3\\\n   347→      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n \\nFiles: tests/test_budget_guard.py\\n\"\n   348→  - id: '4.3'\n   349→    name: Write unit tests for parse_budget_config\n   350→    agent: coder\n   351→    status: pending\n   352→    depends_on:\n   353→    - '1.3'\n   354→    - '4.2'\n   355→    description: \"Add parse_budget_config tests to tests/test_budget_guard.py.\\n\\n\\\n   356→      \\ Reference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n\\\n   357→      \\ 1. Add parse_budget_config to the import block:\\n   parse_budget_config =\\\n   358→      \\ mod.parse_budget_config\\n\\n2. Add these test cases:\\n\\n   a. test_parse_budget_config_defaults:\\\n   359→      \\ Call parse_budget_config with\\n      an empty plan dict and a mock args namespace\\\n   360→      \\ with all budget attrs\\n      set to None. Verify all defaults.\\n\\n   b. test_parse_budget_config_from_plan_yaml:\\\n   361→      \\ Call parse_budget_config\\n      with plan = {\\\"meta\\\": {\\\"budget\\\": {\\\"max_quota_percent\\\"\\\n   362→      : 80,\\n      \\\"quota_ceiling_usd\\\": 50.0}}} and mock args (all None).\\n    \\\n   363→      \\  Verify max_quota_percent=80, quota_ceiling_usd=50.0.\\n\\n   c. test_parse_budget_config_cli_overrides_yaml:\\\n   364→      \\ Call parse_budget_config\\n      with plan containing budget meta AND mock\\\n   365→      \\ args with max_budget_pct=75\\n      and quota_ceiling=25.0. Verify CLI values\\\n   366→      \\ take precedence.\\n\\n   d. test_parse_budget_config_partial_cli_override: Call\\\n   367→      \\ parse_budget_config\\n      with plan containing full budget meta but mock\\\n   368→      \\ args where only\\n      quota_ceiling=30.0 is set (others None). Verify quota_ceiling_usd=30.0\\n\\\n   369→      \\      but max_quota_percent comes from YAML.\\n\\n   For mock args, use argparse.Namespace\\\n   370→      \\ directly:\\n   mock_args = argparse.Namespace(max_budget_pct=None, quota_ceiling=None,\\n\\\n   371→      \\                                  reserved_budget=None)\\n \\n3. Run: python3\\\n   372→      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n \\nFiles: tests/test_budget_guard.py\\n\"\n   373→  - id: '4.4'\n   374→    name: Write unit tests for PipelineBudgetGuard\n   375→    agent: coder\n   376→    status: pending\n   377→    depends_on:\n   378→    - '3.1'\n   379→    - '4.3'\n   380→    description: \"Add PipelineBudgetGuard tests to tests/test_budget_guard.py.\\n\\n\\\n   381→      \\ Reference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n\\\n   382→      \\ 1. Add PipelineBudgetGuard to the import block. Since it is in auto-pipeline.py,\\n\\\n   383→      \\   use a separate importlib load:\\n   spec_ap = importlib.util.spec_from_file_location(\\n\\\n   384→      \\       \\\"auto_pipeline\\\", \\\"scripts/auto-pipeline.py\\\")\\n   mod_ap = importlib.util.module_from_spec(spec_ap)\\n\\\n   385→      \\   spec_ap.loader.exec_module(mod_ap)\\n   PipelineBudgetGuard = mod_ap.PipelineBudgetGuard\\n\\\n   386→      \\ \\n2. Add these test cases:\\n\\n   a. test_pipeline_guard_disabled: Create PipelineBudgetGuard\\\n   387→      \\ with\\n      default values (ceiling=0). Verify is_enabled=False, can_proceed(50.0)\\n\\\n   388→      \\      returns (True, \\\"\\\").\\n\\n   b. test_pipeline_guard_under_budget: Create\\\n   389→      \\ PipelineBudgetGuard(\\n      max_quota_percent=100, quota_ceiling_usd=50.0).\\\n   390→      \\ Verify\\n      can_proceed(30.0) returns (True, \\\"\\\").\\n\\n   c. test_pipeline_guard_over_budget:\\\n   391→      \\ Create PipelineBudgetGuard(\\n      max_quota_percent=90, quota_ceiling_usd=50.0).\\\n   392→      \\ Effective limit=$45.\\n      Verify can_proceed(45.0) returns (False, reason).\\n\\\n   393→      \\ \\n   d. test_pipeline_guard_effective_limit: Create PipelineBudgetGuard(\\n\\\n   394→      \\      max_quota_percent=80, quota_ceiling_usd=100.0, reserved_budget_usd=10.0).\\n\\\n   395→      \\      Verify effective_limit_usd=80.0 (min of 80 and 90).\\n\\n3. Run: python3\\\n   396→      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n\\nFiles: tests/test_budget_guard.py\\n\"\n   397→- id: phase-5\n   398→  name: Phase 5 - Verification\n   399→  status: pending\n   400→  tasks:\n   401→  - id: '5.1'\n   402→    name: Verify syntax, tests, and dry-run\n   403→    agent: code-reviewer\n   404→    status: pending\n   405→    depends_on:\n   406→    - '2.2'\n   407→    - '3.1'\n   408→    - '4.4'\n   409→    description: \"Run verification checks to confirm the quota-aware execution feature\\\n   410→      \\ works correctly.\\n\\nSteps:\\n1. Check Python syntax for both scripts:\\n   python3\\\n   411→      \\ -c \\\"import py_compile; py_compile.compile('scripts/auto-pipeline.py', doraise=True);\\\n   412→      \\ py_compile.compile('scripts/plan-orchestrator.py', doraise=True)\\\"\\n\\n2. Run\\\n   413→      \\ unit tests:\\n   python3 -m pytest tests/ 2>/dev/null || echo 'No test suite\\\n   414→      \\ configured'\\n\\n3. Verify the BudgetConfig and BudgetGuard classes exist:\\n\\\n   415→      \\   python3 -c \\\"\\n   import importlib.util\\n   spec = importlib.util.spec_from_file_location('po',\\\n   416→      \\ 'scripts/plan-orchestrator.py')\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n   417→      \\   spec.loader.exec_module(mod)\\n   assert hasattr(mod, 'BudgetConfig'), 'BudgetConfig\\\n   418→      \\ not found'\\n   assert hasattr(mod, 'BudgetGuard'), 'BudgetGuard not found'\\n\\\n   419→      \\   assert hasattr(mod, 'parse_budget_config'), 'parse_budget_config not found'\\n\\\n   420→      \\   # Verify BudgetConfig properties\\n   cfg = mod.BudgetConfig(quota_ceiling_usd=100.0,\\\n   421→      \\ max_quota_percent=90.0)\\n   assert cfg.is_enabled, 'is_enabled should be True'\\n\\\n   422→      \\   assert cfg.effective_limit_usd == 90.0, f'effective_limit expected 90, got\\\n   423→      \\ {cfg.effective_limit_usd}'\\n   print('All orchestrator classes verified')\\n\\\n   424→      \\   \\\"\\n\\n4. Verify PipelineBudgetGuard in auto-pipeline:\\n   python3 -c \\\"\\n\\\n   425→      \\   import importlib.util\\n   spec = importlib.util.spec_from_file_location('ap',\\\n   426→      \\ 'scripts/auto-pipeline.py')\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n   427→      \\   spec.loader.exec_module(mod)\\n   assert hasattr(mod, 'PipelineBudgetGuard'),\\\n   428→      \\ 'PipelineBudgetGuard not found'\\n   guard = mod.PipelineBudgetGuard(90.0,\\\n   429→      \\ 100.0)\\n   assert guard.is_enabled, 'is_enabled should be True'\\n   assert\\\n   430→      \\ guard.effective_limit_usd == 90.0\\n   print('PipelineBudgetGuard verified')\\n\\\n   431→      \\   \\\"\\n\\n5. Verify CLI flags exist:\\n   python3 scripts/plan-orchestrator.py\\\n   432→      \\ --help 2>&1 | grep -c 'budget\\\\|ceiling'\\n   (should return at least 3 matches)\\n\\\n   433→      \\n   python3 scripts/auto-pipeline.py --help 2>&1 | grep -c 'budget\\\\|ceiling'\\n\\\n   434→      \\   (should return at least 3 matches)\\n\\n6. Run orchestrator dry-run:\\n   python3\\\n   435→      \\ scripts/plan-orchestrator.py --plan .claude/plans/sample-plan.yaml --dry-run\\n\\\n   436→      \\ \\n7. Run orchestrator dry-run with budget flags:\\n   python3 scripts/plan-orchestrator.py\\\n   437→      \\ --plan .claude/plans/sample-plan.yaml --dry-run --quota-ceiling 50.0 --max-budget-pct\\\n   438→      \\ 90\\n\\nIf any check fails, report the failure with specific details.\\n\\nFiles:\\\n   439→      \\ scripts/plan-orchestrator.py, scripts/auto-pipeline.py, tests/test_budget_guard.py\\n\"\n   440→"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"7e6b05f8-543d-488d-aebd-478ea971248d","tool_use_result":{"type":"text","file":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/.claude/plans/07-quota-aware-execution.yaml","content":"meta:\n  name: Quota-Aware Execution with Weekly Budget Limits\n  description: 'Add budget awareness to the orchestrator and auto-pipeline so they\n    can stop gracefully before exhausting the user''s weekly Claude usage quota. Adds\n    BudgetConfig dataclass, BudgetGuard class, CLI flags, pre-task budget checks,\n    plan pause logic, and auto-pipeline session budget tracking. Builds on Feature\n    06 (Token Usage Tracking) which is already implemented.\n\n    '\n  plan_doc: docs/plans/2026-02-14-07-quota-aware-execution-design.md\n  created: '2026-02-14'\n  max_attempts_default: 3\n  validation:\n    enabled: true\n    run_after:\n    - coder\n    validators:\n    - validator\n    max_validation_attempts: 1\nsections:\n- id: phase-1\n  name: Phase 1 - BudgetConfig and BudgetGuard Classes\n  status: completed\n  tasks:\n  - id: '1.1'\n    name: Add BudgetConfig dataclass and budget constants\n    agent: coder\n    status: completed\n    description: \"In scripts/plan-orchestrator.py, add the BudgetConfig dataclass\\\n      \\ and related constants.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. Add three manifest constants after the existing MAX_PLAN_NAME_LENGTH\\\n      \\ constant (currently at line 48):\\n\\n   DEFAULT_MAX_QUOTA_PERCENT = 100.0 \\n\\\n      \\   DEFAULT_QUOTA_CEILING_USD = 0.0\\n   DEFAULT_RESERVED_BUDGET_USD = 0.0\\n\\\n      \\ \\n2. Add the BudgetConfig dataclass after the PlanUsageTracker class (after\\\n      \\ the write_report method). Find the end of PlanUsageTracker by searching for\\\n      \\ the write_report method's return statement.\\n\\n   @dataclass\\n   class BudgetConfig:\\n\\\n      \\       \\\"\\\"\\\"Budget limits for plan execution.\\n\\n       Configuration for\\\n      \\ the budget guard that enforces spending limits.\\n       A ceiling of 0.0 (the\\\n      \\ default) disables budget enforcement entirely.\\n       \\\"\\\"\\\"\\n       max_quota_percent:\\\n      \\ float = DEFAULT_MAX_QUOTA_PERCENT\\n       quota_ceiling_usd: float = DEFAULT_QUOTA_CEILING_USD\\n\\\n      \\       reserved_budget_usd: float = DEFAULT_RESERVED_BUDGET_USD\\n \\n      \\\n      \\ @property\\n       def effective_limit_usd(self) -> float:\\n           \\\"\\\"\\\n      \\\"Calculate effective spending limit in USD.\\\"\\\"\\\"\\n           if self.quota_ceiling_usd\\\n      \\ <= 0:\\n               return float('inf')\\n           percent_limit = self.quota_ceiling_usd\\\n      \\ * (self.max_quota_percent / 100.0)\\n           if self.reserved_budget_usd\\\n      \\ > 0:\\n               reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\\n\\\n      \\               return min(percent_limit, reserve_limit)\\n           return\\\n      \\ percent_limit\\n\\n       @property\\n       def is_enabled(self) -> bool:\\n\\\n      \\           \\\"\\\"\\\"Whether budget enforcement is active.\\\"\\\"\\\"\\n           return\\\n      \\ self.quota_ceiling_usd > 0\\n\\n3. Verify with: python3 -c \\\"import py_compile;\\\n      \\ py_compile.compile('scripts/plan-orchestrator.py', doraise=True); print('syntax\\\n      \\ OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T09:47:27.098220'\n    completed_at: '2026-02-14T09:49:46.625849'\n    result_message: Added 3 budget constants (DEFAULT_MAX_QUOTA_PERCENT, DEFAULT_QUOTA_CEILING_USD,\n      DEFAULT_RESERVED_BUDGET_USD) after MAX_PLAN_NAME_LENGTH and BudgetConfig dataclass\n      with effective_limit_usd and is_enabled properties after PlanUsageTracker.write_report.\n      Syntax verified, all assertions pass.\n  - id: '1.2'\n    name: Add BudgetGuard class\n    agent: coder\n    status: completed\n    depends_on:\n    - '1.1'\n    description: \"In scripts/plan-orchestrator.py, add the BudgetGuard class immediately\\\n      \\ after the BudgetConfig dataclass.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. Add BudgetGuard class right after BudgetConfig:\\n\\n   class BudgetGuard:\\n\\\n      \\       \\\"\\\"\\\"Checks cumulative cost against budget limits before each task.\\n\\\n      \\n       Wraps a PlanUsageTracker to read current spending. Does not maintain\\n\\\n      \\       its own cost counter; queries the tracker directly to avoid duplicate\\\n      \\ state.\\n       \\\"\\\"\\\"\\n\\n       def __init__(self, config: BudgetConfig, usage_tracker:\\\n      \\ PlanUsageTracker) -> None:\\n           self.config = config\\n           self.usage_tracker\\\n      \\ = usage_tracker\\n\\n       def can_proceed(self) -> tuple[bool, str]:\\n   \\\n      \\        \\\"\\\"\\\"Check if budget allows another task.\\n           Returns (can_proceed,\\\n      \\ reason_if_not).\\n           \\\"\\\"\\\"\\n           if not self.config.is_enabled:\\n\\\n      \\               return (True, \\\"\\\")\\n           total = self.usage_tracker.get_total_usage()\\n\\\n      \\           spent = total.total_cost_usd\\n           limit = self.config.effective_limit_usd\\n\\\n      \\           if spent >= limit:\\n               pct = (spent / self.config.quota_ceiling_usd\\\n      \\ * 100) if self.config.quota_ceiling_usd > 0 else 0\\n               reason\\\n      \\ = (\\n                   f\\\"Budget limit reached: ${spent:.4f} / ${limit:.4f}\\\n      \\ \\\"\\n                   f\\\"({pct:.1f}% of ${self.config.quota_ceiling_usd:.2f}\\\n      \\ ceiling)\\\"\\n               )\\n               return (False, reason)\\n    \\\n      \\       return (True, \\\"\\\")\\n\\n       def get_usage_percent(self) -> float:\\n\\\n      \\           \\\"\\\"\\\"Current spending as percentage of ceiling.\\\"\\\"\\\"\\n       \\\n      \\    if not self.config.is_enabled:\\n               return 0.0\\n           total\\\n      \\ = self.usage_tracker.get_total_usage()\\n           return (total.total_cost_usd\\\n      \\ / self.config.quota_ceiling_usd * 100)\\n\\n       def format_status(self) ->\\\n      \\ str:\\n           \\\"\\\"\\\"Format current budget status for display.\\\"\\\"\\\"\\n \\\n      \\          if not self.config.is_enabled:\\n               return \\\"[Budget:\\\n      \\ unlimited]\\\"\\n           total = self.usage_tracker.get_total_usage()\\n  \\\n      \\         spent = total.total_cost_usd\\n           limit = self.config.effective_limit_usd\\n\\\n      \\           pct = self.get_usage_percent()\\n           return f\\\"[Budget: ${spent:.4f}\\\n      \\ / ${limit:.4f} ({pct:.1f}% of ceiling)]\\\"\\n\\n2. Verify with: python3 -c \\\"\\\n      import py_compile; py_compile.compile('scripts/plan-orchestrator.py', doraise=True);\\\n      \\ print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T09:49:48.710476'\n    completed_at: '2026-02-14T09:52:51.642396'\n    result_message: Added BudgetGuard class with can_proceed(), get_usage_percent(),\n      and format_status() methods after BudgetConfig in plan-orchestrator.py. Wraps\n      PlanUsageTracker to check cumulative cost against budget limits. Syntax verified,\n      class tested OK.\n  - id: '1.3'\n    name: Add parse_budget_config helper function\n    agent: coder\n    status: completed\n    depends_on:\n    - '1.2'\n    description: \"In scripts/plan-orchestrator.py, add the parse_budget_config helper\\\n      \\ function after the BudgetGuard class.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. Add the function after BudgetGuard:\\n\\n   def parse_budget_config(plan:\\\n      \\ dict, args: argparse.Namespace) -> BudgetConfig:\\n       \\\"\\\"\\\"Parse budget\\\n      \\ configuration from plan YAML and CLI overrides.\\n\\n       Priority: CLI flags\\\n      \\ > plan YAML meta.budget > defaults.\\n       A ceiling of 0.0 means no budget\\\n      \\ enforcement.\\n       \\\"\\\"\\\"\\n       budget_meta = plan.get(\\\"meta\\\", {}).get(\\\"\\\n      budget\\\", {})\\n       config = BudgetConfig(\\n           max_quota_percent=budget_meta.get(\\\"\\\n      max_quota_percent\\\", DEFAULT_MAX_QUOTA_PERCENT),\\n           quota_ceiling_usd=budget_meta.get(\\\"\\\n      quota_ceiling_usd\\\", DEFAULT_QUOTA_CEILING_USD),\\n           reserved_budget_usd=budget_meta.get(\\\"\\\n      reserved_budget_usd\\\", DEFAULT_RESERVED_BUDGET_USD),\\n       )\\n       if hasattr(args,\\\n      \\ 'max_budget_pct') and args.max_budget_pct is not None:\\n           config.max_quota_percent\\\n      \\ = args.max_budget_pct\\n       if hasattr(args, 'quota_ceiling') and args.quota_ceiling\\\n      \\ is not None:\\n           config.quota_ceiling_usd = args.quota_ceiling\\n \\\n      \\      if hasattr(args, 'reserved_budget') and args.reserved_budget is not None:\\n\\\n      \\           config.reserved_budget_usd = args.reserved_budget\\n       return\\\n      \\ config\\n\\n2. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T09:52:53.707169'\n    completed_at: '2026-02-14T09:54:59.753512'\n    result_message: 'Added parse_budget_config helper function after BudgetGuard class.\n      Parses BudgetConfig from plan YAML meta.budget block with CLI flag overrides\n      (priority: CLI > YAML > defaults). Syntax verified, all assertions pass.'\n- id: phase-2\n  name: Phase 2 - Orchestrator Integration\n  status: completed\n  tasks:\n  - id: '2.1'\n    name: Add budget CLI flags to argparse\n    agent: coder\n    status: completed\n    depends_on:\n    - '1.3'\n    description: \"In scripts/plan-orchestrator.py, add three new CLI flags to the\\\n      \\ argument parser in main().\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. In main(), find the argparse block (currently starting around\\\n      \\ line 2835). Add the following three arguments after the --skip-smoke argument:\\n\\\n      \\ \\n   parser.add_argument(\\n       \\\"--max-budget-pct\\\",\\n       type=float,\\n\\\n      \\       default=None,\\n       metavar=\\\"N\\\",\\n       help=\\\"Maximum percentage\\\n      \\ of quota ceiling to use (default: 100, unlimited)\\\"\\n   )\\n   parser.add_argument(\\n\\\n      \\       \\\"--quota-ceiling\\\",\\n       type=float,\\n       default=None,\\n   \\\n      \\    metavar=\\\"N.NN\\\",\\n       help=\\\"Weekly quota ceiling in USD (default:\\\n      \\ 0 = no budget enforcement)\\\"\\n   )\\n   parser.add_argument(\\n       \\\"--reserved-budget\\\"\\\n      ,\\n       type=float,\\n       default=None,\\n       metavar=\\\"N.NN\\\",\\n    \\\n      \\   help=\\\"USD amount to reserve for interactive use (default: 0)\\\"\\n   )\\n\\n\\\n      2. Update the run_orchestrator() call at the bottom of main() to pass the new\\\n      \\ args.\\n   Change the existing call to pass the full args namespace so budget\\\n      \\ config\\n   can be parsed inside run_orchestrator:\\n\\n   run_orchestrator(\\n\\\n      \\       plan_path=args.plan,\\n       dry_run=args.dry_run,\\n       resume_from=args.resume_from,\\n\\\n      \\       single_task=args.single_task,\\n       verbose=args.verbose,\\n      \\\n      \\ parallel=args.parallel,\\n       skip_smoke=args.skip_smoke,\\n       cli_args=args\\n\\\n      \\   )\\n\\n3. Update the run_orchestrator function signature to accept cli_args:\\n\\\n      \\   Add cli_args: Optional[argparse.Namespace] = None as the last parameter.\\n\\\n      \\n4. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T09:55:01.809556'\n    completed_at: '2026-02-14T09:57:17.932707'\n    result_message: 'Added --max-budget-pct, --quota-ceiling, --reserved-budget CLI\n      flags to argparse in main(). Updated run_orchestrator() call to pass cli_args=args\n      and updated its signature with cli_args: Optional[argparse.Namespace] = None\n      parameter. Syntax verified, all 3 flags visible in --help output.'\n  - id: '2.2'\n    name: Integrate BudgetGuard into run_orchestrator\n    agent: coder\n    status: completed\n    depends_on:\n    - '2.1'\n    description: \"In scripts/plan-orchestrator.py, wire BudgetGuard into the main\\\n      \\ orchestration loop.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. In run_orchestrator(), after the usage_tracker = PlanUsageTracker()\\\n      \\ line\\n   (currently around line 2371), parse budget config and create the\\\n      \\ guard:\\n\\n   # Parse budget configuration from plan YAML + CLI overrides\\n\\\n      \\   budget_config = parse_budget_config(plan, cli_args) if cli_args else BudgetConfig()\\n\\\n      \\   budget_guard = BudgetGuard(budget_config, usage_tracker)\\n \\n2. In the header\\\n      \\ print block (after the existing \\\"Dry run:\\\" line), add budget info:\\n\\n \\\n      \\  if budget_config.is_enabled:\\n       print(f\\\"Budget: {budget_guard.format_status()}\\\"\\\n      )\\n       print(f\\\"  Ceiling: ${budget_config.quota_ceiling_usd:.2f}, Limit:\\\n      \\ ${budget_config.effective_limit_usd:.2f}\\\")\\n   else:\\n       print(\\\"Budget:\\\n      \\ unlimited (no --quota-ceiling configured)\\\")\\n\\n3. In the main while loop,\\\n      \\ AFTER the circuit breaker check (around line 2387)\\n   and BEFORE the parallel/sequential\\\n      \\ execution blocks, add a budget check:\\n\\n   # Check budget before starting\\\n      \\ next task\\n   can_proceed, budget_reason = budget_guard.can_proceed()\\n  \\\n      \\ if not can_proceed:\\n       print(f\\\"\\\\n=== Budget limit reached ===\\\")\\n\\\n      \\       print(f\\\"{budget_reason}\\\")\\n       print(f\\\"Plan paused. Resume with\\\n      \\ --resume-from when more budget is available.\\\")\\n       # Mark plan as paused\\n\\\n      \\       plan.setdefault(\\\"meta\\\", {})[\\\"status\\\"] = \\\"paused_quota\\\"\\n     \\\n      \\  plan[\\\"meta\\\"][\\\"pause_reason\\\"] = budget_reason\\n       if not dry_run:\\n\\\n      \\           save_plan(plan_path, plan, commit=True,\\n                    commit_message=\\\"\\\n      plan: Paused due to budget limit\\\")\\n       break\\n\\n4. After each task prints\\\n      \\ its usage summary line (the existing\\n   usage_tracker.record + print format_summary_line\\\n      \\ blocks in both\\n   sequential and parallel paths), also print the budget status:\\n\\\n      \\n   In the sequential path (after the existing usage_tracker.record block):\\n\\\n      \\   if budget_config.is_enabled:\\n       print(budget_guard.format_status())\\n\\\n      \\ \\n   In the parallel path (after the existing usage_tracker.record loop):\\n\\\n      \\   if budget_config.is_enabled:\\n       print(budget_guard.format_status())\\n\\\n      \\ \\n5. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/plan-orchestrator.py',\\\n      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/plan-orchestrator.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T09:57:19.997572'\n    completed_at: '2026-02-14T10:01:44.737519'\n    result_message: 'Integrated BudgetGuard into run_orchestrator: moved usage_tracker\n      init earlier, created budget_config and budget_guard from plan YAML + CLI overrides,\n      added budget info to header print block, added pre-task budget check in main\n      loop (pauses plan with paused_quota status on limit), and added budget status\n      prints after task usage summaries in both sequential and parallel paths. Syntax\n      verified, runtime assertions pass.'\n- id: phase-3\n  name: Phase 3 - Auto-Pipeline Integration\n  status: pending\n  tasks:\n  - id: '3.1'\n    name: Add PipelineBudgetGuard and CLI flags to auto-pipeline\n    agent: coder\n    status: in_progress\n    depends_on:\n    - '1.1'\n    description: \"In scripts/auto-pipeline.py, add budget awareness to the pipeline.\\n\\\n      \\ \\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\n\\\n      Steps:\\n 1. Add budget constants after the existing RATE_LIMIT_DEFAULT_WAIT_SECONDS\\n\\\n      \\   constant (around line 60):\\n\\n   DEFAULT_MAX_QUOTA_PERCENT = 100.0\\n   DEFAULT_QUOTA_CEILING_USD\\\n      \\ = 0.0\\n   DEFAULT_RESERVED_BUDGET_USD = 0.0\\n \\n2. Add a PipelineBudgetGuard\\\n      \\ class after SessionUsageTracker (after the\\n   write_session_report method).\\\n      \\ This is simpler than the orchestrator's\\n   BudgetGuard because it reads from\\\n      \\ SessionUsageTracker.total_cost_usd:\\n \\n   class PipelineBudgetGuard:\\n  \\\n      \\     \\\"\\\"\\\"Checks session-level cost against budget limits before each work\\\n      \\ item.\\\"\\\"\\\"\\n\\n       def __init__(self, max_quota_percent: float, quota_ceiling_usd:\\\n      \\ float,\\n                    reserved_budget_usd: float = 0.0) -> None:\\n \\\n      \\          self.max_quota_percent = max_quota_percent\\n           self.quota_ceiling_usd\\\n      \\ = quota_ceiling_usd\\n           self.reserved_budget_usd = reserved_budget_usd\\n\\\n      \\n       @property\\n       def is_enabled(self) -> bool:\\n           return\\\n      \\ self.quota_ceiling_usd > 0\\n\\n       @property\\n       def effective_limit_usd(self)\\\n      \\ -> float:\\n           if self.quota_ceiling_usd <= 0:\\n               return\\\n      \\ float('inf')\\n           percent_limit = self.quota_ceiling_usd * (self.max_quota_percent\\\n      \\ / 100.0)\\n           if self.reserved_budget_usd > 0:\\n               reserve_limit\\\n      \\ = self.quota_ceiling_usd - self.reserved_budget_usd\\n               return\\\n      \\ min(percent_limit, reserve_limit)\\n           return percent_limit\\n\\n   \\\n      \\    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\\n \\\n      \\          \\\"\\\"\\\"Check if session budget allows another work item.\\\"\\\"\\\"\\n \\\n      \\          if not self.is_enabled:\\n               return (True, \\\"\\\")\\n   \\\n      \\        limit = self.effective_limit_usd\\n           if session_cost_usd >=\\\n      \\ limit:\\n               pct = (session_cost_usd / self.quota_ceiling_usd *\\\n      \\ 100)\\n               reason = (\\n                   f\\\"Session budget limit\\\n      \\ reached: ${session_cost_usd:.4f} / ${limit:.4f} \\\"\\n                   f\\\"\\\n      ({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\\\"\\n               )\\n\\\n      \\               return (False, reason)\\n           return (True, \\\"\\\")\\n\\n3.\\\n      \\ Add CLI flags to the argparse block in main() (after the --verbose argument):\\n\\\n      \\n   parser.add_argument(\\n       \\\"--max-budget-pct\\\", type=float, default=None,\\n\\\n      \\       metavar=\\\"N\\\",\\n       help=\\\"Maximum percentage of quota ceiling to\\\n      \\ use (default: 100)\\\"\\n   )\\n   parser.add_argument(\\n       \\\"--quota-ceiling\\\"\\\n      , type=float, default=None,\\n       metavar=\\\"N.NN\\\",\\n       help=\\\"Weekly\\\n      \\ quota ceiling in USD (default: 0 = no limit)\\\"\\n   )\\n   parser.add_argument(\\n\\\n      \\       \\\"--reserved-budget\\\", type=float, default=None,\\n       metavar=\\\"\\\n      N.NN\\\",\\n       help=\\\"USD to reserve for interactive use (default: 0)\\\"\\n \\\n      \\  )\\n\\n4. Pass the budget args to main_loop. Update main_loop signature:\\n\\\n      \\   def main_loop(dry_run: bool = False, once: bool = False,\\n             \\\n      \\   budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\\n\\n5. In main(),\\\n      \\ create the guard and pass it:\\n   budget_guard = PipelineBudgetGuard(\\n  \\\n      \\     max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\\n\\\n      \\       quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\\n\\\n      \\       reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\\n\\\n      \\   )\\n   main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)\\n\\\n      \\n6. In main_loop(), before each call to process_item(), add a budget check:\\n\\\n      \\   if budget_guard and budget_guard.is_enabled:\\n       can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\\n\\\n      \\       if not can_go:\\n           log(f\\\"Budget limit reached: {reason}\\\")\\n\\\n      \\           log(\\\"Stopping pipeline due to budget constraint.\\\")\\n         \\\n      \\  break\\n \\n   This check should go in two places:\\n   a) In the --once path,\\\n      \\ before processing the single item\\n   b) In the continuous loop, before each\\\n      \\ item in the for loop\\n\\n7. In the startup log, add budget info:\\n   if budget_guard\\\n      \\ and budget_guard.is_enabled:\\n       log(f\\\"  Budget: ${budget_guard.effective_limit_usd:.2f}\\\n      \\ limit\\\")\\n\\n8. Verify with: python3 -c \\\"import py_compile; py_compile.compile('scripts/auto-pipeline.py',\\\n      \\ doraise=True); print('syntax OK')\\\"\\n\\nFiles: scripts/auto-pipeline.py\\n\"\n    attempts: 1\n    last_attempt: '2026-02-14T10:01:46.802005'\n- id: phase-4\n  name: Phase 4 - Unit Tests\n  status: pending\n  tasks:\n  - id: '4.1'\n    name: Write unit tests for BudgetConfig\n    agent: coder\n    status: pending\n    depends_on:\n    - '1.3'\n    description: \"Create tests/test_budget_guard.py with unit tests for the BudgetConfig\\\n      \\ dataclass.\\n\\nReference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\\n      \\ \\nSteps:\\n1. Create tests/test_budget_guard.py with these test cases:\\n\\n\\\n      \\   a. test_budget_config_defaults: Create BudgetConfig() with no args.\\n  \\\n      \\    Verify max_quota_percent=100.0, quota_ceiling_usd=0.0,\\n      reserved_budget_usd=0.0,\\\n      \\ is_enabled=False, effective_limit_usd=inf.\\n\\n   b. test_budget_config_with_ceiling:\\\n      \\ Create BudgetConfig(\\n      quota_ceiling_usd=100.0, max_quota_percent=90.0).\\n\\\n      \\      Verify is_enabled=True, effective_limit_usd=90.0.\\n\\n   c. test_budget_config_with_reserved:\\\n      \\ Create BudgetConfig(\\n      quota_ceiling_usd=100.0, reserved_budget_usd=15.0).\\n\\\n      \\      Verify effective_limit_usd=85.0 (100 - 15).\\n\\n   d. test_budget_config_percent_and_reserved_takes_minimum:\\\n      \\ Create\\n      BudgetConfig(quota_ceiling_usd=100.0, max_quota_percent=90.0,\\n\\\n      \\      reserved_budget_usd=5.0). Verify effective_limit_usd=90.0\\n      (min\\\n      \\ of 90.0 percent limit and 95.0 reserve limit = 90.0).\\n\\n   e. test_budget_config_reserved_more_restrictive:\\\n      \\ Create\\n      BudgetConfig(quota_ceiling_usd=100.0, max_quota_percent=95.0,\\n\\\n      \\      reserved_budget_usd=20.0). Verify effective_limit_usd=80.0\\n      (min\\\n      \\ of 95.0 percent limit and 80.0 reserve limit = 80.0).\\n\\n   f. test_budget_config_zero_ceiling_not_enabled:\\\n      \\ BudgetConfig(\\n      quota_ceiling_usd=0.0). Verify is_enabled=False.\\n \\n\\\n      2. Import using importlib (same pattern as test_token_usage.py):\\n   import\\\n      \\ importlib.util\\n   spec = importlib.util.spec_from_file_location(\\n      \\\n      \\ \\\"plan_orchestrator\\\", \\\"scripts/plan-orchestrator.py\\\")\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n      \\   spec.loader.exec_module(mod)\\n   BudgetConfig = mod.BudgetConfig\\n\\n 3.\\\n      \\ Run: python3 -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n\\\n      \\ \\nFiles: tests/test_budget_guard.py\\n\"\n  - id: '4.2'\n    name: Write unit tests for BudgetGuard\n    agent: coder\n    status: pending\n    depends_on:\n    - '1.2'\n    - '4.1'\n    description: \"Add BudgetGuard tests to tests/test_budget_guard.py.\\n\\nReference:\\\n      \\ docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n1. Add\\\n      \\ BudgetGuard to the import block:\\n   BudgetGuard = mod.BudgetGuard\\n   PlanUsageTracker\\\n      \\ = mod.PlanUsageTracker\\n   TaskUsage = mod.TaskUsage\\n\\n2. Add these test\\\n      \\ cases:\\n\\n   a. test_guard_unlimited_always_proceeds: Create BudgetGuard with\\n\\\n      \\      BudgetConfig() (default, no ceiling). Record some cost in the\\n     \\\n      \\ tracker. Verify can_proceed() returns (True, \\\"\\\").\\n\\n   b. test_guard_under_budget_proceeds:\\\n      \\ Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=10.0, max_quota_percent=90.0).\\n\\\n      \\      Record a task with cost $5. Verify can_proceed() returns (True, \\\"\\\"\\\n      ).\\n \\n   c. test_guard_at_limit_stops: Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=10.0,\\\n      \\ max_quota_percent=90.0) (limit=$9).\\n      Record tasks totaling $9.00. Verify\\\n      \\ can_proceed() returns (False, reason)\\n      where reason contains \\\"Budget\\\n      \\ limit reached\\\".\\n\\n   d. test_guard_over_limit_stops: Create BudgetGuard\\\n      \\ with\\n      BudgetConfig(quota_ceiling_usd=10.0, max_quota_percent=90.0).\\n\\\n      \\      Record tasks totaling $9.50. Verify can_proceed() returns (False, reason).\\n\\\n      \\n   e. test_guard_usage_percent: Create BudgetGuard with\\n      BudgetConfig(quota_ceiling_usd=100.0).\\\n      \\ Record a task costing $25.\\n      Verify get_usage_percent() returns 25.0.\\n\\\n      \\ \\n   f. test_guard_format_status_unlimited: Create BudgetGuard with\\n    \\\n      \\  BudgetConfig(). Verify format_status() returns \\\"[Budget: unlimited]\\\".\\n\\\n      \\n   g. test_guard_format_status_with_ceiling: Create BudgetGuard with\\n   \\\n      \\   BudgetConfig(quota_ceiling_usd=100.0). Record a task costing $30.\\n    \\\n      \\  Verify format_status() contains \\\"$30\\\" and \\\"$100\\\".\\n \\n3. Run: python3\\\n      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n \\nFiles: tests/test_budget_guard.py\\n\"\n  - id: '4.3'\n    name: Write unit tests for parse_budget_config\n    agent: coder\n    status: pending\n    depends_on:\n    - '1.3'\n    - '4.2'\n    description: \"Add parse_budget_config tests to tests/test_budget_guard.py.\\n\\n\\\n      \\ Reference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n\\\n      \\ 1. Add parse_budget_config to the import block:\\n   parse_budget_config =\\\n      \\ mod.parse_budget_config\\n\\n2. Add these test cases:\\n\\n   a. test_parse_budget_config_defaults:\\\n      \\ Call parse_budget_config with\\n      an empty plan dict and a mock args namespace\\\n      \\ with all budget attrs\\n      set to None. Verify all defaults.\\n\\n   b. test_parse_budget_config_from_plan_yaml:\\\n      \\ Call parse_budget_config\\n      with plan = {\\\"meta\\\": {\\\"budget\\\": {\\\"max_quota_percent\\\"\\\n      : 80,\\n      \\\"quota_ceiling_usd\\\": 50.0}}} and mock args (all None).\\n    \\\n      \\  Verify max_quota_percent=80, quota_ceiling_usd=50.0.\\n\\n   c. test_parse_budget_config_cli_overrides_yaml:\\\n      \\ Call parse_budget_config\\n      with plan containing budget meta AND mock\\\n      \\ args with max_budget_pct=75\\n      and quota_ceiling=25.0. Verify CLI values\\\n      \\ take precedence.\\n\\n   d. test_parse_budget_config_partial_cli_override: Call\\\n      \\ parse_budget_config\\n      with plan containing full budget meta but mock\\\n      \\ args where only\\n      quota_ceiling=30.0 is set (others None). Verify quota_ceiling_usd=30.0\\n\\\n      \\      but max_quota_percent comes from YAML.\\n\\n   For mock args, use argparse.Namespace\\\n      \\ directly:\\n   mock_args = argparse.Namespace(max_budget_pct=None, quota_ceiling=None,\\n\\\n      \\                                  reserved_budget=None)\\n \\n3. Run: python3\\\n      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n \\nFiles: tests/test_budget_guard.py\\n\"\n  - id: '4.4'\n    name: Write unit tests for PipelineBudgetGuard\n    agent: coder\n    status: pending\n    depends_on:\n    - '3.1'\n    - '4.3'\n    description: \"Add PipelineBudgetGuard tests to tests/test_budget_guard.py.\\n\\n\\\n      \\ Reference: docs/plans/2026-02-14-07-quota-aware-execution-design.md\\n\\nSteps:\\n\\\n      \\ 1. Add PipelineBudgetGuard to the import block. Since it is in auto-pipeline.py,\\n\\\n      \\   use a separate importlib load:\\n   spec_ap = importlib.util.spec_from_file_location(\\n\\\n      \\       \\\"auto_pipeline\\\", \\\"scripts/auto-pipeline.py\\\")\\n   mod_ap = importlib.util.module_from_spec(spec_ap)\\n\\\n      \\   spec_ap.loader.exec_module(mod_ap)\\n   PipelineBudgetGuard = mod_ap.PipelineBudgetGuard\\n\\\n      \\ \\n2. Add these test cases:\\n\\n   a. test_pipeline_guard_disabled: Create PipelineBudgetGuard\\\n      \\ with\\n      default values (ceiling=0). Verify is_enabled=False, can_proceed(50.0)\\n\\\n      \\      returns (True, \\\"\\\").\\n\\n   b. test_pipeline_guard_under_budget: Create\\\n      \\ PipelineBudgetGuard(\\n      max_quota_percent=100, quota_ceiling_usd=50.0).\\\n      \\ Verify\\n      can_proceed(30.0) returns (True, \\\"\\\").\\n\\n   c. test_pipeline_guard_over_budget:\\\n      \\ Create PipelineBudgetGuard(\\n      max_quota_percent=90, quota_ceiling_usd=50.0).\\\n      \\ Effective limit=$45.\\n      Verify can_proceed(45.0) returns (False, reason).\\n\\\n      \\ \\n   d. test_pipeline_guard_effective_limit: Create PipelineBudgetGuard(\\n\\\n      \\      max_quota_percent=80, quota_ceiling_usd=100.0, reserved_budget_usd=10.0).\\n\\\n      \\      Verify effective_limit_usd=80.0 (min of 80 and 90).\\n\\n3. Run: python3\\\n      \\ -m pytest tests/test_budget_guard.py -v\\n   Fix any failures.\\n\\nFiles: tests/test_budget_guard.py\\n\"\n- id: phase-5\n  name: Phase 5 - Verification\n  status: pending\n  tasks:\n  - id: '5.1'\n    name: Verify syntax, tests, and dry-run\n    agent: code-reviewer\n    status: pending\n    depends_on:\n    - '2.2'\n    - '3.1'\n    - '4.4'\n    description: \"Run verification checks to confirm the quota-aware execution feature\\\n      \\ works correctly.\\n\\nSteps:\\n1. Check Python syntax for both scripts:\\n   python3\\\n      \\ -c \\\"import py_compile; py_compile.compile('scripts/auto-pipeline.py', doraise=True);\\\n      \\ py_compile.compile('scripts/plan-orchestrator.py', doraise=True)\\\"\\n\\n2. Run\\\n      \\ unit tests:\\n   python3 -m pytest tests/ 2>/dev/null || echo 'No test suite\\\n      \\ configured'\\n\\n3. Verify the BudgetConfig and BudgetGuard classes exist:\\n\\\n      \\   python3 -c \\\"\\n   import importlib.util\\n   spec = importlib.util.spec_from_file_location('po',\\\n      \\ 'scripts/plan-orchestrator.py')\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n      \\   spec.loader.exec_module(mod)\\n   assert hasattr(mod, 'BudgetConfig'), 'BudgetConfig\\\n      \\ not found'\\n   assert hasattr(mod, 'BudgetGuard'), 'BudgetGuard not found'\\n\\\n      \\   assert hasattr(mod, 'parse_budget_config'), 'parse_budget_config not found'\\n\\\n      \\   # Verify BudgetConfig properties\\n   cfg = mod.BudgetConfig(quota_ceiling_usd=100.0,\\\n      \\ max_quota_percent=90.0)\\n   assert cfg.is_enabled, 'is_enabled should be True'\\n\\\n      \\   assert cfg.effective_limit_usd == 90.0, f'effective_limit expected 90, got\\\n      \\ {cfg.effective_limit_usd}'\\n   print('All orchestrator classes verified')\\n\\\n      \\   \\\"\\n\\n4. Verify PipelineBudgetGuard in auto-pipeline:\\n   python3 -c \\\"\\n\\\n      \\   import importlib.util\\n   spec = importlib.util.spec_from_file_location('ap',\\\n      \\ 'scripts/auto-pipeline.py')\\n   mod = importlib.util.module_from_spec(spec)\\n\\\n      \\   spec.loader.exec_module(mod)\\n   assert hasattr(mod, 'PipelineBudgetGuard'),\\\n      \\ 'PipelineBudgetGuard not found'\\n   guard = mod.PipelineBudgetGuard(90.0,\\\n      \\ 100.0)\\n   assert guard.is_enabled, 'is_enabled should be True'\\n   assert\\\n      \\ guard.effective_limit_usd == 90.0\\n   print('PipelineBudgetGuard verified')\\n\\\n      \\   \\\"\\n\\n5. Verify CLI flags exist:\\n   python3 scripts/plan-orchestrator.py\\\n      \\ --help 2>&1 | grep -c 'budget\\\\|ceiling'\\n   (should return at least 3 matches)\\n\\\n      \\n   python3 scripts/auto-pipeline.py --help 2>&1 | grep -c 'budget\\\\|ceiling'\\n\\\n      \\   (should return at least 3 matches)\\n\\n6. Run orchestrator dry-run:\\n   python3\\\n      \\ scripts/plan-orchestrator.py --plan .claude/plans/sample-plan.yaml --dry-run\\n\\\n      \\ \\n7. Run orchestrator dry-run with budget flags:\\n   python3 scripts/plan-orchestrator.py\\\n      \\ --plan .claude/plans/sample-plan.yaml --dry-run --quota-ceiling 50.0 --max-budget-pct\\\n      \\ 90\\n\\nIf any check fails, report the failure with specific details.\\n\\nFiles:\\\n      \\ scripts/plan-orchestrator.py, scripts/auto-pipeline.py, tests/test_budget_guard.py\\n\"\n","numLines":440,"startLine":1,"totalLines":440}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01BXcw2toevDDgz1tkiHeP6H","type":"message","role":"assistant","content":[{"type":"text","text":"Now I have a clear understanding of the task. Let me set up my todo list and start implementing."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":37790,"cache_read_input_tokens":33748,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":37790},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"a0c62fd5-0e18-46a4-8804-ac5199c86a08"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01BXcw2toevDDgz1tkiHeP6H","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012WKify8LY4zbhTnY1Wp6mZ","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"in_progress","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"pending","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":37790,"cache_read_input_tokens":33748,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":37790},"output_tokens":5,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"48d85a65-cbed-463d-b9ff-3b10ed714640"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012WKify8LY4zbhTnY1Wp6mZ","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"6ce5869d-d36f-4a0c-848a-cf3b56d63969","tool_use_result":{"oldTodos":[],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"in_progress","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"pending","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01XFWePcEVV7xHxwQQRMvDXd","type":"message","role":"assistant","content":[{"type":"text","text":"`★ Insight ─────────────────────────────────────`\nThe auto-pipeline has a simpler budget model than the orchestrator. The orchestrator's `BudgetGuard` wraps a `PlanUsageTracker` (per-task granularity), while `PipelineBudgetGuard` just takes a raw `session_cost_usd` float from `SessionUsageTracker.total_cost_usd` (per-work-item granularity). This makes sense because the pipeline operates at a coarser level — it processes entire backlog items, not individual tasks.\n`─────────────────────────────────────────────────`\n\n**Step 1: Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS (line 60)**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":361,"cache_read_input_tokens":71538,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":361},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"adb220f5-4cb3-4d77-b630-04089cabc1e5"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01XFWePcEVV7xHxwQQRMvDXd","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019fN6ju4qwKfTvWRwEqek1U","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\n\n\ndef load_orchestrator_config() -> dict:","new_string":"RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":361,"cache_read_input_tokens":71538,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":361},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"9d2fba97-2792-4243-88a1-a70003a1ec1d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019fN6ju4qwKfTvWRwEqek1U","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"df4e415f-ab4e-4d12-98d7-04dc3b8a4f5f","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\n\n\ndef load_orchestrator_config() -> dict:","newString":"RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":58,"oldLines":6,"newStart":58,"newLines":9,"lines":[" CHILD_SHUTDOWN_TIMEOUT_SECONDS = 10"," RATE_LIMIT_BUFFER_SECONDS = 30"," RATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600","+DEFAULT_MAX_QUOTA_PERCENT = 100.0","+DEFAULT_QUOTA_CEILING_USD = 0.0","+DEFAULT_RESERVED_BUDGET_USD = 0.0"," "," "," def load_orchestrator_config() -> dict:"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016484mPVyH4qyCHfxCnmmWz","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_0159WwajxN46MQrj4XBAWZTD","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"in_progress","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":454,"cache_read_input_tokens":71899,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":454},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"18e29acb-c838-41fe-9442-3af46e48828f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_0159WwajxN46MQrj4XBAWZTD","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"7292a8d5-1018-4f88-ad01-97babe6a8db3","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"in_progress","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"pending","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"in_progress","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01F9ZrBSH9qd4bKjFKSWQNci","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 2: Add PipelineBudgetGuard class after SessionUsageTracker.write_session_report**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":339,"cache_read_input_tokens":72353,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":339},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"50303206-a88e-481a-a8be-fd37918ed402"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01F9ZrBSH9qd4bKjFKSWQNci","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01RqLJprKADrbdfNWzk4u13V","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\ndef run_child_process(","new_string":"        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process("},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":339,"cache_read_input_tokens":72353,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":339},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"0f343467-bd0a-406e-88c0-d4f599f6c2c6"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01RqLJprKADrbdfNWzk4u13V","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b244b66b-f044-4cc8-af72-9195a834254e","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\ndef run_child_process(","newString":"        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":557,"oldLines":6,"newStart":557,"newLines":44,"lines":["         return str(report_path)"," "," ","+class PipelineBudgetGuard:","+    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"","+","+    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,","+                 reserved_budget_usd: float = 0.0) -> None:","+        self.max_quota_percent = max_quota_percent","+        self.quota_ceiling_usd = quota_ceiling_usd","+        self.reserved_budget_usd = reserved_budget_usd","+","+    @property","+    def is_enabled(self) -> bool:","+        return self.quota_ceiling_usd > 0","+","+    @property","+    def effective_limit_usd(self) -> float:","+        if self.quota_ceiling_usd <= 0:","+            return float('inf')","+        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)","+        if self.reserved_budget_usd > 0:","+            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd","+            return min(percent_limit, reserve_limit)","+        return percent_limit","+","+    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:","+        \"\"\"Check if session budget allows another work item.\"\"\"","+        if not self.is_enabled:","+            return (True, \"\")","+        limit = self.effective_limit_usd","+        if session_cost_usd >= limit:","+            pct = (session_cost_usd / self.quota_ceiling_usd * 100)","+            reason = (","+                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"","+                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"","+            )","+            return (False, reason)","+        return (True, \"\")","+","+"," def run_child_process(","     cmd: list[str],","     description: str,"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_014YgCqfpcwwybjfSGiiNPA3","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01G27oaJ9rvmKEUJmbrecw7T","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"in_progress","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":753,"cache_read_input_tokens":72692,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":753},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"ff3416ea-2982-4c90-9507-e4f581dc442d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01G27oaJ9rvmKEUJmbrecw7T","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"1b23445e-180d-487e-8a03-69d626c727c4","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"in_progress","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"pending","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"in_progress","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Rq4QBsZmSKAz4BFtEdHwJE","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 3: Add CLI flags to argparse in main() (after --verbose)**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":339,"cache_read_input_tokens":73445,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":339},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"94ea4985-51c0-4e25-abad-9fcb97f9aa85"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Rq4QBsZmSKAz4BFtEdHwJE","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YQfGoVWuDReJq39yPqo5Ue","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()","new_string":"    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":339,"cache_read_input_tokens":73445,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":339},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b339ffb0-4918-4d67-9e5c-dc5aaa994109"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YQfGoVWuDReJq39yPqo5Ue","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"e9a5c6a9-6f9b-439f-b670-24455eb5b180","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()","newString":"    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1644,"oldLines":6,"newStart":1644,"newLines":21,"lines":["         \"--verbose\", action=\"store_true\",","         help=\"Stream all child output in detail\",","     )","+    parser.add_argument(","+        \"--max-budget-pct\", type=float, default=None,","+        metavar=\"N\",","+        help=\"Maximum percentage of quota ceiling to use (default: 100)\",","+    )","+    parser.add_argument(","+        \"--quota-ceiling\", type=float, default=None,","+        metavar=\"N.NN\",","+        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",","+    )","+    parser.add_argument(","+        \"--reserved-budget\", type=float, default=None,","+        metavar=\"N.NN\",","+        help=\"USD to reserve for interactive use (default: 0)\",","+    )","     args = parser.parse_args()","     VERBOSE = args.verbose"," "]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QGxyas3NDHbd6U6yqdEjWh","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CGDgHFWuSwEoMJzak7uwTR","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"in_progress","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":435,"cache_read_input_tokens":73784,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":435},"output_tokens":19,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"c877bdec-567b-47fc-84c2-3c134284a118"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CGDgHFWuSwEoMJzak7uwTR","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"3a6ad7fb-7cf7-4d7b-b1b8-f6cde3234b9b","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"in_progress","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard","status":"pending","activeForm":"Updating main_loop signature"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"in_progress","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JzNfdhJnLsoEy3dqJn3U3d","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 4: Update main_loop signature and Step 5: Create guard in main() and pass it**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":74219,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"18fd5785-43f3-4856-a38d-ede493fabed5"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JzNfdhJnLsoEy3dqJn3U3d","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Ch73JUcLViH8cGdbKzzJCX","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"def main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"","new_string":"def main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\""},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":74219,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"1068703b-96df-49e2-9fdf-7d97c7a02492"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Ch73JUcLViH8cGdbKzzJCX","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"0efdc36c-81a1-4d89-9035-a1516c06c9f7","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"def main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"","newString":"def main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1468,"oldLines":7,"newStart":1468,"newLines":8,"lines":["     return False"," "," ","-def main_loop(dry_run: bool = False, once: bool = False) -> None:","+def main_loop(dry_run: bool = False, once: bool = False,","+              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:","     \"\"\"Main processing loop with filesystem watching.\"\"\"","     global VERBOSE, CLAUDE_CMD"," "]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015Djab1gVcgVSXkxBpa7rKF","type":"message","role":"assistant","content":[{"type":"text","text":"Now update the main() function to create the guard and pass it:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":74565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":280},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"252da3a6-2be0-4d25-a61c-a5ae6917219d"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_015Djab1gVcgVSXkxBpa7rKF","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01CGnDgPtrDamrEsMneTDoqb","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"    main_loop(dry_run=args.dry_run, once=args.once)","new_string":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":280,"cache_read_input_tokens":74565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":280},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"4abd3efa-3bda-4f3b-b43b-8f0f8b2ac599"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01CGnDgPtrDamrEsMneTDoqb","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"6dc2303d-ee38-4b62-b17a-aca28af64686","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"    main_loop(dry_run=args.dry_run, once=args.once)","newString":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    main_loop(dry_run=args.dry_run, once=args.once)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1672,"oldLines":7,"newStart":1672,"newLines":12,"lines":["     log(f\"  Feature backlog: {FEATURE_DIR}/\")","     log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")"," ","-    main_loop(dry_run=args.dry_run, once=args.once)","+    budget_guard = PipelineBudgetGuard(","+        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,","+        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,","+        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,","+    )","+    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)"," "," "," if __name__ == \"__main__\":"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01LRjdCxTqRGaxvK9oTzrS4m","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YC9o4uES2eSYsMjcAgKHpN","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"in_progress","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":329,"cache_read_input_tokens":74845,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":329},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"755082b4-8bfb-44e8-9325-70c19bb68e98"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YC9o4uES2eSYsMjcAgKHpN","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"3a957756-d182-460f-bfd5-28e585d809de","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"in_progress","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"pending","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"in_progress","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01B4syQbTg2fvfXuE57wH999","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 6: Add budget checks in main_loop before process_item calls**\n\nI need to add budget checks in two places:\n1. In the `--once` path, before processing the single item\n2. In the continuous loop, before each item in the for loop\n\nLet me re-read the main_loop to find the exact locations after all edits."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":75174,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"186ca444-292f-4f5d-9faa-3a859af19d65"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01B4syQbTg2fvfXuE57wH999","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DMnCgwEyZiQu3xHSU5JgHw","name":"Read","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","offset":1520,"limit":80},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":75174,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":4,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"00a296e3-d76f-41be-ab93-fe55c42fb1fa"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DMnCgwEyZiQu3xHSU5JgHw","type":"tool_result","content":"  1520→            if not dry_run:\n  1521→                in_progress_plans = find_in_progress_plans()\n  1522→                if in_progress_plans:\n  1523→                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n  1524→                    for plan_path in in_progress_plans:\n  1525→                        if check_stop_requested():\n  1526→                            break\n  1527→                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n  1528→                        success = execute_plan(plan_path, dry_run)\n  1529→                        # Record usage from the orchestrator's report\n  1530→                        plan_basename = os.path.basename(plan_path)\n  1531→                        _try_record_usage(\n  1532→                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n  1533→                        )\n  1534→                        if not success:\n  1535→                            failed_items.add(plan_path)\n  1536→                            log(f\"In-progress plan failed: {plan_path}\")\n  1537→                    # After resuming, re-scan (completed plans may unblock new items)\n  1538→                    continue\n  1539→\n  1540→            # Scan for items (with dependency filtering)\n  1541→            items = scan_all_backlogs()\n  1542→\n  1543→            # Filter out previously failed items\n  1544→            items = [i for i in items if i.path not in failed_items]\n  1545→\n  1546→            if items:\n  1547→                log(f\"Found {len(items)} item(s) to process\")\n  1548→                for i, item in enumerate(items, 1):\n  1549→                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n  1550→            else:\n  1551→                if once:\n  1552→                    log(\"No items to process. Exiting (--once mode).\")\n  1553→                    break\n  1554→                log(f\"No items to process. Watching for new items...\")\n  1555→                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n  1556→\n  1557→                # Wait for either a filesystem event or the safety scan interval\n  1558→                new_item_event.clear()\n  1559→                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n  1560→                continue\n  1561→\n  1562→            # In --once mode, process only the first item then exit\n  1563→            if once:\n  1564→                item = items[0]\n  1565→                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n  1566→                success = process_item(item, dry_run, session_tracker)\n  1567→                if not success:\n  1568→                    log(f\"Item failed: {item.slug}\")\n  1569→                log(\"Exiting (--once mode).\")\n  1570→                break\n  1571→\n  1572→            # Process items one at a time\n  1573→            for item in items:\n  1574→                if check_stop_requested():\n  1575→                    log(\"Stop requested. Finishing current session.\")\n  1576→                    break\n  1577→\n  1578→                success = process_item(item, dry_run, session_tracker)\n  1579→                if not success:\n  1580→                    failed_items.add(item.path)\n  1581→                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n  1582→\n  1583→            # Brief pause before next scan\n  1584→            time.sleep(2)\n  1585→\n  1586→    except KeyboardInterrupt:\n  1587→        log(\"Interrupted by user. Shutting down...\")\n  1588→    finally:\n  1589→        # Print and write session usage summary\n  1590→        print(session_tracker.format_session_summary())\n  1591→        session_report = session_tracker.write_session_report()\n  1592→        if session_report:\n  1593→            log(f\"[Session usage report: {session_report}]\")\n  1594→\n  1595→        if not once:\n  1596→            observer.stop()\n  1597→            observer.join(timeout=5)\n  1598→        restore_terminal_settings()\n  1599→        log(\"Auto-pipeline stopped.\")"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"ae49de9e-39e8-4d68-8f06-e1a7b63e17c9","tool_use_result":{"type":"text","file":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","content":"            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")","numLines":80,"startLine":1520,"totalLines":1685}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Sv9DRLBugSo7yLe53kxQ1T","type":"message","role":"assistant","content":[{"type":"text","text":"Now I'll add the budget check in the `--once` path (before processing the single item):"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1388,"cache_read_input_tokens":75520,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1388},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"64226210-0c0e-4c3b-917a-86be0cfc618a"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01Sv9DRLBugSo7yLe53kxQ1T","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011VXSJUhCtXUvcBgP1ALXCb","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)","new_string":"            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":1388,"cache_read_input_tokens":75520,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":1388},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"360f0789-fb45-49c8-aed0-3361f7d09874"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011VXSJUhCtXUvcBgP1ALXCb","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"0d734804-573d-4a5a-a79b-4e0ef14601d3","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)","newString":"            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1562,"oldLines":6,"newStart":1562,"newLines":12,"lines":["             # In --once mode, process only the first item then exit","             if once:","                 item = items[0]","+                if budget_guard and budget_guard.is_enabled:","+                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)","+                    if not can_go:","+                        log(f\"Budget limit reached: {reason}\")","+                        log(\"Stopping pipeline due to budget constraint.\")","+                        break","                 log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")","                 success = process_item(item, dry_run, session_tracker)","                 if not success:"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_018pyMGFxa4PowzQczZNxXo4","type":"message","role":"assistant","content":[{"type":"text","text":"Now add the budget check in the continuous loop, before each item:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":418,"cache_read_input_tokens":76908,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":418},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"6923c236-3612-4b0d-b9db-1e7b8d4e73d9"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_018pyMGFxa4PowzQczZNxXo4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WPTuW3rNo1qsqowpzrhhN8","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)","new_string":"            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n\n                success = process_item(item, dry_run, session_tracker)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":418,"cache_read_input_tokens":76908,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":418},"output_tokens":2,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"65e3c1ec-7477-47cd-b7d6-369aac22c0c3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WPTuW3rNo1qsqowpzrhhN8","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"fb48cfaf-1278-490a-84bb-5beb2166267d","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)","newString":"            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n\n                success = process_item(item, dry_run, session_tracker)","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1581,"oldLines":6,"newStart":1581,"newLines":13,"lines":["                     log(\"Stop requested. Finishing current session.\")","                     break"," ","+                if budget_guard and budget_guard.is_enabled:","+                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)","+                    if not can_go:","+                        log(f\"Budget limit reached: {reason}\")","+                        log(\"Stopping pipeline due to budget constraint.\")","+                        break","+","                 success = process_item(item, dry_run, session_tracker)","                 if not success:","                     failed_items.add(item.path)"]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JCBoBoyKpajrwntTcdiyEQ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LH1iS8kvgn1vxJ9cUvbdv2","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"in_progress","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":385,"cache_read_input_tokens":77326,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":385},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"1bb50ebf-f497-4d96-8e58-20cd443e7fcf"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LH1iS8kvgn1vxJ9cUvbdv2","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"f6b76529-5647-43d0-8535-8b791c7ea5a4","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"in_progress","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"pending","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"in_progress","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CCCVGR3nRG8TeNBvuSTh3B","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 7: Add budget info to the startup log**\n\nLet me find the startup log section in main()."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":77711,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"0b45400d-3ee8-4a9f-a845-449c757225da"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01CCCVGR3nRG8TeNBvuSTh3B","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014DhCLjdUzuLtWM6usiwrMR","name":"Read","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","offset":1650,"limit":40},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":77711,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"70012cf8-3ccf-485b-b2a5-6823efe2249d"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014DhCLjdUzuLtWM6usiwrMR","type":"tool_result","content":"  1650→        \"--dry-run\", action=\"store_true\",\n  1651→        help=\"Show what would be processed without spawning Claude or orchestrator\",\n  1652→    )\n  1653→    parser.add_argument(\n  1654→        \"--once\", action=\"store_true\",\n  1655→        help=\"Process the first item found then exit (single-item mode)\",\n  1656→    )\n  1657→    parser.add_argument(\n  1658→        \"--verbose\", action=\"store_true\",\n  1659→        help=\"Stream all child output in detail\",\n  1660→    )\n  1661→    parser.add_argument(\n  1662→        \"--max-budget-pct\", type=float, default=None,\n  1663→        metavar=\"N\",\n  1664→        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n  1665→    )\n  1666→    parser.add_argument(\n  1667→        \"--quota-ceiling\", type=float, default=None,\n  1668→        metavar=\"N.NN\",\n  1669→        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n  1670→    )\n  1671→    parser.add_argument(\n  1672→        \"--reserved-budget\", type=float, default=None,\n  1673→        metavar=\"N.NN\",\n  1674→        help=\"USD to reserve for interactive use (default: 0)\",\n  1675→    )\n  1676→    args = parser.parse_args()\n  1677→    VERBOSE = args.verbose\n  1678→\n  1679→    # Register signal handlers\n  1680→    signal.signal(signal.SIGINT, handle_signal)\n  1681→    signal.signal(signal.SIGTERM, handle_signal)\n  1682→\n  1683→    log(\"Starting auto-pipeline\")\n  1684→    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n  1685→    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n  1686→    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n  1687→\n  1688→    budget_guard = PipelineBudgetGuard(\n  1689→        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b3c46b3b-f5ca-4774-87bb-398d7dac0ad9","tool_use_result":{"type":"text","file":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","content":"        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,","numLines":40,"startLine":1650,"totalLines":1698}}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016885VpdDE46oxy8e3bmxP9","type":"message","role":"assistant","content":[{"type":"text","text":"I need to add the budget info log after the mode line and before creating the budget_guard (or after creating it). Since the guard is created right after the log lines, I'll add the budget info after creating the guard, before calling main_loop."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":756,"cache_read_input_tokens":78057,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":756},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"5b6ba590-e8a2-47a5-a459-9854296dbbe2"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016885VpdDE46oxy8e3bmxP9","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011xU8LEjtcwGAq5KwHAtcnW","name":"Edit","input":{"replace_all":false,"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","old_string":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)","new_string":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    if budget_guard.is_enabled:\n        log(f\"  Budget: ${budget_guard.effective_limit_usd:.2f} limit\")\n\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":756,"cache_read_input_tokens":78057,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":756},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"2f51c4d0-63f8-4878-a0f7-730d2c837b44"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011xU8LEjtcwGAq5KwHAtcnW","type":"tool_result","content":"The file /Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py has been updated successfully."}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"77ec8013-fd9a-4644-b382-bd1bcc18e57a","tool_use_result":{"filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/scripts/auto-pipeline.py","oldString":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)","newString":"    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    if budget_guard.is_enabled:\n        log(f\"  Budget: ${budget_guard.effective_limit_usd:.2f} limit\")\n\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)","originalFile":"#!/usr/bin/env -S python3 -u\n\"\"\"\nAuto-Pipeline: Automated backlog processing for Claude Code.\n\nMonitors docs/defect-backlog/ and docs/feature-backlog/ for new items,\ncreates implementation plans via Claude, executes them via the plan\norchestrator, and archives completed items.\n\nUsage:\n    python scripts/auto-pipeline.py [--dry-run] [--once] [--verbose]\n\nCopyright (c) 2025 Martin Bechard [martin.bechard@DevConsult.ca]\n\"\"\"\n\nimport argparse\nimport json\nimport os\nimport re\nimport shutil\nimport signal\nimport subprocess\nimport sys\nimport termios\nimport threading\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timedelta\nfrom pathlib import Path\nfrom typing import Optional\nfrom zoneinfo import ZoneInfo\n\nimport yaml\n\ntry:\n    from watchdog.observers import Observer\n    from watchdog.events import FileSystemEventHandler, FileCreatedEvent, FileModifiedEvent\nexcept ImportError:\n    print(\"[AUTO-PIPELINE] ERROR: watchdog not installed. Run: pip install watchdog\")\n    sys.exit(1)\n\n# ─── Configuration ────────────────────────────────────────────────────\n\nORCHESTRATOR_CONFIG_PATH = \".claude/orchestrator-config.yaml\"\nDEFAULT_DEV_SERVER_PORT = 3000\nDEFAULT_BUILD_COMMAND = \"pnpm run build\"\nDEFAULT_TEST_COMMAND = \"pnpm test\"\nDEFAULT_DEV_SERVER_COMMAND = \"pnpm dev\"\nDEFAULT_AGENTS_DIR = \".claude/agents/\"\n\nDEFECT_DIR = \"docs/defect-backlog\"\nFEATURE_DIR = \"docs/feature-backlog\"\nCOMPLETED_SUBDIR = \"completed\"\nPLANS_DIR = \".claude/plans\"\nDESIGN_DIR = \"docs/plans\"\nSTOP_SEMAPHORE_PATH = \".claude/plans/.stop\"\nSAFETY_SCAN_INTERVAL_SECONDS = 60\nPLAN_CREATION_TIMEOUT_SECONDS = 600\nCHILD_SHUTDOWN_TIMEOUT_SECONDS = 10\nRATE_LIMIT_BUFFER_SECONDS = 30\nRATE_LIMIT_DEFAULT_WAIT_SECONDS = 3600\nDEFAULT_MAX_QUOTA_PERCENT = 100.0\nDEFAULT_QUOTA_CEILING_USD = 0.0\nDEFAULT_RESERVED_BUDGET_USD = 0.0\n\n\ndef load_orchestrator_config() -> dict:\n    \"\"\"Load project-level orchestrator config from .claude/orchestrator-config.yaml.\n\n    Returns the parsed dict, or an empty dict if the file doesn't exist.\n    \"\"\"\n    try:\n        with open(ORCHESTRATOR_CONFIG_PATH, \"r\") as f:\n            config = yaml.safe_load(f)\n        return config if isinstance(config, dict) else {}\n    except (IOError, yaml.YAMLError):\n        return {}\n\n\n_config = load_orchestrator_config()\nDEV_SERVER_PORT = int(_config.get(\"dev_server_port\", DEFAULT_DEV_SERVER_PORT))\nBUILD_COMMAND = _config.get(\"build_command\", DEFAULT_BUILD_COMMAND)\nTEST_COMMAND = _config.get(\"test_command\", DEFAULT_TEST_COMMAND)\nDEV_SERVER_COMMAND = _config.get(\"dev_server_command\", DEFAULT_DEV_SERVER_COMMAND)\nAGENTS_DIR = _config.get(\"agents_dir\", DEFAULT_AGENTS_DIR)\n\n# Pattern matching backlog item slugs (NN-slug-name format)\nBACKLOG_SLUG_PATTERN = re.compile(r\"^\\d{2,}-[\\w-]+$\")\n\n# Status patterns in backlog files that indicate already-processed items\nCOMPLETED_STATUS_PATTERN = re.compile(\n    r\"^##\\s*Status:\\s*(Fixed|Completed)\", re.IGNORECASE | re.MULTILINE\n)\n\n# Rate limit detection (same pattern as plan-orchestrator.py)\nRATE_LIMIT_PATTERN = re.compile(\n    r\"(?:You've hit your limit|you've hit your limit|Usage limit reached)\"\n    r\".*?resets?\\s+(\\w+\\s+\\d{1,2})\\s+at\\s+(\\d{1,2}(?::\\d{2})?\\s*(?:am|pm|AM|PM)?)\"\n    r\"(?:\\s*\\(([^)]+)\\))?\",\n    re.IGNORECASE | re.DOTALL,\n)\nMONTH_NAMES = {\n    \"jan\": 1, \"january\": 1, \"feb\": 2, \"february\": 2,\n    \"mar\": 3, \"march\": 3, \"apr\": 4, \"april\": 4,\n    \"may\": 5, \"jun\": 6, \"june\": 6,\n    \"jul\": 7, \"july\": 7, \"aug\": 8, \"august\": 8,\n    \"sep\": 9, \"september\": 9, \"oct\": 10, \"october\": 10,\n    \"nov\": 11, \"november\": 11, \"dec\": 12, \"december\": 12,\n}\n\n# Known locations for the claude binary\nCLAUDE_BINARY_SEARCH_PATHS = [\n    \"/opt/homebrew/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n    \"/usr/local/lib/node_modules/@anthropic-ai/claude-code/cli.js\",\n]\n\n# Global state\nVERBOSE = False\nCLAUDE_CMD: list[str] = [\"claude\"]\n_saved_terminal_settings = None  # Saved termios settings for restoration\n\n# ─── Terminal Management ─────────────────────────────────────────────\n\n\ndef save_terminal_settings() -> None:\n    \"\"\"Save current terminal settings. Call before spawning child processes.\"\"\"\n    global _saved_terminal_settings\n    try:\n        if sys.stdin.isatty():\n            _saved_terminal_settings = termios.tcgetattr(sys.stdin)\n    except (termios.error, OSError):\n        pass\n\n\ndef restore_terminal_settings() -> None:\n    \"\"\"Restore terminal settings after child process exits or is killed.\n\n    Claude CLI modifies terminal settings (raw mode). If killed abruptly,\n    settings aren't restored, leaving the terminal without echo and in a\n    broken state. This fixes that.\n    \"\"\"\n    global _saved_terminal_settings\n    if _saved_terminal_settings is None:\n        return\n    try:\n        if sys.stdin.isatty():\n            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, _saved_terminal_settings)\n    except (termios.error, OSError):\n        pass\n\n\n# ─── Logging ──────────────────────────────────────────────────────────\n\n\n_PIPELINE_PID = os.getpid()\n\n\ndef log(message: str) -> None:\n    \"\"\"Print a timestamped log message with PID for process tracking.\"\"\"\n    timestamp = datetime.now().strftime(\"%H:%M:%S\")\n    print(f\"[{timestamp}] [AUTO-PIPELINE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\ndef verbose_log(message: str) -> None:\n    \"\"\"Print a verbose log message if verbose mode is enabled.\"\"\"\n    if VERBOSE:\n        timestamp = datetime.now().strftime(\"%H:%M:%S.%f\")[:-3]\n        print(f\"[{timestamp}] [VERBOSE:{_PIPELINE_PID}] {message}\", flush=True)\n\n\n# ─── Claude Binary Resolution ────────────────────────────────────────\n\n\ndef resolve_claude_binary() -> list[str]:\n    \"\"\"Find the claude binary, checking PATH then known install locations.\"\"\"\n    claude_path = shutil.which(\"claude\")\n    if claude_path:\n        return [claude_path]\n\n    for search_path in CLAUDE_BINARY_SEARCH_PATHS:\n        if os.path.isfile(search_path):\n            node_path = shutil.which(\"node\")\n            if node_path:\n                return [node_path, search_path]\n\n    npx_path = shutil.which(\"npx\")\n    if npx_path:\n        return [npx_path, \"@anthropic-ai/claude-code\"]\n\n    log(\"WARNING: Could not find 'claude' binary. Tasks will fail.\")\n    return [\"claude\"]\n\n\n# ─── Output Streaming ────────────────────────────────────────────────\n\n\nclass OutputCollector:\n    \"\"\"Collects output from a subprocess and tracks stats.\"\"\"\n\n    def __init__(self):\n        self.lines: list[str] = []\n        self.bytes_received: int = 0\n        self.line_count: int = 0\n\n    def add_line(self, line: str) -> None:\n        self.lines.append(line)\n        self.bytes_received += len(line.encode(\"utf-8\"))\n        self.line_count += 1\n\n    def get_output(self) -> str:\n        return \"\".join(self.lines)\n\n\ndef stream_output(\n    pipe, prefix: str, collector: OutputCollector, show_full: bool\n) -> None:\n    \"\"\"Stream output from a subprocess pipe line by line.\"\"\"\n    try:\n        for line in iter(pipe.readline, \"\"):\n            if line:\n                collector.add_line(line)\n                if show_full:\n                    ts = datetime.now().strftime(\"%H:%M:%S\")\n                    print(f\"[{ts}] [{prefix}] {line.rstrip()}\", flush=True)\n    except Exception as e:\n        if VERBOSE:\n            verbose_log(f\"Error streaming {prefix}: {e}\")\n\n\n# ─── Rate Limit Handling ─────────────────────────────────────────────\n\n\ndef parse_rate_limit_reset_time(output: str) -> Optional[datetime]:\n    \"\"\"Parse a rate limit reset time from Claude CLI output.\"\"\"\n    match = RATE_LIMIT_PATTERN.search(output)\n    if not match:\n        return None\n\n    date_str = match.group(1).strip()\n    time_str = match.group(2).strip()\n    tz_str = match.group(3)\n\n    try:\n        parts = date_str.split()\n        if len(parts) != 2:\n            return None\n        month_name, day_str = parts\n        month = MONTH_NAMES.get(month_name.lower())\n        if not month:\n            return None\n        day = int(day_str)\n\n        time_match = re.match(r\"(\\d{1,2})(?::(\\d{2}))?\\s*(am|pm)\", time_str, re.IGNORECASE)\n        if not time_match:\n            return None\n        hour = int(time_match.group(1))\n        minute = int(time_match.group(2) or \"0\")\n        ampm = time_match.group(3).lower()\n        if ampm == \"pm\" and hour != 12:\n            hour += 12\n        elif ampm == \"am\" and hour == 12:\n            hour = 0\n\n        tz = ZoneInfo(tz_str) if tz_str else ZoneInfo(\"America/Toronto\")\n        now = datetime.now(tz)\n        year = now.year\n        reset_time = datetime(year, month, day, hour, minute, tzinfo=tz)\n\n        if reset_time < now:\n            reset_time = reset_time.replace(year=year + 1)\n\n        return reset_time\n    except (ValueError, KeyError):\n        return None\n\n\ndef check_rate_limit(output: str) -> Optional[float]:\n    \"\"\"Check if output contains a rate limit message. Returns seconds to wait, or None.\"\"\"\n    if not re.search(r\"(?:You've hit your limit|Usage limit reached)\", output, re.IGNORECASE):\n        return None\n\n    reset_time = parse_rate_limit_reset_time(output)\n    if reset_time:\n        now = datetime.now(reset_time.tzinfo)\n        wait_seconds = (reset_time - now).total_seconds() + RATE_LIMIT_BUFFER_SECONDS\n        return max(wait_seconds, 0)\n\n    return float(RATE_LIMIT_DEFAULT_WAIT_SECONDS)\n\n\n# ─── Stop Semaphore ──────────────────────────────────────────────────\n\n\ndef check_stop_requested() -> bool:\n    \"\"\"Check if a graceful stop has been requested via semaphore file.\"\"\"\n    return os.path.exists(STOP_SEMAPHORE_PATH)\n\n\ndef clear_stop_semaphore() -> None:\n    \"\"\"Remove the stop semaphore file if it exists.\"\"\"\n    if os.path.exists(STOP_SEMAPHORE_PATH):\n        os.remove(STOP_SEMAPHORE_PATH)\n        log(f\"Cleared stale stop semaphore: {STOP_SEMAPHORE_PATH}\")\n\n\n# ─── Backlog Scanning ────────────────────────────────────────────────\n\n\n@dataclass\nclass BacklogItem:\n    \"\"\"A defect or feature backlog item.\"\"\"\n    path: str\n    name: str\n    slug: str\n    item_type: str  # \"defect\" or \"feature\"\n\n    @property\n    def display_name(self) -> str:\n        return f\"{self.item_type}: {self.name}\"\n\n\ndef is_item_completed(filepath: str) -> bool:\n    \"\"\"Check if a backlog item file has a completed/fixed status.\"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read(2000)  # Only need the header\n        return bool(COMPLETED_STATUS_PATTERN.search(content))\n    except (IOError, OSError):\n        return False\n\n\ndef scan_directory(directory: str, item_type: str) -> list[BacklogItem]:\n    \"\"\"Scan a backlog directory for processable .md files.\"\"\"\n    items: list[BacklogItem] = []\n    dir_path = Path(directory)\n\n    if not dir_path.exists():\n        return items\n\n    for md_file in sorted(dir_path.glob(\"*.md\")):\n        if md_file.name.startswith(\".\"):\n            continue\n        if is_item_completed(str(md_file)):\n            verbose_log(f\"Skipping completed item: {md_file.name}\")\n            continue\n\n        slug = md_file.stem  # filename without .md\n        items.append(BacklogItem(\n            path=str(md_file),\n            name=md_file.stem.replace(\"-\", \" \").title(),\n            slug=slug,\n            item_type=item_type,\n        ))\n\n    return items\n\n\ndef parse_dependencies(filepath: str) -> list[str]:\n    \"\"\"Parse the ## Dependencies section from a backlog .md file.\n\n    Extracts dependency slugs from lines like '- 03-karma-trust-system.md' or\n    '- 03-karma-trust-system'. Non-backlog dependencies (e.g. 'Base application\n    scaffold') that don't match the NN-slug pattern are silently skipped.\n\n    Returns list of dependency slugs (e.g. ['03-karma-trust-system']).\n    \"\"\"\n    try:\n        with open(filepath, \"r\") as f:\n            content = f.read()\n    except (IOError, OSError):\n        return []\n\n    deps: list[str] = []\n    in_deps_section = False\n\n    for line in content.splitlines():\n        stripped = line.strip()\n\n        # Detect the Dependencies heading\n        if re.match(r\"^##\\s+Dependencies\", stripped, re.IGNORECASE):\n            in_deps_section = True\n            continue\n\n        # Stop at the next heading\n        if in_deps_section and stripped.startswith(\"##\"):\n            break\n\n        if not in_deps_section:\n            continue\n\n        # Parse list items: '- 03-karma-trust-system.md' or '- 03-karma-trust-system'\n        list_match = re.match(r\"^-\\s+(.+)\", stripped)\n        if not list_match:\n            continue\n\n        raw = list_match.group(1).strip()\n        # Extract the filename portion (before any parenthetical comment or space)\n        # e.g. '03-karma-trust-system.md (determines who can post)' -> '03-karma-trust-system.md'\n        filename_part = re.split(r\"\\s+\\(|$\", raw)[0].strip()\n        # Strip .md extension if present\n        slug = filename_part.removesuffix(\".md\").strip()\n\n        # Only include items matching the NN-slug backlog pattern\n        if BACKLOG_SLUG_PATTERN.match(slug):\n            deps.append(slug)\n        else:\n            verbose_log(f\"Ignoring non-backlog dependency: '{raw}' in {filepath}\")\n\n    return deps\n\n\ndef completed_slugs() -> set[str]:\n    \"\"\"Build a set of completed backlog item slugs from completed/ directories.\"\"\"\n    slugs: set[str] = set()\n\n    for base_dir in [DEFECT_DIR, FEATURE_DIR]:\n        completed_dir = Path(base_dir) / COMPLETED_SUBDIR\n        if not completed_dir.exists():\n            continue\n        for md_file in completed_dir.glob(\"*.md\"):\n            slugs.add(md_file.stem)\n\n    return slugs\n\n\ndef scan_all_backlogs() -> list[BacklogItem]:\n    \"\"\"Scan both backlog directories with dependency filtering.\n\n    Returns defects first, then features. Items whose dependencies are not\n    all present in the completed/ directories are filtered out.\n    \"\"\"\n    defects = scan_directory(DEFECT_DIR, \"defect\")\n    features = scan_directory(FEATURE_DIR, \"feature\")\n    all_items = defects + features\n\n    # Build the set of completed slugs for dependency resolution\n    done = completed_slugs()\n    verbose_log(f\"Completed slugs: {done}\")\n\n    # Filter items with unsatisfied dependencies\n    ready: list[BacklogItem] = []\n    for item in all_items:\n        deps = parse_dependencies(item.path)\n        if not deps:\n            ready.append(item)\n            continue\n\n        unsatisfied = [d for d in deps if d not in done]\n        if unsatisfied:\n            log(f\"Skipped: {item.slug} (waiting on: {', '.join(unsatisfied)})\")\n        else:\n            ready.append(item)\n\n    return ready\n\n\n# ─── Filesystem Watcher ──────────────────────────────────────────────\n\n\nclass BacklogWatcher(FileSystemEventHandler):\n    \"\"\"Watchdog handler that detects new/modified backlog items.\"\"\"\n\n    def __init__(self, event_callback):\n        super().__init__()\n        self.event_callback = event_callback\n\n    def on_created(self, event):\n        if isinstance(event, FileCreatedEvent) and event.src_path.endswith(\".md\"):\n            # Ignore files in completed/ subdirectory\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File created: {event.src_path}\")\n                self.event_callback()\n\n    def on_modified(self, event):\n        if isinstance(event, FileModifiedEvent) and event.src_path.endswith(\".md\"):\n            if f\"/{COMPLETED_SUBDIR}/\" not in event.src_path:\n                verbose_log(f\"File modified: {event.src_path}\")\n                self.event_callback()\n\n\n# ─── Child Process Runner ────────────────────────────────────────────\n\n\n@dataclass\nclass ProcessResult:\n    \"\"\"Result of a child process execution.\"\"\"\n    success: bool\n    exit_code: int\n    stdout: str\n    stderr: str\n    duration_seconds: float\n    rate_limited: bool = False\n    rate_limit_wait: Optional[float] = None\n\n\n# Max chars from plan name used in report filenames (matches plan-orchestrator.py)\nMAX_PLAN_NAME_LENGTH = 50\n\n\nclass SessionUsageTracker:\n    \"\"\"Accumulates usage reports across all work items in a pipeline session.\"\"\"\n\n    def __init__(self) -> None:\n        self.work_item_costs: list[dict] = []\n        self.total_cost_usd: float = 0.0\n        self.total_input_tokens: int = 0\n        self.total_output_tokens: int = 0\n\n    def record_from_report(self, report_path: str, work_item_name: str) -> None:\n        \"\"\"Read a usage report JSON and accumulate totals.\"\"\"\n        try:\n            with open(report_path) as f:\n                report = json.load(f)\n            total = report.get(\"total\", {})\n            cost = total.get(\"cost_usd\", 0.0)\n            self.total_cost_usd += cost\n            self.total_input_tokens += total.get(\"input_tokens\", 0)\n            self.total_output_tokens += total.get(\"output_tokens\", 0)\n            self.work_item_costs.append({\n                \"name\": work_item_name,\n                \"cost_usd\": cost,\n            })\n            log(f\"[Usage] {work_item_name}: ${cost:.4f}\")\n        except (FileNotFoundError, json.JSONDecodeError, ValueError):\n            pass  # Report not available, skip silently\n\n    def format_session_summary(self) -> str:\n        \"\"\"Format session-level usage summary.\"\"\"\n        lines = [\"\\n=== Pipeline Session Usage ===\"]\n        lines.append(f\"Total cost: ${self.total_cost_usd:.4f}\")\n        lines.append(\n            f\"Total tokens: {self.total_input_tokens:,} input / \"\n            f\"{self.total_output_tokens:,} output\"\n        )\n        if self.work_item_costs:\n            lines.append(\"Per work item:\")\n            for item in self.work_item_costs:\n                lines.append(f\"  {item['name']}: ${item['cost_usd']:.4f}\")\n        return \"\\n\".join(lines)\n\n    def write_session_report(self) -> Optional[str]:\n        \"\"\"Write a session summary JSON file.\"\"\"\n        if not self.work_item_costs:\n            return None\n        log_dir = Path(\".claude/plans/logs\")\n        log_dir.mkdir(parents=True, exist_ok=True)\n        timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n        report_path = log_dir / f\"pipeline-session-{timestamp}.json\"\n        report = {\n            \"session_timestamp\": datetime.now().isoformat(),\n            \"total_cost_usd\": self.total_cost_usd,\n            \"total_input_tokens\": self.total_input_tokens,\n            \"total_output_tokens\": self.total_output_tokens,\n            \"work_items\": self.work_item_costs,\n        }\n        with open(report_path, \"w\") as f:\n            json.dump(report, f, indent=2)\n        return str(report_path)\n\n\nclass PipelineBudgetGuard:\n    \"\"\"Checks session-level cost against budget limits before each work item.\"\"\"\n\n    def __init__(self, max_quota_percent: float, quota_ceiling_usd: float,\n                 reserved_budget_usd: float = 0.0) -> None:\n        self.max_quota_percent = max_quota_percent\n        self.quota_ceiling_usd = quota_ceiling_usd\n        self.reserved_budget_usd = reserved_budget_usd\n\n    @property\n    def is_enabled(self) -> bool:\n        return self.quota_ceiling_usd > 0\n\n    @property\n    def effective_limit_usd(self) -> float:\n        if self.quota_ceiling_usd <= 0:\n            return float('inf')\n        percent_limit = self.quota_ceiling_usd * (self.max_quota_percent / 100.0)\n        if self.reserved_budget_usd > 0:\n            reserve_limit = self.quota_ceiling_usd - self.reserved_budget_usd\n            return min(percent_limit, reserve_limit)\n        return percent_limit\n\n    def can_proceed(self, session_cost_usd: float) -> tuple[bool, str]:\n        \"\"\"Check if session budget allows another work item.\"\"\"\n        if not self.is_enabled:\n            return (True, \"\")\n        limit = self.effective_limit_usd\n        if session_cost_usd >= limit:\n            pct = (session_cost_usd / self.quota_ceiling_usd * 100)\n            reason = (\n                f\"Session budget limit reached: ${session_cost_usd:.4f} / ${limit:.4f} \"\n                f\"({pct:.1f}% of ${self.quota_ceiling_usd:.2f} ceiling)\"\n            )\n            return (False, reason)\n        return (True, \"\")\n\n\ndef run_child_process(\n    cmd: list[str],\n    description: str,\n    timeout: Optional[int] = None,\n    show_output: bool = False,\n) -> ProcessResult:\n    \"\"\"Run a child process with output streaming and crash detection.\"\"\"\n    start_time = time.time()\n    log(f\"Starting: {description}\")\n    verbose_log(f\"Command: {' '.join(cmd[:3])}...\")\n\n    # Save terminal settings before child process can corrupt them\n    save_terminal_settings()\n\n    stdout_collector = OutputCollector()\n    stderr_collector = OutputCollector()\n\n    try:\n        # Force unbuffered output from Python child processes (orchestrator)\n        # so their output streams in real-time instead of in chunks\n        child_env = os.environ.copy()\n        child_env[\"PYTHONUNBUFFERED\"] = \"1\"\n        child_env.pop(\"CLAUDECODE\", None)  # Allow spawning Claude from within Claude Code\n\n        process = subprocess.Popen(\n            cmd,\n            stdin=subprocess.DEVNULL,  # Prevent children from modifying terminal settings\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            cwd=os.getcwd(),\n            env=child_env,\n        )\n\n        # Track active child for signal handling\n        global _active_child_process\n        _active_child_process = process\n        log(f\"Spawned child process PID {process.pid}: {description}\")\n\n        # Start output streaming threads\n        stdout_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stdout, description, stdout_collector, show_output or VERBOSE),\n        )\n        stderr_thread = threading.Thread(\n            target=stream_output,\n            args=(process.stderr, f\"{description} ERR\", stderr_collector, show_output or VERBOSE),\n        )\n        stdout_thread.start()\n        stderr_thread.start()\n\n        # Monitor process with optional timeout\n        if not (show_output or VERBOSE):\n            print(f\"  [{description}] Working\", end=\"\", flush=True)\n\n        while process.poll() is None:\n            time.sleep(1)\n            elapsed = time.time() - start_time\n\n            if not (show_output or VERBOSE):\n                current_bytes = stdout_collector.bytes_received + stderr_collector.bytes_received\n                if current_bytes > 0 and int(elapsed) % 10 == 0:\n                    print(\".\", end=\"\", flush=True)\n\n            if timeout and elapsed > timeout:\n                if not (show_output or VERBOSE):\n                    print(\" [TIMEOUT]\", flush=True)\n                log(f\"TIMEOUT after {timeout}s: {description}\")\n                process.terminate()\n                try:\n                    process.wait(timeout=5)\n                except subprocess.TimeoutExpired:\n                    process.kill()\n                    process.wait()\n                stdout_thread.join(timeout=2)\n                stderr_thread.join(timeout=2)\n                _active_child_process = None\n                restore_terminal_settings()\n                duration = time.time() - start_time\n                return ProcessResult(\n                    success=False, exit_code=-1,\n                    stdout=stdout_collector.get_output(),\n                    stderr=stderr_collector.get_output(),\n                    duration_seconds=duration,\n                )\n\n        # Process finished\n        stdout_thread.join(timeout=5)\n        stderr_thread.join(timeout=5)\n        _active_child_process = None\n        restore_terminal_settings()\n\n        duration = time.time() - start_time\n        exit_code = process.returncode\n        log(f\"Child PID {process.pid} exited with code {exit_code} after {duration:.0f}s: {description}\")\n\n        if not (show_output or VERBOSE):\n            status = \"done\" if exit_code == 0 else f\"FAILED (exit {exit_code})\"\n            print(\n                f\" {status} ({stdout_collector.line_count} lines, \"\n                f\"{stdout_collector.bytes_received:,} bytes, {duration:.0f}s)\",\n                flush=True,\n            )\n\n        full_output = stdout_collector.get_output() + stderr_collector.get_output()\n\n        # Check for rate limiting\n        rate_limit_wait = check_rate_limit(full_output)\n        if rate_limit_wait is not None:\n            return ProcessResult(\n                success=False, exit_code=exit_code,\n                stdout=stdout_collector.get_output(),\n                stderr=stderr_collector.get_output(),\n                duration_seconds=duration,\n                rate_limited=True,\n                rate_limit_wait=rate_limit_wait,\n            )\n\n        return ProcessResult(\n            success=(exit_code == 0),\n            exit_code=exit_code,\n            stdout=stdout_collector.get_output(),\n            stderr=stderr_collector.get_output(),\n            duration_seconds=duration,\n        )\n\n    except FileNotFoundError as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Command not found: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n    except Exception as e:\n        _active_child_process = None\n        restore_terminal_settings()\n        duration = time.time() - start_time\n        log(f\"ERROR: Unexpected error running {description}: {e}\")\n        return ProcessResult(\n            success=False, exit_code=-1, stdout=\"\", stderr=str(e),\n            duration_seconds=duration,\n        )\n\n\n# Active child process for signal handling\n_active_child_process: Optional[subprocess.Popen] = None\n\n\n# ─── Plan Creation ────────────────────────────────────────────────────\n\nPLAN_CREATION_PROMPT_TEMPLATE = \"\"\"You are creating an implementation plan for a backlog item.\n\n## Instructions\n\n1. Read the backlog item file: {item_path}\n2. Read procedure-coding-rules.md for coding standards\n3. Read an existing YAML plan for format reference: look at .claude/plans/*.yaml files\n4. Read the CLAUDE.md file for project conventions\n5. If the backlog item has a ## Verification Log section, READ IT CAREFULLY.\n   Previous fix attempts and their verification results are recorded there.\n   Your plan MUST address any unresolved findings from prior verifications.\n\n## What to produce\n\n1. Create a design document at: docs/plans/{date}-{slug}-design.md\n   - Brief architecture overview\n   - Key files to create/modify\n   - Design decisions\n\n2. Create a YAML plan at: .claude/plans/{slug}.yaml\n   - Use the exact format: meta + sections with nested tasks\n   - Each section has: id, name, status: pending, tasks: [...]\n   - Each task has: id, name, description, status: pending\n   - Task descriptions should be detailed enough for a fresh Claude session to execute\n   - Include: documentation tasks, implementation tasks, unit tests, verification\n   - The verification task should run {build_command} and {test_command}\n\n3. Validate the plan: python scripts/plan-orchestrator.py --plan .claude/plans/{slug}.yaml --dry-run\n   - If validation fails, fix the YAML format and retry\n\n4. Git commit both files with message: \"plan: add {slug} design and YAML plan\"\n\n## Backlog item type: {item_type}\n\n## Agent Selection\n\nTasks can specify which agent should execute them via the optional \"agent\" field.\nAvailable agents are in {agents_dir}:\n\n- **coder**: Implementation specialist. Use for coding, implementation, and\n  modification tasks. This is the default if no agent is specified.\n- **code-reviewer**: Read-only reviewer. Use for verification, review, and\n  compliance-checking tasks.\n\nExample:\n  - id: '2.1'\n    name: Implement the feature\n    agent: coder\n    status: pending\n    description: ...\n\n  - id: '3.1'\n    name: Review code quality\n    agent: code-reviewer\n    status: pending\n    description: ...\n\nIf you do not set the agent field, the orchestrator will infer it from the\ntask description (verification tasks get code-reviewer, everything else gets coder).\n\n## Validation (Optional)\n\nPlans can enable per-task validation by adding a validation block to the meta section. When enabled, a validator agent runs after each coder task to independently verify the result.\n\nExample meta configuration:\n\n  meta:\n    validation:\n      enabled: true\n      run_after:\n        - coder\n      validators:\n        - validator\n      max_validation_attempts: 1\n\nThe validator produces PASS/WARN/FAIL verdicts:\n- PASS: task proceeds normally\n- WARN: task completes but warnings are logged\n- FAIL: task is retried with validation findings prepended to the prompt\n\nFor defect fixes, use the issue-verifier validator instead of or in addition to the default validator. This validator reads the original defect file and checks whether reported symptoms are resolved.\n\n## Important\n- Follow the CLAUDE.md change workflow order: docs -> code -> tests -> verification\n- For defects: include a task to verify the fix with a regression test\n- For features: include documentation, implementation, unit tests, and E2E tests as appropriate\n- Keep tasks focused - each task should be completable in one Claude session (under 10 minutes)\n- If the backlog item has a ## Verification Log with unresolved findings, your plan\n  must specifically address those findings. The previous code fix may be correct but\n  incomplete (e.g., operational steps not executed, data not deployed).\n\"\"\"\n\n\ndef reset_interrupted_tasks(plan_path: str) -> int:\n    \"\"\"Reset in_progress tasks back to pending and clear their attempt counters.\n\n    When the pipeline is killed mid-task, the orchestrator leaves tasks as\n    'in_progress'. On recovery, these should be treated as fresh retries,\n    not as failed attempts. Returns the number of tasks reset.\n    \"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n    except (IOError, yaml.YAMLError) as e:\n        log(f\"WARNING: Could not read plan for reset: {e}\")\n        return 0\n\n    if not plan or \"sections\" not in plan:\n        return 0\n\n    reset_count = 0\n    for section in plan.get(\"sections\", []):\n        for task in section.get(\"tasks\", []):\n            if task.get(\"status\") == \"in_progress\":\n                task_id = task.get(\"id\", \"?\")\n                task[\"status\"] = \"pending\"\n                # Clear attempt counter so interrupted tasks don't burn retries\n                task.pop(\"attempts\", None)\n                task.pop(\"last_attempt\", None)\n                reset_count += 1\n                log(f\"  Reset interrupted task {task_id}: in_progress -> pending\")\n\n        # Also reset section status if it was in_progress\n        if section.get(\"status\") == \"in_progress\":\n            section[\"status\"] = \"pending\"\n\n    if reset_count > 0:\n        try:\n            with open(plan_path, \"w\") as f:\n                yaml.dump(plan, f, default_flow_style=False, sort_keys=False)\n            log(f\"Reset {reset_count} interrupted task(s)\")\n        except IOError as e:\n            log(f\"WARNING: Could not write plan after reset: {e}\")\n            return 0\n\n    return reset_count\n\n\ndef check_existing_plan(item: BacklogItem) -> Optional[str]:\n    \"\"\"Check if a valid YAML plan already exists for this item.\n\n    Returns the plan path if it exists and is valid, None otherwise.\n    This enables recovery: if the pipeline was interrupted after plan creation\n    but before completion, we skip straight to execution on restart.\n    \"\"\"\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n    if not os.path.exists(plan_path):\n        return None\n\n    # Reset any tasks stuck as in_progress from a previous interrupted run\n    reset_interrupted_tasks(plan_path)\n\n    # Count task statuses from YAML directly (faster than dry-run validation)\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        if not plan or \"sections\" not in plan:\n            log(f\"WARNING: Plan file is empty or invalid: {plan_path}\")\n            return None\n        done = 0\n        pending = 0\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    done += 1\n                elif status == \"pending\":\n                    pending += 1\n    except (IOError, yaml.YAMLError):\n        log(f\"WARNING: Could not parse plan file: {plan_path}\")\n        return None\n\n    if pending == 0 and done > 0:\n        log(f\"Found existing plan: {plan_path} (all {done} tasks completed)\")\n    else:\n        log(f\"Found existing plan: {plan_path} ({done} completed, {pending} pending)\")\n    return plan_path\n\n\ndef create_plan(item: BacklogItem, dry_run: bool = False) -> Optional[str]:\n    \"\"\"Create a design doc and YAML plan for a backlog item.\n\n    Returns the plan YAML path on success, or None on failure.\n    If a valid plan already exists (from a previous interrupted run), returns it directly.\n    \"\"\"\n    date_str = datetime.now().strftime(\"%Y-%m-%d\")\n    plan_path = f\"{PLANS_DIR}/{item.slug}.yaml\"\n\n    if dry_run:\n        existing = os.path.exists(plan_path)\n        if existing:\n            log(f\"[DRY RUN] Would resume existing plan: {plan_path}\")\n        else:\n            log(f\"[DRY RUN] Would create plan for: {item.display_name}\")\n            log(f\"  Design: {DESIGN_DIR}/{date_str}-{item.slug}-design.md\")\n            log(f\"  Plan:   {plan_path}\")\n        return plan_path\n\n    # Check for existing plan (recovery from interrupted run)\n    existing_plan = check_existing_plan(item)\n    if existing_plan:\n        log(f\"Resuming from existing plan (skipping Phase 1)\")\n        return existing_plan\n\n    prompt = PLAN_CREATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        date=date_str,\n        slug=item.slug,\n        item_type=item.item_type,\n        agents_dir=AGENTS_DIR,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Plan creation for {item.slug}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        return None  # Caller handles rate limit sleep\n\n    if not result.success:\n        log(f\"Plan creation failed for {item.display_name} (exit {result.exit_code})\")\n        if result.stderr:\n            log(f\"  stderr: {result.stderr[:500]}\")\n        return None\n\n    # Verify the plan was created and is valid\n    if not os.path.exists(plan_path):\n        log(f\"Plan file not created at expected path: {plan_path}\")\n        return None\n\n    # Dry-run validation\n    validate_result = run_child_process(\n        [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path, \"--dry-run\"],\n        description=f\"Plan validation for {item.slug}\",\n        timeout=30,\n    )\n\n    if not validate_result.success:\n        log(f\"Plan validation failed for {item.slug}\")\n        if validate_result.stdout:\n            log(f\"  output: {validate_result.stdout[:500]}\")\n        return None\n\n    # Count tasks from dry-run output\n    task_count = validate_result.stdout.count(\"Result: SUCCESS\")\n    log(f\"Plan created and validated: {plan_path} ({task_count} tasks)\")\n    return plan_path\n\n\n# ─── Dev Server Management ───────────────────────────────────────────\n\n# Track whether we stopped the dev server so we know to restart it\n_dev_server_was_running = False\n\n\ndef find_dev_server_pid() -> Optional[int]:\n    \"\"\"Find the PID of the Next.js dev server on DEV_SERVER_PORT. Returns None if not running.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"lsof\", \"-ti\", f\":{DEV_SERVER_PORT}\"],\n            capture_output=True, text=True, timeout=5,\n        )\n        if result.returncode == 0 and result.stdout.strip():\n            # lsof may return multiple PIDs (parent + child); take the first\n            pids = result.stdout.strip().split(\"\\n\")\n            return int(pids[0])\n    except (subprocess.TimeoutExpired, ValueError, OSError):\n        pass\n    return None\n\n\ndef stop_dev_server() -> bool:\n    \"\"\"Stop the dev server on DEV_SERVER_PORT if running. Returns True if it was running.\"\"\"\n    global _dev_server_was_running\n    pid = find_dev_server_pid()\n    if pid is None:\n        verbose_log(f\"No dev server found on port {DEV_SERVER_PORT}\")\n        _dev_server_was_running = False\n        return False\n\n    log(f\"Stopping dev server (PID {pid}) on port {DEV_SERVER_PORT}...\")\n    try:\n        os.kill(pid, signal.SIGTERM)\n        # Wait for it to stop\n        for _ in range(10):\n            time.sleep(1)\n            if find_dev_server_pid() is None:\n                break\n        # Force kill if still running\n        if find_dev_server_pid() is not None:\n            remaining_pid = find_dev_server_pid()\n            if remaining_pid:\n                os.kill(remaining_pid, signal.SIGKILL)\n                time.sleep(1)\n    except OSError as e:\n        verbose_log(f\"Error stopping dev server: {e}\")\n\n    _dev_server_was_running = True\n    log(\"Dev server stopped\")\n    return True\n\n\ndef start_dev_server() -> None:\n    \"\"\"Restart the dev server if it was running before we stopped it.\"\"\"\n    global _dev_server_was_running\n    if not _dev_server_was_running:\n        verbose_log(\"Dev server was not running before - skipping restart\")\n        return\n\n    # Check it's not already running (e.g. orchestrator started one)\n    if find_dev_server_pid() is not None:\n        verbose_log(\"Dev server already running - skipping restart\")\n        _dev_server_was_running = False\n        return\n\n    log(f\"Restarting dev server on port {DEV_SERVER_PORT}...\")\n    try:\n        subprocess.Popen(\n            DEV_SERVER_COMMAND.split(),\n            stdout=subprocess.DEVNULL,\n            stderr=subprocess.DEVNULL,\n            cwd=os.getcwd(),\n            start_new_session=True,  # Detach from our process group\n        )\n        # Wait briefly for startup\n        time.sleep(3)\n        if find_dev_server_pid() is not None:\n            log(\"Dev server restarted\")\n        else:\n            log(\"WARNING: Dev server may not have started - check manually\")\n    except OSError as e:\n        log(f\"WARNING: Failed to restart dev server: {e}\")\n\n    _dev_server_was_running = False\n\n\n# ─── Plan Execution ───────────────────────────────────────────────────\n\n\ndef execute_plan(plan_path: str, dry_run: bool = False) -> bool:\n    \"\"\"Execute a YAML plan via the plan orchestrator. Returns True on success.\"\"\"\n    if dry_run:\n        log(f\"[DRY RUN] Would execute plan: {plan_path}\")\n        return True\n\n    # Stop dev server before orchestrator runs (builds conflict with turbopack cache)\n    stop_dev_server()\n\n    try:\n        orch_cmd = [\"python\", \"scripts/plan-orchestrator.py\", \"--plan\", plan_path]\n        if VERBOSE:\n            orch_cmd.append(\"--verbose\")\n\n        result = run_child_process(\n            orch_cmd,\n            description=f\"Orchestrator: {os.path.basename(plan_path)}\",\n            timeout=None,  # Orchestrator has its own timeouts\n            show_output=True,  # Always stream orchestrator output\n        )\n\n        if result.rate_limited and result.rate_limit_wait:\n            log(f\"Rate limited during orchestrator. Waiting {result.rate_limit_wait:.0f}s...\")\n            try:\n                time.sleep(result.rate_limit_wait)\n            except KeyboardInterrupt:\n                log(\"Interrupted during rate limit wait\")\n                return False\n            # After rate limit, the orchestrator needs to be re-run\n            # It will resume from where it left off (tasks already completed in YAML)\n            log(\"Resuming orchestrator after rate limit...\")\n            return execute_plan(plan_path, dry_run)\n\n        if not result.success:\n            log(f\"Orchestrator failed (exit {result.exit_code})\")\n            # Check for partial completion\n            completed = result.stdout.count(\"Result: SUCCESS\")\n            failed = result.stdout.count(\"Result: FAILED\")\n            log(f\"  Tasks completed: {completed}, Tasks failed: {failed}\")\n            return False\n\n        # Parse summary from orchestrator output\n        completed = result.stdout.count(\"Result: SUCCESS\")\n        log(f\"Orchestrator completed: {completed} tasks\")\n        return True\n    finally:\n        # Always restart dev server after orchestrator, even on failure\n        start_dev_server()\n\n\n# ─── Archive ──────────────────────────────────────────────────────────\n\n\ndef find_in_progress_plans() -> list[str]:\n    \"\"\"Find YAML plans that have pending tasks (started but not finished).\n\n    When the pipeline restarts, any plan with remaining pending tasks must\n    be completed before new backlog items are processed. This prevents the\n    pipeline from starting new work while previous plans are incomplete.\n    Excludes the sample-plan.yaml template.\n    \"\"\"\n    in_progress: list[str] = []\n    plans_dir = Path(PLANS_DIR)\n\n    if not plans_dir.exists():\n        return in_progress\n\n    for yaml_file in sorted(plans_dir.glob(\"*.yaml\")):\n        if yaml_file.name == \"sample-plan.yaml\":\n            continue\n\n        try:\n            with open(yaml_file, \"r\") as f:\n                plan = yaml.safe_load(f)\n        except (IOError, yaml.YAMLError):\n            continue\n\n        if not plan or \"sections\" not in plan:\n            continue\n\n        has_completed = False\n        has_pending = False\n        for section in plan.get(\"sections\", []):\n            for task in section.get(\"tasks\", []):\n                status = task.get(\"status\", \"pending\")\n                if status == \"completed\":\n                    has_completed = True\n                elif status in (\"pending\", \"in_progress\"):\n                    has_pending = True\n\n        # A plan is \"in progress\" if it has both completed and pending tasks\n        # (i.e. it was started but not finished)\n        if has_completed and has_pending:\n            in_progress.append(str(yaml_file))\n\n    return in_progress\n\n\ndef archive_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Move a completed backlog item to the completed/ subfolder.\"\"\"\n    source = item.path\n    dest_dir = os.path.join(os.path.dirname(item.path), COMPLETED_SUBDIR)\n    dest = os.path.join(dest_dir, os.path.basename(item.path))\n\n    if dry_run:\n        log(f\"[DRY RUN] Would archive: {source} -> {dest}\")\n        return True\n\n    try:\n        os.makedirs(dest_dir, exist_ok=True)\n        shutil.move(source, dest)\n\n        # Git commit the move\n        subprocess.run([\"git\", \"add\", source, dest], capture_output=True, check=True)\n        subprocess.run(\n            [\"git\", \"commit\", \"-m\", f\"chore: archive completed {item.item_type} {item.slug}\"],\n            capture_output=True, check=True,\n        )\n        log(f\"Archived: {source} -> {dest}\")\n        return True\n    except (OSError, subprocess.CalledProcessError) as e:\n        log(f\"WARNING: Failed to archive {source}: {e}\")\n        return False\n\n\n# ─── Symptom Verification ─────────────────────────────────────────────\n\nVERIFICATION_PROMPT_TEMPLATE = \"\"\"You are a VERIFIER. Your job is to check whether a defect's\nreported symptoms have been fully resolved. You must NOT fix anything. You only observe and report.\n\n## Instructions\n\n1. Read the defect file: {item_path}\n2. Read the \"Expected Behavior\" and \"Actual Behavior\" sections carefully\n3. Read the \"Fix Required\" section for any commands or checks that should be performed\n4. If there is a \"## Verification Log\" section, read previous verification attempts\n\n## What to check\n\nFor each item in \"Fix Required\" or \"Verification\" that describes a testable condition:\n- Run the command or check the condition\n- Record whether it passed or failed\n- Record the actual output or observation\n\nAlso check:\n- Does `{build_command}` pass? (code correctness)\n- Do unit tests pass? (`{test_command}`)\n- Is the reported symptom actually gone? (the MOST IMPORTANT check)\n\n## What to produce\n\nAppend your findings to the defect file at {item_path}.\nIf no \"## Verification Log\" section exists, create one at the end of the file.\n\nUse this exact format (the count MUST increment from the last entry, or start at 1):\n\n```\n### Verification #{count} - YYYY-MM-DD HH:MM\n\n**Verdict: PASS** or **Verdict: FAIL**\n\n**Checks performed:**\n- [ ] or [x] Build passes\n- [ ] or [x] Unit tests pass\n- [ ] or [x] (each specific symptom check from the defect)\n\n**Findings:**\n(describe what you observed for each check - be specific about command outputs)\n```\n\n## CRITICAL RULES\n\n- Do NOT modify any code files\n- Do NOT fix anything\n- Do NOT change the defect's ## Status line\n- ONLY read, run verification commands, and append findings to the defect file\n- If you need the dev server running for a check, start it with `{dev_server_command}`, wait for it,\n  run your check, then stop it\n- Git commit the updated defect file with message: \"verify: {slug} verification #{count}\"\n\"\"\"\n\n# Maximum number of verify-then-fix cycles before giving up\nMAX_VERIFICATION_CYCLES = 3\n\n\ndef count_verification_attempts(item_path: str) -> int:\n    \"\"\"Count how many verification entries exist in the defect file.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return 0\n\n    return len(re.findall(r\"### Verification #\\d+\", content))\n\n\ndef last_verification_passed(item_path: str) -> bool:\n    \"\"\"Check if the most recent verification entry has Verdict: PASS.\"\"\"\n    try:\n        with open(item_path, \"r\") as f:\n            content = f.read()\n    except IOError:\n        return False\n\n    # Find all verdict lines and check the last one\n    verdicts = re.findall(r\"\\*\\*Verdict:\\s*(PASS|FAIL)\\*\\*\", content, re.IGNORECASE)\n    if not verdicts:\n        return False\n    return verdicts[-1].upper() == \"PASS\"\n\n\ndef verify_item(item: BacklogItem, dry_run: bool = False) -> bool:\n    \"\"\"Run symptom verification on a completed defect fix.\n\n    Returns True if verification passed, False if it failed.\n    The verifier appends findings to the defect file regardless of outcome.\n    \"\"\"\n    if item.item_type != \"defect\":\n        # Features don't have symptom verification (yet)\n        return True\n\n    attempt_count = count_verification_attempts(item.path) + 1\n\n    if dry_run:\n        log(f\"[DRY RUN] Would verify symptoms for: {item.display_name} (attempt #{attempt_count})\")\n        return True\n\n    log(f\"Running symptom verification #{attempt_count}...\")\n\n    prompt = VERIFICATION_PROMPT_TEMPLATE.format(\n        item_path=item.path,\n        slug=item.slug,\n        count=attempt_count,\n        build_command=BUILD_COMMAND,\n        test_command=TEST_COMMAND,\n        dev_server_command=DEV_SERVER_COMMAND,\n    )\n\n    cmd = [*CLAUDE_CMD, \"--dangerously-skip-permissions\", \"--print\", prompt]\n\n    result = run_child_process(\n        cmd,\n        description=f\"Verify {item.slug} #{attempt_count}\",\n        timeout=PLAN_CREATION_TIMEOUT_SECONDS,\n        show_output=VERBOSE,\n    )\n\n    if result.rate_limited:\n        log(\"Rate limited during verification\")\n        return False\n\n    if not result.success:\n        log(f\"Verification process failed (exit {result.exit_code})\")\n        return False\n\n    # Check if the verifier recorded a PASS\n    passed = last_verification_passed(item.path)\n    if passed:\n        log(f\"Verification #{attempt_count}: PASSED\")\n    else:\n        log(f\"Verification #{attempt_count}: FAILED - defect stays in queue for next cycle\")\n\n    return passed\n\n\n# ─── Main Pipeline ────────────────────────────────────────────────────\n\n\ndef _read_plan_name(plan_path: str) -> str:\n    \"\"\"Read the plan name from a YAML plan file's meta.name field.\"\"\"\n    try:\n        with open(plan_path, \"r\") as f:\n            plan = yaml.safe_load(f)\n        return plan.get(\"meta\", {}).get(\"name\", \"unknown\") if plan else \"unknown\"\n    except (IOError, yaml.YAMLError):\n        return \"unknown\"\n\n\ndef _try_record_usage(\n    session_tracker: SessionUsageTracker, plan_path: str, work_item_name: str\n) -> None:\n    \"\"\"Try to find and record a usage report after orchestrator execution.\"\"\"\n    plan_name = _read_plan_name(plan_path)\n    safe_name = plan_name.lower().replace(\" \", \"-\")[:MAX_PLAN_NAME_LENGTH]\n    report_path = Path(\".claude/plans/logs\") / f\"{safe_name}-usage-report.json\"\n    if report_path.exists():\n        session_tracker.record_from_report(str(report_path), work_item_name)\n\n\ndef process_item(\n    item: BacklogItem,\n    dry_run: bool = False,\n    session_tracker: Optional[SessionUsageTracker] = None,\n) -> bool:\n    \"\"\"Process a single backlog item through the full pipeline.\n\n    For defects, runs a verify-then-fix cycle:\n      Phase 1: Create plan\n      Phase 2: Execute plan (orchestrator)\n      Phase 3: Verify symptoms resolved (verifier agent, append-only)\n        - If PASS: Phase 4 (archive)\n        - If FAIL: Delete stale plan, loop back to Phase 1\n          (next plan creation sees verification findings in the defect file)\n      Phase 4: Archive\n\n    Returns True on success, False on failure or max cycles exceeded.\n    \"\"\"\n    item_start = time.time()\n    log(f\"{'=' * 60}\")\n    log(f\"Processing {item.display_name}\")\n    log(f\"  Type: {item.item_type}\")\n    log(f\"  File: {item.path}\")\n    log(f\"  Pipeline PID: {_PIPELINE_PID}\")\n    log(f\"{'=' * 60}\")\n\n    prior_verifications = count_verification_attempts(item.path)\n\n    for cycle in range(MAX_VERIFICATION_CYCLES):\n        cycle_num = prior_verifications + cycle + 1\n\n        if check_stop_requested():\n            log(\"Stop requested during processing.\")\n            return False\n\n        # Phase 1: Create plan\n        log(f\"Phase 1: Creating plan (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})...\")\n        plan_path = create_plan(item, dry_run)\n        if not plan_path:\n            log(f\"FAILED: Could not create plan for {item.display_name}\")\n            return False\n\n        # Phase 2: Execute plan\n        log(\"Phase 2: Running orchestrator...\")\n        success = execute_plan(plan_path, dry_run)\n\n        # Record usage from the orchestrator's report (regardless of success)\n        if session_tracker and plan_path:\n            _try_record_usage(session_tracker, plan_path, item.display_name)\n\n        if not success:\n            log(f\"FAILED: Orchestrator failed for {item.display_name}\")\n            return False\n\n        # Phase 3: Verify symptoms\n        log(\"Phase 3: Verifying symptoms...\")\n        verified = verify_item(item, dry_run)\n\n        if verified:\n            # Phase 4: Archive\n            log(\"Phase 4: Archiving...\")\n            archive_item(item, dry_run)\n\n            elapsed = time.time() - item_start\n            minutes = int(elapsed // 60)\n            seconds = int(elapsed % 60)\n            log(f\"Item complete: {item.display_name} ({minutes}m {seconds}s)\")\n            return True\n\n        # Verification failed - prepare for next cycle\n        log(f\"Verification failed (cycle {cycle + 1}/{MAX_VERIFICATION_CYCLES})\")\n\n        if cycle + 1 < MAX_VERIFICATION_CYCLES:\n            # Delete the stale plan so next cycle creates a fresh one\n            # that incorporates the verification findings\n            if plan_path and os.path.exists(plan_path):\n                os.remove(plan_path)\n                log(f\"Removed stale plan: {plan_path}\")\n            log(\"Cycling back to Phase 1 with verification findings...\")\n        else:\n            log(f\"Max verification cycles ({MAX_VERIFICATION_CYCLES}) reached for {item.slug}\")\n            log(\"Defect stays in queue with accumulated verification findings.\")\n\n    return False\n\n\ndef main_loop(dry_run: bool = False, once: bool = False,\n              budget_guard: Optional[PipelineBudgetGuard] = None) -> None:\n    \"\"\"Main processing loop with filesystem watching.\"\"\"\n    global VERBOSE, CLAUDE_CMD\n\n    # Save terminal settings at startup (before any child can corrupt them)\n    save_terminal_settings()\n\n    # Resolve Claude binary\n    CLAUDE_CMD = resolve_claude_binary()\n    log(f\"Claude binary: {' '.join(CLAUDE_CMD)}\")\n\n    # Clear stale stop semaphore\n    clear_stop_semaphore()\n\n    # Track items that failed in this session (don't retry)\n    failed_items: set[str] = set()\n\n    # Track usage across all work items in this session\n    session_tracker = SessionUsageTracker()\n\n    # Event to signal new items detected\n    new_item_event = threading.Event()\n\n    def on_new_item():\n        new_item_event.set()\n\n    # Set up filesystem watcher\n    observer = Observer()\n    watcher = BacklogWatcher(on_new_item)\n\n    for watch_dir in [DEFECT_DIR, FEATURE_DIR]:\n        if os.path.isdir(watch_dir):\n            observer.schedule(watcher, watch_dir, recursive=False)\n            verbose_log(f\"Watching directory: {watch_dir}\")\n\n    if not once:\n        observer.start()\n        log(\"Filesystem watcher started\")\n\n    try:\n        while True:\n            # Check stop semaphore\n            if check_stop_requested():\n                log(\"Stop requested via semaphore. Exiting.\")\n                break\n\n            # Resume in-progress plans before scanning for new work.\n            # This ensures partially-completed plans finish before new items start.\n            if not dry_run:\n                in_progress_plans = find_in_progress_plans()\n                if in_progress_plans:\n                    log(f\"Found {len(in_progress_plans)} in-progress plan(s) to resume\")\n                    for plan_path in in_progress_plans:\n                        if check_stop_requested():\n                            break\n                        log(f\"  Resuming: {os.path.basename(plan_path)}\")\n                        success = execute_plan(plan_path, dry_run)\n                        # Record usage from the orchestrator's report\n                        plan_basename = os.path.basename(plan_path)\n                        _try_record_usage(\n                            session_tracker, plan_path, f\"resumed: {plan_basename}\"\n                        )\n                        if not success:\n                            failed_items.add(plan_path)\n                            log(f\"In-progress plan failed: {plan_path}\")\n                    # After resuming, re-scan (completed plans may unblock new items)\n                    continue\n\n            # Scan for items (with dependency filtering)\n            items = scan_all_backlogs()\n\n            # Filter out previously failed items\n            items = [i for i in items if i.path not in failed_items]\n\n            if items:\n                log(f\"Found {len(items)} item(s) to process\")\n                for i, item in enumerate(items, 1):\n                    log(f\"  {i}. [{item.item_type}] {item.slug}\")\n            else:\n                if once:\n                    log(\"No items to process. Exiting (--once mode).\")\n                    break\n                log(f\"No items to process. Watching for new items...\")\n                log(f\"  (Ctrl+C or 'touch {STOP_SEMAPHORE_PATH}' to stop)\")\n\n                # Wait for either a filesystem event or the safety scan interval\n                new_item_event.clear()\n                new_item_event.wait(timeout=SAFETY_SCAN_INTERVAL_SECONDS)\n                continue\n\n            # In --once mode, process only the first item then exit\n            if once:\n                item = items[0]\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n                log(f\"Processing single item (--once mode): [{item.item_type}] {item.slug}\")\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    log(f\"Item failed: {item.slug}\")\n                log(\"Exiting (--once mode).\")\n                break\n\n            # Process items one at a time\n            for item in items:\n                if check_stop_requested():\n                    log(\"Stop requested. Finishing current session.\")\n                    break\n\n                if budget_guard and budget_guard.is_enabled:\n                    can_go, reason = budget_guard.can_proceed(session_tracker.total_cost_usd)\n                    if not can_go:\n                        log(f\"Budget limit reached: {reason}\")\n                        log(\"Stopping pipeline due to budget constraint.\")\n                        break\n\n                success = process_item(item, dry_run, session_tracker)\n                if not success:\n                    failed_items.add(item.path)\n                    log(f\"Item failed - will not retry in this session: {item.slug}\")\n\n            # Brief pause before next scan\n            time.sleep(2)\n\n    except KeyboardInterrupt:\n        log(\"Interrupted by user. Shutting down...\")\n    finally:\n        # Print and write session usage summary\n        print(session_tracker.format_session_summary())\n        session_report = session_tracker.write_session_report()\n        if session_report:\n            log(f\"[Session usage report: {session_report}]\")\n\n        if not once:\n            observer.stop()\n            observer.join(timeout=5)\n        restore_terminal_settings()\n        log(\"Auto-pipeline stopped.\")\n\n\n# ─── Signal Handling ──────────────────────────────────────────────────\n\n\ndef handle_signal(signum, frame):\n    \"\"\"Handle SIGINT/SIGTERM gracefully.\"\"\"\n    sig_name = \"SIGINT\" if signum == signal.SIGINT else \"SIGTERM\"\n    log(f\"Received {sig_name}. Shutting down gracefully...\")\n\n    # Terminate active child process if any\n    if _active_child_process and _active_child_process.poll() is None:\n        log(f\"Terminating active child process (PID {_active_child_process.pid})...\")\n        _active_child_process.terminate()\n        try:\n            _active_child_process.wait(timeout=CHILD_SHUTDOWN_TIMEOUT_SECONDS)\n        except subprocess.TimeoutExpired:\n            log(\"Child process did not exit gracefully. Killing...\")\n            _active_child_process.kill()\n            _active_child_process.wait()\n\n    # Restore terminal settings (child processes like Claude CLI can corrupt them)\n    restore_terminal_settings()\n\n    sys.exit(0)\n\n\n# ─── Entry Point ──────────────────────────────────────────────────────\n\n\ndef main():\n    global VERBOSE\n\n    parser = argparse.ArgumentParser(\n        description=\"Auto-Pipeline: automated backlog processing for Claude Code\"\n    )\n    parser.add_argument(\n        \"--dry-run\", action=\"store_true\",\n        help=\"Show what would be processed without spawning Claude or orchestrator\",\n    )\n    parser.add_argument(\n        \"--once\", action=\"store_true\",\n        help=\"Process the first item found then exit (single-item mode)\",\n    )\n    parser.add_argument(\n        \"--verbose\", action=\"store_true\",\n        help=\"Stream all child output in detail\",\n    )\n    parser.add_argument(\n        \"--max-budget-pct\", type=float, default=None,\n        metavar=\"N\",\n        help=\"Maximum percentage of quota ceiling to use (default: 100)\",\n    )\n    parser.add_argument(\n        \"--quota-ceiling\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"Weekly quota ceiling in USD (default: 0 = no limit)\",\n    )\n    parser.add_argument(\n        \"--reserved-budget\", type=float, default=None,\n        metavar=\"N.NN\",\n        help=\"USD to reserve for interactive use (default: 0)\",\n    )\n    args = parser.parse_args()\n    VERBOSE = args.verbose\n\n    # Register signal handlers\n    signal.signal(signal.SIGINT, handle_signal)\n    signal.signal(signal.SIGTERM, handle_signal)\n\n    log(\"Starting auto-pipeline\")\n    log(f\"  Defect backlog: {DEFECT_DIR}/\")\n    log(f\"  Feature backlog: {FEATURE_DIR}/\")\n    log(f\"  Mode: {'dry-run' if args.dry_run else 'once' if args.once else 'continuous watch'}\")\n\n    budget_guard = PipelineBudgetGuard(\n        max_quota_percent=args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT,\n        quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,\n        reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,\n    )\n    main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)\n\n\nif __name__ == \"__main__\":\n    main()\n","structuredPatch":[{"oldStart":1690,"oldLines":6,"newStart":1690,"newLines":9,"lines":["         quota_ceiling_usd=args.quota_ceiling or DEFAULT_QUOTA_CEILING_USD,","         reserved_budget_usd=args.reserved_budget or DEFAULT_RESERVED_BUDGET_USD,","     )","+    if budget_guard.is_enabled:","+        log(f\"  Budget: ${budget_guard.effective_limit_usd:.2f} limit\")","+","     main_loop(dry_run=args.dry_run, once=args.once, budget_guard=budget_guard)"," "," "]}],"userModified":false,"replaceAll":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01JcJvedx4vYiEDgyh8qJ9QD","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013598pdhVRaPva99Jkt6KUX","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"completed","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"in_progress","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":508,"cache_read_input_tokens":78813,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":508},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"656ac96e-b5e8-454b-ac16-737298ab89e3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013598pdhVRaPva99Jkt6KUX","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"09e0aa21-f92f-427e-a640-70ccae3653ff","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"in_progress","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"pending","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"completed","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"in_progress","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QM8FEumNGak5ZfJoBS3PBZ","type":"message","role":"assistant","content":[{"type":"text","text":"**Step 8: Verify syntax**"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":79321,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"057910e8-ee60-4650-9a5c-21c007765df1"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QM8FEumNGak5ZfJoBS3PBZ","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011hxhydLzbMXPoTKa6R9Wmu","name":"Bash","input":{"command":"python3 -c \"import py_compile; py_compile.compile('scripts/auto-pipeline.py', doraise=True); py_compile.compile('scripts/plan-orchestrator.py', doraise=True); print('syntax OK')\"","description":"Verify Python syntax for both scripts"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":346,"cache_read_input_tokens":79321,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":346},"output_tokens":8,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"29990481-1b55-419e-88f9-2d155609ee50"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011hxhydLzbMXPoTKa6R9Wmu","type":"tool_result","content":"syntax OK","is_error":false}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"7ae81998-1c3f-425a-9f46-e48d504157ae","tool_use_result":{"stdout":"syntax OK","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011qvfDVNFvEDAa6ir6AuHHY","type":"message","role":"assistant","content":[{"type":"text","text":"Both files pass syntax checks. Let me also verify the class is importable and works correctly:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":154,"cache_read_input_tokens":79667,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":154},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"968d9cdd-17c2-4651-8bb8-466076a0d38a"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011qvfDVNFvEDAa6ir6AuHHY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MK4sYKbtYjX6bu3g7Gxnh2","name":"Bash","input":{"command":"python3 -c \"\nimport importlib.util\nspec = importlib.util.spec_from_file_location('ap', 'scripts/auto-pipeline.py')\nmod = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(mod)\n\n# Verify class exists and properties work\nguard = mod.PipelineBudgetGuard(90.0, 100.0)\nassert guard.is_enabled, 'is_enabled should be True'\nassert guard.effective_limit_usd == 90.0, f'expected 90.0, got {guard.effective_limit_usd}'\n\n# Verify can_proceed under budget\nok, reason = guard.can_proceed(50.0)\nassert ok, 'should be under budget'\nassert reason == '', 'no reason when under budget'\n\n# Verify can_proceed over budget\nok, reason = guard.can_proceed(95.0)\nassert not ok, 'should be over budget'\nassert 'Session budget limit reached' in reason\n\n# Verify disabled guard\ndisabled = mod.PipelineBudgetGuard(100.0, 0.0)\nassert not disabled.is_enabled, 'should be disabled'\nok, reason = disabled.can_proceed(999.0)\nassert ok, 'disabled guard should always allow'\n\n# Verify reserved budget\nreserved = mod.PipelineBudgetGuard(100.0, 100.0, 20.0)\nassert reserved.effective_limit_usd == 80.0, f'expected 80.0, got {reserved.effective_limit_usd}'\n\nprint('All PipelineBudgetGuard assertions passed')\n\"","description":"Verify PipelineBudgetGuard class works correctly"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":154,"cache_read_input_tokens":79667,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":154},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"e633c30a-5ace-4f15-aa13-e19e32400045"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MK4sYKbtYjX6bu3g7Gxnh2","type":"tool_result","content":"All PipelineBudgetGuard assertions passed","is_error":false}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"3042b8de-8730-4c93-a0b4-40428f0826d8","tool_use_result":{"stdout":"All PipelineBudgetGuard assertions passed","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01VetVBJ9T93VYwns4nsxy2J","type":"message","role":"assistant","content":[{"type":"text","text":"Let me also verify the CLI flags are present:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":526,"cache_read_input_tokens":79821,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":526},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"19daa3ab-7667-40a9-8c9a-7fd9eb3c6b86"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01VetVBJ9T93VYwns4nsxy2J","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01U41TECSGntqRpmBrY67s8f","name":"Bash","input":{"command":"python3 scripts/auto-pipeline.py --help 2>&1 | grep -E 'budget|ceiling'","description":"Verify budget CLI flags in --help output"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":526,"cache_read_input_tokens":79821,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":526},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b7dd6701-f6da-4479-9557-b9396838809f"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01U41TECSGntqRpmBrY67s8f","type":"tool_result","content":"                        [--max-budget-pct N] [--quota-ceiling N.NN]\n                        [--reserved-budget N.NN]\n  --max-budget-pct N    Maximum percentage of quota ceiling to use (default:\n  --quota-ceiling N.NN  Weekly quota ceiling in USD (default: 0 = no limit)\n  --reserved-budget N.NN","is_error":false}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"537ea3e5-de8e-4296-99b6-f6659b4af8ac","tool_use_result":{"stdout":"                        [--max-budget-pct N] [--quota-ceiling N.NN]\n                        [--reserved-budget N.NN]\n  --max-budget-pct N    Maximum percentage of quota ceiling to use (default:\n  --quota-ceiling N.NN  Weekly quota ceiling in USD (default: 0 = no limit)\n  --reserved-budget N.NN","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QMRHtCSDFDuNPcq8QGdV5E","type":"message","role":"assistant","content":[{"type":"text","text":"All CLI flags are present. Now let me commit the changes."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":218,"cache_read_input_tokens":80347,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":218},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"69a8fafc-7620-43d1-a7db-e8fb6c316286"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01QMRHtCSDFDuNPcq8QGdV5E","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013B5MY3gbK2pPoALpsmQQjP","name":"Bash","input":{"command":"git diff scripts/auto-pipeline.py --stat","description":"Check diff stats for auto-pipeline.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":218,"cache_read_input_tokens":80347,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":218},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"65044f8c-1eeb-4c24-833e-4ea8798d2cb4"}
{"type":"user","message":{"role":"user","content":[{"type":"tool_result","content":"Exit code 128\nfatal: option '--stat' must come before non-option arguments","is_error":true,"tool_use_id":"toolu_013B5MY3gbK2pPoALpsmQQjP"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"b01079c6-e1fa-430c-9c6f-8bb2d1d4792f","tool_use_result":"Error: Exit code 128\nfatal: option '--stat' must come before non-option arguments"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_011Gcjq5fpezqGF2YKffG9jt","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01N6PiG6bX79ystHsaei5DMj","name":"Bash","input":{"command":"git diff --stat scripts/auto-pipeline.py","description":"Check diff stats for auto-pipeline.py"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":139,"cache_read_input_tokens":80565,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":139},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"adf78f09-61ed-4b97-b25b-b7c576e0a440"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01N6PiG6bX79ystHsaei5DMj","type":"tool_result","content":" scripts/auto-pipeline.py | 82 ++++++++++++++++++++++++++++++++++++++++++++++--\n 1 file changed, 80 insertions(+), 2 deletions(-)","is_error":false}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"db5fdd47-f6dd-411c-a812-fb7ef83edf4a","tool_use_result":{"stdout":" scripts/auto-pipeline.py | 82 ++++++++++++++++++++++++++++++++++++++++++++++--\n 1 file changed, 80 insertions(+), 2 deletions(-)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01E5TCD4hoH7uzzoWz4EesBH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HK4xGYrv7N8wSZGigB6HNS","name":"Bash","input":{"command":"git add scripts/auto-pipeline.py && git commit -m \"$(cat <<'EOF'\nfeat: add PipelineBudgetGuard and budget CLI flags to auto-pipeline\n\nAdd session-level budget awareness to the auto-pipeline:\n- Budget constants (DEFAULT_MAX_QUOTA_PERCENT, DEFAULT_QUOTA_CEILING_USD,\n  DEFAULT_RESERVED_BUDGET_USD) after rate limit constants\n- PipelineBudgetGuard class after SessionUsageTracker with is_enabled,\n  effective_limit_usd, and can_proceed(session_cost_usd) interface\n- CLI flags: --max-budget-pct, --quota-ceiling, --reserved-budget\n- Pre-item budget checks in both --once and continuous loop paths\n- Budget info in startup log when enabled\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n)\"","description":"Commit auto-pipeline budget changes"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":148,"cache_read_input_tokens":80704,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":148},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"80b40715-cb90-4c96-b879-b75344cec038"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HK4xGYrv7N8wSZGigB6HNS","type":"tool_result","content":"[master d5bca4a] feat: add PipelineBudgetGuard and budget CLI flags to auto-pipeline\n 1 file changed, 80 insertions(+), 2 deletions(-)","is_error":false}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"208cdeed-b6a4-4276-8ef1-78f18eb9fc19","tool_use_result":{"stdout":"[master d5bca4a] feat: add PipelineBudgetGuard and budget CLI flags to auto-pipeline\n 1 file changed, 80 insertions(+), 2 deletions(-)","stderr":"","interrupted":false,"isImage":false,"noOutputExpected":false}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016AAeooNPztkCpdkebFqp4X","type":"message","role":"assistant","content":[{"type":"text","text":"Now write the status file."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":588,"cache_read_input_tokens":80852,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":588},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"f5ffc0a0-dbbf-4636-b1b8-c9e657343d57"}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_016AAeooNPztkCpdkebFqp4X","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EcoEA5dmMK5N1a18QVAz2a","name":"TodoWrite","input":{"todos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"completed","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"completed","activeForm":"Verifying syntax and committing"}]},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":588,"cache_read_input_tokens":80852,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":588},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"e82162e7-a3e2-4e80-9179-822ec9df72bf"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EcoEA5dmMK5N1a18QVAz2a","type":"tool_result","content":"Todos have been modified successfully. Ensure that you continue to use the todo list to track your progress. Please proceed with the current tasks if applicable"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"c2611347-be29-4c1d-a5c5-bca7c26943ae","tool_use_result":{"oldTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"completed","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"in_progress","activeForm":"Verifying syntax and committing"}],"newTodos":[{"content":"Add budget constants after RATE_LIMIT_DEFAULT_WAIT_SECONDS","status":"completed","activeForm":"Adding budget constants"},{"content":"Add PipelineBudgetGuard class after SessionUsageTracker","status":"completed","activeForm":"Adding PipelineBudgetGuard class"},{"content":"Add CLI flags to argparse in main()","status":"completed","activeForm":"Adding CLI flags"},{"content":"Update main_loop signature and pass budget_guard from main()","status":"completed","activeForm":"Updating main_loop signature and main() call"},{"content":"Add budget checks in main_loop before process_item calls","status":"completed","activeForm":"Adding budget checks in main_loop"},{"content":"Add budget info to startup log","status":"completed","activeForm":"Adding budget info to startup log"},{"content":"Verify syntax and commit","status":"completed","activeForm":"Verifying syntax and committing"}]}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01EqFe1tLNXmMvH4EHR4nKkW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EUwhXh35rT5ZCTBtTo6pGn","name":"Write","input":{"file_path":"/Users/martinbechard/dev/claude-plan-orchestrator/.claude/plans/task-status.json","content":"{\n  \"task_id\": \"3.1\",\n  \"status\": \"completed\",\n  \"message\": \"Added PipelineBudgetGuard class, budget constants (DEFAULT_MAX_QUOTA_PERCENT, DEFAULT_QUOTA_CEILING_USD, DEFAULT_RESERVED_BUDGET_USD), CLI flags (--max-budget-pct, --quota-ceiling, --reserved-budget), budget checks in both --once and continuous loop paths, and budget info in startup log to scripts/auto-pipeline.py. Syntax verified, all assertions pass.\",\n  \"timestamp\": \"2026-02-14T10:02:30.000000\",\n  \"plan_modified\": false\n}\n"},"caller":{"type":"direct"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":351,"cache_read_input_tokens":81440,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":351},"output_tokens":25,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"cd5b1593-7bb8-4a95-b30d-0f76b13418b3"}
{"type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EUwhXh35rT5ZCTBtTo6pGn","type":"tool_result","content":"File created successfully at: /Users/martinbechard/dev/claude-plan-orchestrator/.claude/plans/task-status.json"}]},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"2b329559-e8f7-4a48-b7bc-225e4bd47b07","tool_use_result":{"type":"create","filePath":"/Users/martinbechard/dev/claude-plan-orchestrator/.claude/plans/task-status.json","content":"{\n  \"task_id\": \"3.1\",\n  \"status\": \"completed\",\n  \"message\": \"Added PipelineBudgetGuard class, budget constants (DEFAULT_MAX_QUOTA_PERCENT, DEFAULT_QUOTA_CEILING_USD, DEFAULT_RESERVED_BUDGET_USD), CLI flags (--max-budget-pct, --quota-ceiling, --reserved-budget), budget checks in both --once and continuous loop paths, and budget info in startup log to scripts/auto-pipeline.py. Syntax verified, all assertions pass.\",\n  \"timestamp\": \"2026-02-14T10:02:30.000000\",\n  \"plan_modified\": false\n}\n","structuredPatch":[],"originalFile":null}}
{"type":"assistant","message":{"model":"claude-opus-4-6","id":"msg_01NFrupqiZ6HbR4zWJyhsLtY","type":"message","role":"assistant","content":[{"type":"text","text":"`★ Insight ─────────────────────────────────────`\n1. **Two-tier budget architecture**: The orchestrator checks budget *per-task* (fine-grained, can pause mid-plan), while the auto-pipeline checks *per-work-item* (coarse-grained, stops between backlog items). This reflects their different abstraction levels — the orchestrator manages tasks within a single plan, while the pipeline manages entire backlog items across multiple plans.\n\n2. **Guard vs. Config separation**: The orchestrator splits concerns into `BudgetConfig` (data) + `BudgetGuard` (behavior wrapping `PlanUsageTracker`). The pipeline's `PipelineBudgetGuard` combines both because it takes a raw `session_cost_usd` float rather than wrapping a tracker — simpler interface for a simpler use case.\n\n3. **`or` vs `None` for CLI defaults**: Using `args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT` means that passing `0` explicitly would fall through to the default. This is intentional here — a 0% budget percentage or $0 ceiling means \"disabled\", which is the same as the default behavior.\n`─────────────────────────────────────────────────`\n\nTask 3.1 is complete. Here's what was implemented in `scripts/auto-pipeline.py`:\n\n- **3 budget constants** (`DEFAULT_MAX_QUOTA_PERCENT`, `DEFAULT_QUOTA_CEILING_USD`, `DEFAULT_RESERVED_BUDGET_USD`) added after `RATE_LIMIT_DEFAULT_WAIT_SECONDS`\n- **`PipelineBudgetGuard` class** added after `SessionUsageTracker` with `is_enabled`, `effective_limit_usd`, and `can_proceed(session_cost_usd)` interface\n- **3 CLI flags** (`--max-budget-pct`, `--quota-ceiling`, `--reserved-budget`) added after `--verbose`\n- **`main_loop` signature** updated to accept `budget_guard: Optional[PipelineBudgetGuard]`\n- **Budget checks** added in both the `--once` path and continuous loop path, before each `process_item()` call\n- **Budget info** logged at startup when enabled\n- Syntax verified for both scripts, all runtime assertions pass, committed as `d5bca4a`"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1,"cache_creation_input_tokens":294,"cache_read_input_tokens":81791,"cache_creation":{"ephemeral_5m_input_tokens":0,"ephemeral_1h_input_tokens":294},"output_tokens":1,"service_tier":"standard","inference_geo":"not_available"},"context_management":null},"parent_tool_use_id":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","uuid":"ab985f19-8a68-4afc-b090-7fea6ba43a56"}
{"type":"result","subtype":"success","is_error":false,"duration_ms":168377,"duration_api_ms":169839,"num_turns":31,"result":"`★ Insight ─────────────────────────────────────`\n1. **Two-tier budget architecture**: The orchestrator checks budget *per-task* (fine-grained, can pause mid-plan), while the auto-pipeline checks *per-work-item* (coarse-grained, stops between backlog items). This reflects their different abstraction levels — the orchestrator manages tasks within a single plan, while the pipeline manages entire backlog items across multiple plans.\n\n2. **Guard vs. Config separation**: The orchestrator splits concerns into `BudgetConfig` (data) + `BudgetGuard` (behavior wrapping `PlanUsageTracker`). The pipeline's `PipelineBudgetGuard` combines both because it takes a raw `session_cost_usd` float rather than wrapping a tracker — simpler interface for a simpler use case.\n\n3. **`or` vs `None` for CLI defaults**: Using `args.max_budget_pct or DEFAULT_MAX_QUOTA_PERCENT` means that passing `0` explicitly would fall through to the default. This is intentional here — a 0% budget percentage or $0 ceiling means \"disabled\", which is the same as the default behavior.\n`─────────────────────────────────────────────────`\n\nTask 3.1 is complete. Here's what was implemented in `scripts/auto-pipeline.py`:\n\n- **3 budget constants** (`DEFAULT_MAX_QUOTA_PERCENT`, `DEFAULT_QUOTA_CEILING_USD`, `DEFAULT_RESERVED_BUDGET_USD`) added after `RATE_LIMIT_DEFAULT_WAIT_SECONDS`\n- **`PipelineBudgetGuard` class** added after `SessionUsageTracker` with `is_enabled`, `effective_limit_usd`, and `can_proceed(session_cost_usd)` interface\n- **3 CLI flags** (`--max-budget-pct`, `--quota-ceiling`, `--reserved-budget`) added after `--verbose`\n- **`main_loop` signature** updated to accept `budget_guard: Optional[PipelineBudgetGuard]`\n- **Budget checks** added in both the `--once` path and continuous loop path, before each `process_item()` call\n- **Budget info** logged at startup when enabled\n- Syntax verified for both scripts, all runtime assertions pass, committed as `d5bca4a`","stop_reason":null,"session_id":"f9299ab3-06dd-44c4-bed4-0bd0f41e15e3","total_cost_usd":1.6130109999999998,"usage":{"input_tokens":30,"cache_creation_input_tokens":61666,"cache_read_input_tokens":2010211,"output_tokens":8384,"server_tool_use":{"web_search_requests":0,"web_fetch_requests":0},"service_tier":"standard","cache_creation":{"ephemeral_1h_input_tokens":61666,"ephemeral_5m_input_tokens":0},"inference_geo":"","iterations":[],"speed":"standard"},"modelUsage":{"claude-opus-4-6":{"inputTokens":30,"outputTokens":8384,"cacheReadInputTokens":2010211,"cacheCreationInputTokens":61666,"webSearchRequests":0,"costUSD":1.6002679999999998,"contextWindow":200000,"maxOutputTokens":32000},"claude-haiku-4-5-20251001":{"inputTokens":11528,"outputTokens":243,"cacheReadInputTokens":0,"cacheCreationInputTokens":0,"webSearchRequests":0,"costUSD":0.012742999999999999,"contextWindow":200000,"maxOutputTokens":32000}},"permission_denials":[],"uuid":"c2cc6130-f9db-402a-9141-03bac8860e85"}

=== STDERR ===
